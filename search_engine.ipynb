{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e44b67e-f87a-4ffd-9cbd-530617d6bcfd",
   "metadata": {},
   "source": [
    "# Ανάκτησης Πληροφορίας - Δημιουργία Μηχανής Αναζήτησης\n",
    "- Μπηλιώνη Παρασκευή <br> Α.Μ. ice20390286\n",
    "  \n",
    "- Πλάγου Αικατερίνη  <br> Α.Μ. ice20390191"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f16e44-86fe-4f42-b1fb-b9a4ef6aea66",
   "metadata": {},
   "source": [
    "# 1. Συλλογή δεδομένων"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce382ce-5a5d-4e64-b889-3db892d56fbf",
   "metadata": {},
   "source": [
    "Εισαγωγή και αρχικοποίηση των απαραίτητων βιβλιοθηκών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31ecc6cc-f715-4e2f-a491-63fe559c791e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vivh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vivh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vivh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup  # Web scraping and parsing \n",
    "import requests                # Makes HTTP request\n",
    "import json                    # Handles JSON data\n",
    "import nltk                    # Text processing\n",
    "import string                  # Handles strings\n",
    "import sys                     # System-specific parameters and functions\n",
    "from nltk.corpus import stopwords       # Handles stopwords in text processing\n",
    "from nltk.stem import WordNetLemmatizer # Word lemmatization\n",
    "from collections import defaultdict     # Creates dictionaries \n",
    "import ipywidgets as widgets            # Creates widgets\n",
    "import numpy as np                      # Does computations\n",
    "from IPython.display import display, Markdown                # Displays widgets and text\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # TF-IDF vectorization\n",
    "from sklearn.metrics.pairwise import cosine_similarity       # Calculates vector similarity (used in VSM)\n",
    "from rank_bm25 import BM25Okapi                              # Rankins documents (used in okapi BM25)\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score  # Calculates engine evaluation metrics\n",
    "from IPython.display import display, Markdown               \n",
    "import pandas as pd   \n",
    "\n",
    "# Download NLTK datasets\n",
    "# Tokenizer models\n",
    "nltk.download('punkt')  \n",
    "# List of stopwords\n",
    "nltk.download('stopwords')  \n",
    "# For lemmatization\n",
    "nltk.download('wordnet')    \n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))  # Set of stopwords\n",
    "lemmatizer = WordNetLemmatizer()              # Lemmatizer for reducing words to base forms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b283a0-d7aa-4e3c-9b8c-b1937d8d982f",
   "metadata": {},
   "source": [
    "Επιλογή πηγής από την οποία θα ξεκινήσει η συλλογή εγγράφων. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef38166-29e8-4966-b24a-68a38b476147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data will be scraped from this starting page: [https://en.wikipedia.org/wiki/Data_analysis](https://en.wikipedia.org/wiki/Data_analysis)<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Starting wikipedia link to scrape\n",
    "wiki_url = 'https://en.wikipedia.org/wiki/Data_analysis'\n",
    "\n",
    "try:\n",
    "    # Send request to starting link\n",
    "    response = requests.get(wiki_url)\n",
    "    # Raise an exception for errors\n",
    "    response.raise_for_status()\n",
    "        \n",
    "    # Parse HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "# Handle any exceptions during the request\n",
    "except requests.RequestException as e:\n",
    "    print(f\"____Request failed____\\n{e}\\n\")\n",
    "\n",
    "display(Markdown(f\"Data will be scraped from this starting page: [{wiki_url}]({wiki_url})<br><br>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551f31d-061d-4fe0-ae56-56cc5bb607a0",
   "metadata": {},
   "source": [
    "Αποθήκευση δεδομένων σε JSON αρχείο.\n",
    "Σε περίπτωση σφάλματος κατά την διάρκεια της διαδικασίας, εμφανίζεται κατάλληλο μήνυμα λάθους."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84adcf0-9753-4895-81aa-ae954f00445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_things(things, filename):\n",
    "    try:\n",
    "        # Open the specified file in write mode\n",
    "        with open(filename, 'w') as file:\n",
    "            # Convert data to a JSON string and write it to the file\n",
    "            json.dump(things, file, indent = 4)\n",
    "\n",
    "    # If the process fails print error message\n",
    "    except Exception as e:\n",
    "        print(f\"____Error saving____\\n{e}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2a824-8e28-4db4-81e5-27bd903d42a1",
   "metadata": {},
   "source": [
    "Απόκτηση εγγράφων/συνδέσμων από την κύρια σελίδα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7976e336-5f00-41b0-b034-9434e2d3dc76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Links saved: <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "https://en.wikipedia.org/wiki/Statistics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Data_and_information_visualization\n",
      "\n",
      "https://en.wikipedia.org/wiki/Exploratory_data_analysis\n",
      "\n",
      "https://en.wikipedia.org/wiki/Information_design\n",
      "\n",
      "https://en.wikipedia.org/wiki/Interactive_data_visualization\n",
      "\n",
      "https://en.wikipedia.org/wiki/Descriptive_statistics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Statistical_inference\n",
      "\n",
      "https://en.wikipedia.org/wiki/Statistical_graphics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Plot_(graphics)\n",
      "\n",
      "https://en.wikipedia.org/wiki/Infographic\n",
      "\n",
      "https://en.wikipedia.org/wiki/Data_science\n",
      "\n",
      "https://en.wikipedia.org/wiki/Tamara_Munzner\n",
      "\n",
      "https://en.wikipedia.org/wiki/Ben_Shneiderman\n",
      "\n",
      "https://en.wikipedia.org/wiki/John_Tukey\n",
      "\n",
      "https://en.wikipedia.org/wiki/Edward_Tufte\n",
      "\n",
      "https://en.wikipedia.org/wiki/Simon_Wardley\n",
      "\n",
      "https://en.wikipedia.org/wiki/Hans_Rosling\n",
      "\n",
      "https://en.wikipedia.org/wiki/David_McCandless\n",
      "\n",
      "https://en.wikipedia.org/wiki/Kim_Albrecht\n",
      "\n",
      "https://en.wikipedia.org/wiki/Alexander_Osterwalder\n",
      "\n",
      "https://en.wikipedia.org/wiki/Ed_Hawkins_(climatologist)\n",
      "\n",
      "https://en.wikipedia.org/wiki/Hadley_Wickham\n",
      "\n",
      "https://en.wikipedia.org/wiki/Leland_Wilkinson\n",
      "\n",
      "https://en.wikipedia.org/wiki/Mike_Bostock\n",
      "\n",
      "https://en.wikipedia.org/wiki/Jeffrey_Heer\n",
      "\n",
      "https://en.wikipedia.org/wiki/Ihab_Ilyas\n",
      "\n",
      "https://en.wikipedia.org/wiki/Line_chart\n",
      "\n",
      "https://en.wikipedia.org/wiki/Bar_chart\n",
      "\n",
      "https://en.wikipedia.org/wiki/Histogram\n",
      "\n",
      "https://en.wikipedia.org/wiki/Scatter_plot\n",
      "\n",
      "https://en.wikipedia.org/wiki/Box_plot\n",
      "\n",
      "https://en.wikipedia.org/wiki/Pareto_chart\n",
      "\n",
      "https://en.wikipedia.org/wiki/Pie_chart\n",
      "\n",
      "https://en.wikipedia.org/wiki/Area_chart\n",
      "\n",
      "https://en.wikipedia.org/wiki/Treemapping\n",
      "\n",
      "https://en.wikipedia.org/wiki/Bubble_chart\n",
      "\n",
      "https://en.wikipedia.org/wiki/Warming_stripes\n",
      "\n",
      "https://en.wikipedia.org/wiki/Control_chart\n",
      "\n",
      "https://en.wikipedia.org/wiki/Run_chart\n",
      "\n",
      "https://en.wikipedia.org/wiki/Stem-and-leaf_display\n",
      "\n",
      "https://en.wikipedia.org/wiki/Cartogram\n",
      "\n",
      "https://en.wikipedia.org/wiki/Small_multiple\n",
      "\n",
      "https://en.wikipedia.org/wiki/Sparkline\n",
      "\n",
      "https://en.wikipedia.org/wiki/Table_(information)\n",
      "\n",
      "https://en.wikipedia.org/wiki/Mosaic_plot\n",
      "\n",
      "https://en.wikipedia.org/wiki/Data\n",
      "\n",
      "https://en.wikipedia.org/wiki/Information\n",
      "\n",
      "https://en.wikipedia.org/wiki/Big_data\n",
      "\n",
      "https://en.wikipedia.org/wiki/Database\n",
      "\n",
      "https://en.wikipedia.org/wiki/Chartjunk\n",
      "\n",
      "https://en.wikipedia.org/wiki/Visual_perception\n",
      "\n",
      "https://en.wikipedia.org/wiki/Regression_analysis\n",
      "\n",
      "https://en.wikipedia.org/wiki/Statistical_model\n",
      "\n",
      "https://en.wikipedia.org/wiki/Misleading_graph\n",
      "\n",
      "https://en.wikipedia.org/wiki/Template:Data_visualization\n",
      "\n",
      "https://en.wikipedia.org/wiki/Template_talk:Data_visualization\n",
      "\n",
      "https://en.wikipedia.org/wiki/Computational_physics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Computational_mechanics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Computational_electromagnetics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Multiphysics_simulation\n",
      "\n",
      "https://en.wikipedia.org/wiki/Computational_particle_physics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Computational_thermodynamics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Computer_simulation\n",
      "\n",
      "https://en.wikipedia.org/wiki/Morse/Long-range_potential\n",
      "\n",
      "https://en.wikipedia.org/wiki/Lennard-Jones_potential\n",
      "\n",
      "https://en.wikipedia.org/wiki/Yukawa_potential\n",
      "\n",
      "https://en.wikipedia.org/wiki/Morse_potential\n",
      "\n",
      "https://en.wikipedia.org/wiki/Computational_fluid_dynamics\n",
      "\n",
      "https://en.wikipedia.org/wiki/Finite_difference_method\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_links(soup):\n",
    "    # Base wikipedia url\n",
    "    https = 'https://en.wikipedia.org'  \n",
    "    # For storing valid links\n",
    "    links = []  \n",
    "\n",
    "    display(Markdown(\"Links saved: <br>\"))\n",
    "    # Find all anchor tags with 'href' attribute\n",
    "    for link in soup.find_all('a', href = True):\n",
    "        # Extract link reference\n",
    "        url = link.get('href') \n",
    "\n",
    "        # Check if the link is a wikipedia aticle and filter out irrelevant links\n",
    "        if url.startswith('/wiki/') and not any(\n",
    "            url.startswith(f'/wiki/{keyword}')\n",
    "            for keyword in ['Wikipedia', 'Help', 'Special', 'Portal', 'Talk', 'Category', 'File', 'Main_Page']):\n",
    "            # Construct full wikipedia url\n",
    "            full_url = f\"{https}{url}\"\n",
    "\n",
    "            # Skip links that appear if they are already saved\n",
    "            if full_url not in links:\n",
    "                links.append(full_url)\n",
    "                #display(Markdown(f\"[{full_url}]({full_url})<br>\"))\n",
    "                print(f\"{full_url}\\n\")\n",
    "                \n",
    "        # Collect 70 first valid links\n",
    "        if len(links) >= 70:\n",
    "            break \n",
    "            \n",
    "    # Return links\n",
    "    return links  \n",
    "\n",
    "\n",
    "# Collect and store links from the main page\n",
    "links = get_links(soup)\n",
    "store_things(links, 'wikipedia_collected_urls.json')\n",
    "\n",
    "# For tracking visited pages\n",
    "visited_links = set()\n",
    "\n",
    "# Mark the starting link as visited\n",
    "visited_links.add(wiki_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4925bea3-bbbd-448e-8568-3adac1c97b46",
   "metadata": {},
   "source": [
    "Συλλογή παραγράφων από κάθε σελίδα. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf1a21c-496e-4ea1-8c9b-78f12d095586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Paragraphs saved from starting page: <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making. Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains. In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively.\n",
      "\n",
      "The data is necessary as inputs to the analysis, which is specified based upon the requirements of those directing the analytics (or customers, who will use the finished product of the analysis). The general type of entity upon which the data will be collected is referred to as an experimental unit (e.g., a person or population of people). Specific variables regarding a population (e.g., age and income) may be specified and obtained.  Data may be numerical or categorical (i.e., a text label for numbers).\n",
      "\n",
      "Mathematical formulas or models (also known as algorithms), may be applied to the data in order to identify relationships among the variables; for example, using correlation or causation. In general terms, models may be developed to evaluate a specific variable based on other variable(s) contained within the dataset, with some residual error depending on the implemented model's accuracy (e.g., Data = Model + Error).\n",
      "\n",
      "A data product is a computer application that takes data inputs and generates outputs, feeding them back into the environment. It may be based on a model or algorithm. For instance, an application that analyzes data about customer purchase history, and uses the results to recommend other purchases the customer might enjoy.\n",
      "\n",
      "When determining how to communicate the results, the analyst may consider implementing a variety of data visualization techniques to help communicate the message more clearly and efficiently to the audience. Data visualization uses information displays (graphics such as, tables and charts) to help communicate key messages contained in the data. Tables are a valuable tool by enabling the ability of a user to query and focus on specific numbers; while charts (e.g., bar charts or line charts), may help explain the quantitative messages contained in the data.\n",
      "\n",
      "Stephen Few described eight types of quantitative messages that users may attempt to understand or communicate from a set of data and the associated graphs used to help communicate the message. Customers specifying requirements and analysts performing the data analysis may consider these messages during the course of the process.\n",
      "\n",
      "Analysts may use robust statistical measurements to solve certain analytical problems. Hypothesis testing is used when a particular hypothesis about the true state of affairs is made by the analyst and data is gathered to determine whether that state of affairs is true or false. For example, the hypothesis might be that \"Unemployment has no effect on inflation\", which relates to an economics concept called the Phillips Curve. Hypothesis testing involves considering the likelihood of Type I and type II errors, which relate to whether the data supports accepting or rejecting the hypothesis.\n",
      "\n",
      "Regression analysis may be used when the analyst is trying to determine the extent to which independent variable X affects dependent variable Y (e.g., \"To what extent do changes in the unemployment rate (X) affect the inflation rate (Y)?\"). This is an attempt to model or fit an equation line or curve to the data, such that Y is a function of X.\n",
      "\n",
      "Users may have particular data points of interest within a data set, as opposed to the general messaging outlined above. Such low-level user analytic activities are presented in the following table. The taxonomy can also be organized by three poles of activities: retrieving values, finding data points, and arranging data points.\n",
      "\n",
      "As another example, the auditor of a public company must arrive at a formal opinion on whether financial statements of publicly traded corporations are \"fairly stated, in all material respects\". This requires extensive analysis of factual data and evidence to support their opinion. When making the leap from facts to opinions, there is always the possibility that the opinion is erroneous.\n",
      "\n",
      "Analysts may be trained specifically to be aware of these biases and how to overcome them. In his book Psychology of Intelligence Analysis, retired CIA analyst Richards Heuer wrote that analysts should clearly delineate their assumptions and chains of inference and specify the degree and source of the uncertainty involved in the conclusions. He emphasized procedures to help surface and debate alternative points of view.\n",
      "\n",
      "Analysts may also analyze data under different assumptions or scenario. For example, when analysts perform financial statement analysis, they will often recast the financial statements under different assumptions to help arrive at an estimate of future cash flow, which they then discount to present value based on some interest rate, to determine the valuation of the company or its stock. Similarly, the CBO analyzes the effects of various policy options on the government's revenue, outlays and deficits, creating alternative future scenarios for key measures.\n",
      "\n",
      "A data analytics approach can be used in order to predict energy consumption in buildings. The different steps of the data analysis process are carried out in order to realise smart buildings, where the building management and control operations including heating, ventilation, air conditioning, lighting and security are realised automatically by miming the needs of the building users and optimising resources like energy and time.\n",
      "\n",
      "Analytics is the \"extensive use of data, statistical and quantitative analysis, explanatory and predictive models, and fact-based management to drive decisions and actions.\" It is a subset of business intelligence, which is a set of technologies and processes that uses data to understand and analyze business performance to drive decision-making .\n",
      "\n",
      "In education, most educators have access to a data system for the purpose of analyzing student data. These data systems present data to educators in an over-the-counter data format (embedding labels, supplemental documentation, and a help system and making key package/display and content decisions) to improve the accuracy of educators' data analyses.\n",
      "\n",
      "One should check the success of the randomization procedure, for instance by checking whether background and substantive variables are equally distributed within and across groups. If the study did not need or use a randomization procedure, one should check the success of the non-random sampling, for instance by checking whether all subgroups of the population of interest are represented in sample.Other possible data distortions that should be checked are:\n",
      "\n",
      "In any report or article, the structure of the sample must be accurately described. It is especially important to exactly determine the structure of the sample (and specifically the size of the subgroups) when subgroup analyses will be performed during the main analysis phase.The characteristics of the data sample can be assessed by looking at:\n",
      "\n",
      "During the final stage, the findings of the initial data analysis are documented, and necessary, preferable, and possible corrective actions are taken.Also, the original plan for the main data analyses can and should be specified in more detail or rewritten. In order to do this, several decisions about the main data analyses can and should be made:\n",
      "\n",
      "In the main analysis phase, either an exploratory or confirmatory approach can be adopted. Usually the approach is decided before data is collected. In an exploratory analysis no clear hypothesis is stated before analysing the data, and the data is searched for models that describe the data well. In a confirmatory analysis clear hypotheses about the data are tested.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_paragraphs(soup, visited_paragraphs, link):\n",
    "    # Stores paragraphs\n",
    "    paragraphs = []  \n",
    "\n",
    "    # Remove the content from superscripts and references\n",
    "    for sup in soup.find_all(['sup', 'reflist']):\n",
    "        sup.decompose()  \n",
    "\n",
    "    # Find all paragraph tags \n",
    "    for p in soup.find_all('p'):\n",
    "        # Extract text from each paragraph\n",
    "        text = p.get_text()  \n",
    "        \n",
    "        # Remove empty paragraphs and those containing the term 'displaystyle' to avoid mathematical functions\n",
    "        if text and 'displaystyle' not in text.lower():\n",
    "            # Calculate the number of words in the paragraph\n",
    "            word_count = len(text.split())  \n",
    "            \n",
    "            # Include paragraphs with word count between 50 and 100 and avoid duplicates\n",
    "            if 50 <= word_count <= 100 and text not in visited_paragraphs:\n",
    "                # Store paragraph with source link\n",
    "                paragraphs.append({'text': text, 'link': link}) \n",
    "                # Mark the paragraph as visited to avoid repetition\n",
    "                visited_paragraphs.add(text)  \n",
    "                        \n",
    "    # Return filtered paragraphs         \n",
    "    return paragraphs  \n",
    "\n",
    "\n",
    "# For tracking visited paragraphs\n",
    "visited_paragraphs = set()\n",
    "\n",
    "# Collect paragraphs from starting page\n",
    "original_paragraphs = get_paragraphs(soup, visited_paragraphs, wiki_url)\n",
    "\n",
    "display(Markdown(\"Paragraphs saved from starting page: <br>\"))\n",
    "for paragraph in original_paragraphs:\n",
    "    print(f\"{paragraph['text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ba030-174f-4a75-8510-f9f8391109db",
   "metadata": {},
   "source": [
    "# 2. Προεπεξεργασία κειμένου (Text Procissing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb7b9ad-490e-4ed1-8e61-194977a3656c",
   "metadata": {},
   "source": [
    "Διαμόρφωση κειμένου μετά από αφαίρεση διακόπτουσων λέξεων, ειδικών χαρακτήρων και λημματοποίση όρων. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a00cbde-eb35-40a8-8276-2e2ee890422d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Processed paragraphs from starting page: <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data', 'analysis', 'process', 'inspecting', 'cleansing', 'transforming', 'modeling', 'data', 'goal', 'discovering', 'useful', 'information', 'informing', 'conclusion', 'supporting', 'data', 'analysis', 'multiple', 'facet', 'approach', 'encompassing', 'diverse', 'technique', 'variety', 'name', 'used', 'different', 'business', 'science', 'social', 'science', 'domain', 'today', 'business', 'world', 'data', 'analysis', 'play', 'role', 'making', 'decision', 'scientific', 'helping', 'business', 'operate', 'effectively']\n",
      "\n",
      "['data', 'necessary', 'input', 'analysis', 'specified', 'based', 'upon', 'requirement', 'directing', 'analytics', 'customer', 'use', 'finished', 'product', 'analysis', 'general', 'type', 'entity', 'upon', 'data', 'collected', 'referred', 'experimental', 'unit', 'person', 'population', 'people', 'specific', 'variable', 'regarding', 'population', 'age', 'income', 'may', 'specified', 'obtained', 'data', 'may', 'numerical', 'categorical', 'text', 'label', 'number']\n",
      "\n",
      "['mathematical', 'formula', 'model', 'also', 'known', 'algorithm', 'may', 'applied', 'data', 'order', 'identify', 'relationship', 'among', 'variable', 'example', 'using', 'correlation', 'causation', 'general', 'term', 'model', 'may', 'developed', 'evaluate', 'specific', 'variable', 'based', 'variable', 'contained', 'within', 'dataset', 'residual', 'error', 'depending', 'implemented', 'model', 'accuracy', 'data', 'model', 'error']\n",
      "\n",
      "['data', 'product', 'computer', 'application', 'take', 'data', 'input', 'generates', 'output', 'feeding', 'back', 'environment', 'may', 'based', 'model', 'algorithm', 'instance', 'application', 'analyzes', 'data', 'customer', 'purchase', 'history', 'us', 'result', 'recommend', 'purchase', 'customer', 'might', 'enjoy']\n",
      "\n",
      "['determining', 'communicate', 'result', 'analyst', 'may', 'consider', 'implementing', 'variety', 'data', 'visualization', 'technique', 'help', 'communicate', 'message', 'clearly', 'efficiently', 'audience', 'data', 'visualization', 'us', 'information', 'display', 'graphic', 'table', 'chart', 'help', 'communicate', 'key', 'message', 'contained', 'data', 'table', 'valuable', 'tool', 'enabling', 'ability', 'user', 'query', 'focus', 'specific', 'number', 'chart', 'bar', 'chart', 'line', 'chart', 'may', 'help', 'explain', 'quantitative', 'message', 'contained', 'data']\n",
      "\n",
      "['stephen', 'described', 'eight', 'type', 'quantitative', 'message', 'user', 'may', 'attempt', 'understand', 'communicate', 'set', 'data', 'associated', 'graph', 'used', 'help', 'communicate', 'message', 'customer', 'specifying', 'requirement', 'analyst', 'performing', 'data', 'analysis', 'may', 'consider', 'message', 'course', 'process']\n",
      "\n",
      "['analyst', 'may', 'use', 'robust', 'statistical', 'measurement', 'solve', 'certain', 'analytical', 'problem', 'hypothesis', 'testing', 'used', 'particular', 'hypothesis', 'true', 'state', 'affair', 'made', 'analyst', 'data', 'gathered', 'determine', 'whether', 'state', 'affair', 'true', 'false', 'example', 'hypothesis', 'might', 'unemployment', 'effect', 'inflation', 'relates', 'economics', 'concept', 'called', 'phillips', 'curve', 'hypothesis', 'testing', 'involves', 'considering', 'likelihood', 'type', 'type', 'ii', 'error', 'relate', 'whether', 'data', 'support', 'accepting', 'rejecting', 'hypothesis']\n",
      "\n",
      "['regression', 'analysis', 'may', 'used', 'analyst', 'trying', 'determine', 'extent', 'independent', 'variable', 'x', 'affect', 'dependent', 'variable', 'extent', 'change', 'unemployment', 'rate', 'x', 'affect', 'inflation', 'rate', 'attempt', 'model', 'fit', 'equation', 'line', 'curve', 'data', 'function', 'x']\n",
      "\n",
      "['user', 'may', 'particular', 'data', 'point', 'interest', 'within', 'data', 'set', 'opposed', 'general', 'messaging', 'outlined', 'user', 'analytic', 'activity', 'presented', 'following', 'table', 'taxonomy', 'also', 'organized', 'three', 'pole', 'activity', 'retrieving', 'value', 'finding', 'data', 'point', 'arranging', 'data', 'point']\n",
      "\n",
      "['another', 'example', 'auditor', 'public', 'company', 'must', 'arrive', 'formal', 'opinion', 'whether', 'financial', 'statement', 'publicly', 'traded', 'corporation', 'fairly', 'stated', 'material', 'respect', 'requires', 'extensive', 'analysis', 'factual', 'data', 'evidence', 'support', 'opinion', 'making', 'leap', 'fact', 'opinion', 'always', 'possibility', 'opinion', 'erroneous']\n",
      "\n",
      "['analyst', 'may', 'trained', 'specifically', 'aware', 'bias', 'overcome', 'book', 'psychology', 'intelligence', 'analysis', 'retired', 'cia', 'analyst', 'richards', 'heuer', 'wrote', 'analyst', 'clearly', 'delineate', 'assumption', 'chain', 'inference', 'specify', 'degree', 'source', 'uncertainty', 'involved', 'conclusion', 'emphasized', 'procedure', 'help', 'surface', 'debate', 'alternative', 'point', 'view']\n",
      "\n",
      "['analyst', 'may', 'also', 'analyze', 'data', 'different', 'assumption', 'scenario', 'example', 'analyst', 'perform', 'financial', 'statement', 'analysis', 'often', 'recast', 'financial', 'statement', 'different', 'assumption', 'help', 'arrive', 'estimate', 'future', 'cash', 'flow', 'discount', 'present', 'value', 'based', 'interest', 'rate', 'determine', 'valuation', 'company', 'stock', 'similarly', 'cbo', 'analyzes', 'effect', 'various', 'policy', 'option', 'government', 'revenue', 'outlay', 'deficit', 'creating', 'alternative', 'future', 'scenario', 'key', 'measure']\n",
      "\n",
      "['data', 'analytics', 'approach', 'used', 'order', 'predict', 'energy', 'consumption', 'building', 'different', 'step', 'data', 'analysis', 'process', 'carried', 'order', 'realise', 'smart', 'building', 'building', 'management', 'control', 'operation', 'including', 'heating', 'ventilation', 'air', 'conditioning', 'lighting', 'security', 'realised', 'automatically', 'miming', 'need', 'building', 'user', 'optimising', 'resource', 'like', 'energy', 'time']\n",
      "\n",
      "['analytics', 'extensive', 'use', 'data', 'statistical', 'quantitative', 'analysis', 'explanatory', 'predictive', 'model', 'management', 'drive', 'decision', 'action', 'subset', 'business', 'intelligence', 'set', 'technology', 'process', 'us', 'data', 'understand', 'analyze', 'business', 'performance', 'drive']\n",
      "\n",
      "['education', 'educator', 'access', 'data', 'system', 'purpose', 'analyzing', 'student', 'data', 'data', 'system', 'present', 'data', 'educator', 'data', 'format', 'embedding', 'label', 'supplemental', 'documentation', 'help', 'system', 'making', 'key', 'content', 'decision', 'improve', 'accuracy', 'educator', 'data', 'analysis']\n",
      "\n",
      "['one', 'check', 'success', 'randomization', 'procedure', 'instance', 'checking', 'whether', 'background', 'substantive', 'variable', 'equally', 'distributed', 'within', 'across', 'group', 'study', 'need', 'use', 'randomization', 'procedure', 'one', 'check', 'success', 'sampling', 'instance', 'checking', 'whether', 'subgroup', 'population', 'interest', 'represented', 'possible', 'data', 'distortion', 'checked']\n",
      "\n",
      "['report', 'article', 'structure', 'sample', 'must', 'accurately', 'described', 'especially', 'important', 'exactly', 'determine', 'structure', 'sample', 'specifically', 'size', 'subgroup', 'subgroup', 'analysis', 'performed', 'main', 'analysis', 'characteristic', 'data', 'sample', 'assessed', 'looking']\n",
      "\n",
      "['final', 'stage', 'finding', 'initial', 'data', 'analysis', 'documented', 'necessary', 'preferable', 'possible', 'corrective', 'action', 'original', 'plan', 'main', 'data', 'analysis', 'specified', 'detail', 'rewritten', 'order', 'several', 'decision', 'main', 'data', 'analysis', 'made']\n",
      "\n",
      "['main', 'analysis', 'phase', 'either', 'exploratory', 'confirmatory', 'approach', 'adopted', 'usually', 'approach', 'decided', 'data', 'collected', 'exploratory', 'analysis', 'clear', 'hypothesis', 'stated', 'analysing', 'data', 'data', 'searched', 'model', 'describe', 'data', 'well', 'confirmatory', 'analysis', 'clear', 'hypothesis', 'data', 'tested']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    # Tokenize text into individual words and convert to lowercase for better search results\n",
    "    tokens = nltk.word_tokenize(text.lower())\n",
    "\n",
    "    # List to store cleaned tokens\n",
    "    cleaned_tokens = []\n",
    "\n",
    "    # Remove punctuation and non alphanumeric tokens\n",
    "    for token in tokens:\n",
    "        if token not in string.punctuation and token.isalnum():\n",
    "            cleaned_tokens.append(token)\n",
    "\n",
    "    # List to store tokens after stopword removal\n",
    "    filtered_tokens = []\n",
    "\n",
    "    # Remove stopwords from the tokenized text\n",
    "    for token in cleaned_tokens:\n",
    "        if token not in stop_words:\n",
    "            filtered_tokens.append(token)\n",
    "\n",
    "    # Initialize a list to store lemmatized tokens\n",
    "    lemmatized_tokens = []\n",
    "\n",
    "    # Lemmatize the tokens\n",
    "    for token in filtered_tokens:\n",
    "        lemmatized_tokens.append(lemmatizer.lemmatize(token))\n",
    "\n",
    "    # Return processed tokens\n",
    "    return lemmatized_tokens\n",
    "\n",
    "cleaned_paragraphs = []\n",
    "\n",
    "# Clean the collected paragraphs using text preprocessing\n",
    "for paragraph in original_paragraphs:\n",
    "    #clean_paragraph = ' '.join(clean_text(paragraph))\n",
    "    clean_paragraph = clean_text(paragraph['text'])\n",
    "    cleaned_paragraphs.append({'tokens': clean_paragraph, 'link': paragraph['link']})\n",
    "\n",
    "display(Markdown(\"Processed paragraphs from starting page: <br>\"))\n",
    "for paragraph in cleaned_paragraphs:\n",
    "    print(f\"{paragraph['tokens']}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0fcd5-5937-4b52-8588-1c8e65ee8f2f",
   "metadata": {},
   "source": [
    "Ληψη και εξαγωγή παραγράφων από κάθε σύνδεσμο. \n",
    "Λαμβάνεται το περιεχόμενο από έναν σύνδεσμο και εξάγονται οι παράγραφοι, σε περίπτωση που δεν έχουν ήδη καταχωρηθεί."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8110dc8-7ea2-4676-824b-3ad28e6a00d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Scraping paragraphs from each link <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8044ce7ca1e542abbaa1ab08fe638a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=70)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def paragraphs_within_links(link, visited_links, visited_paragraphs):\n",
    "    # Skip the link and return an empty list if it has already been processed\n",
    "    if link in visited_links:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        # Send get request to link and raise error if the request was unsuccessful\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the pages content\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Mark current link as visited\n",
    "        visited_links.add(link)\n",
    "        \n",
    "        # Extract and return paragraphs from the page\n",
    "        return get_paragraphs(soup, visited_paragraphs, link)\n",
    "        \n",
    "    # Exception for request errors\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error retrieving links: {e}\")\n",
    "        # Return an empty list if there is an error\n",
    "        return []  \n",
    "\n",
    "display(Markdown(\"Scraping paragraphs from each link <br>\"))\n",
    "progress = widgets.IntProgress(\n",
    "    value = 0,\n",
    "    min = 0,\n",
    "    max = len(links)\n",
    ")\n",
    "\n",
    "display(progress)\n",
    "\n",
    "# Get paragraphs from each link and avoid re visiting links\n",
    "for i, link in enumerate(links):\n",
    "    # Get paragraphs from current link\n",
    "    link_paragraphs = paragraphs_within_links(link, visited_links, visited_paragraphs)\n",
    "\n",
    "    # Extend list of original paragraphs adding the new ones\n",
    "    original_paragraphs.extend(link_paragraphs)\n",
    "\n",
    "    # Clean and store paragraphs from current link\n",
    "    for paragraph in link_paragraphs:\n",
    "        #clean_paragraph = ' '.join(clean_text(paragraph))\n",
    "        clean_paragraph = clean_text(paragraph['text'])\n",
    "        cleaned_paragraphs.append({'tokens': clean_paragraph, 'link': paragraph['link']})\n",
    "\n",
    "    # Update progress bar\n",
    "    progress.value = i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27794df3-965b-4c06-93e7-569cf7a90cbb",
   "metadata": {},
   "source": [
    "Αποθήκευση επιλεγμένων παραγράφων στην αρχική και επεξεργασμένη μορφή τους."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8a0e48-8cac-49d7-8cfe-9801585e438a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How some of the paragraphs are saved: <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: Data analysis is the process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making. Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains. In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively.\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: The data is necessary as inputs to the analysis, which is specified based upon the requirements of those directing the analytics (or customers, who will use the finished product of the analysis). The general type of entity upon which the data will be collected is referred to as an experimental unit (e.g., a person or population of people). Specific variables regarding a population (e.g., age and income) may be specified and obtained.  Data may be numerical or categorical (i.e., a text label for numbers).\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: Mathematical formulas or models (also known as algorithms), may be applied to the data in order to identify relationships among the variables; for example, using correlation or causation. In general terms, models may be developed to evaluate a specific variable based on other variable(s) contained within the dataset, with some residual error depending on the implemented model's accuracy (e.g., Data = Model + Error).\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: A data product is a computer application that takes data inputs and generates outputs, feeding them back into the environment. It may be based on a model or algorithm. For instance, an application that analyzes data about customer purchase history, and uses the results to recommend other purchases the customer might enjoy.\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: When determining how to communicate the results, the analyst may consider implementing a variety of data visualization techniques to help communicate the message more clearly and efficiently to the audience. Data visualization uses information displays (graphics such as, tables and charts) to help communicate key messages contained in the data. Tables are a valuable tool by enabling the ability of a user to query and focus on specific numbers; while charts (e.g., bar charts or line charts), may help explain the quantitative messages contained in the data.\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: Stephen Few described eight types of quantitative messages that users may attempt to understand or communicate from a set of data and the associated graphs used to help communicate the message. Customers specifying requirements and analysts performing the data analysis may consider these messages during the course of the process.\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: Analysts may use robust statistical measurements to solve certain analytical problems. Hypothesis testing is used when a particular hypothesis about the true state of affairs is made by the analyst and data is gathered to determine whether that state of affairs is true or false. For example, the hypothesis might be that \"Unemployment has no effect on inflation\", which relates to an economics concept called the Phillips Curve. Hypothesis testing involves considering the likelihood of Type I and type II errors, which relate to whether the data supports accepting or rejecting the hypothesis.\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: Regression analysis may be used when the analyst is trying to determine the extent to which independent variable X affects dependent variable Y (e.g., \"To what extent do changes in the unemployment rate (X) affect the inflation rate (Y)?\"). This is an attempt to model or fit an equation line or curve to the data, such that Y is a function of X.\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: Users may have particular data points of interest within a data set, as opposed to the general messaging outlined above. Such low-level user analytic activities are presented in the following table. The taxonomy can also be organized by three poles of activities: retrieving values, finding data points, and arranging data points.\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "text: As another example, the auditor of a public company must arrive at a formal opinion on whether financial statements of publicly traded corporations are \"fairly stated, in all material respects\". This requires extensive analysis of factual data and evidence to support their opinion. When making the leap from facts to opinions, there is always the possibility that the opinion is erroneous.\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "store_things(original_paragraphs, 'wikipedia_paragraphs.json')\n",
    "store_things(cleaned_paragraphs, 'wikipedia_paragraphs_cleaned.json')\n",
    "\n",
    "display(Markdown(\"How some of the paragraphs are saved: <br>\"))\n",
    "for paragraph in original_paragraphs[:10]:\n",
    "    text = paragraph['text']\n",
    "    link = paragraph['link']\n",
    "\n",
    "    print(f\"text: {text}\")\n",
    "    print(f\"link: {link}\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da15bc76-a952-4880-b64b-2700f1faa693",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How some of the processed and tokenised paragraphs are saved: <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['data', 'analysis', 'process', 'inspecting', 'cleansing', 'transforming', 'modeling', 'data', 'goal', 'discovering', 'useful', 'information', 'informing', 'conclusion', 'supporting', 'data', 'analysis', 'multiple', 'facet', 'approach', 'encompassing', 'diverse', 'technique', 'variety', 'name', 'used', 'different', 'business', 'science', 'social', 'science', 'domain', 'today', 'business', 'world', 'data', 'analysis', 'play', 'role', 'making', 'decision', 'scientific', 'helping', 'business', 'operate', 'effectively']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['data', 'necessary', 'input', 'analysis', 'specified', 'based', 'upon', 'requirement', 'directing', 'analytics', 'customer', 'use', 'finished', 'product', 'analysis', 'general', 'type', 'entity', 'upon', 'data', 'collected', 'referred', 'experimental', 'unit', 'person', 'population', 'people', 'specific', 'variable', 'regarding', 'population', 'age', 'income', 'may', 'specified', 'obtained', 'data', 'may', 'numerical', 'categorical', 'text', 'label', 'number']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['mathematical', 'formula', 'model', 'also', 'known', 'algorithm', 'may', 'applied', 'data', 'order', 'identify', 'relationship', 'among', 'variable', 'example', 'using', 'correlation', 'causation', 'general', 'term', 'model', 'may', 'developed', 'evaluate', 'specific', 'variable', 'based', 'variable', 'contained', 'within', 'dataset', 'residual', 'error', 'depending', 'implemented', 'model', 'accuracy', 'data', 'model', 'error']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['data', 'product', 'computer', 'application', 'take', 'data', 'input', 'generates', 'output', 'feeding', 'back', 'environment', 'may', 'based', 'model', 'algorithm', 'instance', 'application', 'analyzes', 'data', 'customer', 'purchase', 'history', 'us', 'result', 'recommend', 'purchase', 'customer', 'might', 'enjoy']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['determining', 'communicate', 'result', 'analyst', 'may', 'consider', 'implementing', 'variety', 'data', 'visualization', 'technique', 'help', 'communicate', 'message', 'clearly', 'efficiently', 'audience', 'data', 'visualization', 'us', 'information', 'display', 'graphic', 'table', 'chart', 'help', 'communicate', 'key', 'message', 'contained', 'data', 'table', 'valuable', 'tool', 'enabling', 'ability', 'user', 'query', 'focus', 'specific', 'number', 'chart', 'bar', 'chart', 'line', 'chart', 'may', 'help', 'explain', 'quantitative', 'message', 'contained', 'data']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['stephen', 'described', 'eight', 'type', 'quantitative', 'message', 'user', 'may', 'attempt', 'understand', 'communicate', 'set', 'data', 'associated', 'graph', 'used', 'help', 'communicate', 'message', 'customer', 'specifying', 'requirement', 'analyst', 'performing', 'data', 'analysis', 'may', 'consider', 'message', 'course', 'process']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['analyst', 'may', 'use', 'robust', 'statistical', 'measurement', 'solve', 'certain', 'analytical', 'problem', 'hypothesis', 'testing', 'used', 'particular', 'hypothesis', 'true', 'state', 'affair', 'made', 'analyst', 'data', 'gathered', 'determine', 'whether', 'state', 'affair', 'true', 'false', 'example', 'hypothesis', 'might', 'unemployment', 'effect', 'inflation', 'relates', 'economics', 'concept', 'called', 'phillips', 'curve', 'hypothesis', 'testing', 'involves', 'considering', 'likelihood', 'type', 'type', 'ii', 'error', 'relate', 'whether', 'data', 'support', 'accepting', 'rejecting', 'hypothesis']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['regression', 'analysis', 'may', 'used', 'analyst', 'trying', 'determine', 'extent', 'independent', 'variable', 'x', 'affect', 'dependent', 'variable', 'extent', 'change', 'unemployment', 'rate', 'x', 'affect', 'inflation', 'rate', 'attempt', 'model', 'fit', 'equation', 'line', 'curve', 'data', 'function', 'x']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['user', 'may', 'particular', 'data', 'point', 'interest', 'within', 'data', 'set', 'opposed', 'general', 'messaging', 'outlined', 'user', 'analytic', 'activity', 'presented', 'following', 'table', 'taxonomy', 'also', 'organized', 'three', 'pole', 'activity', 'retrieving', 'value', 'finding', 'data', 'point', 'arranging', 'data', 'point']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n",
      "tokens: ['another', 'example', 'auditor', 'public', 'company', 'must', 'arrive', 'formal', 'opinion', 'whether', 'financial', 'statement', 'publicly', 'traded', 'corporation', 'fairly', 'stated', 'material', 'respect', 'requires', 'extensive', 'analysis', 'factual', 'data', 'evidence', 'support', 'opinion', 'making', 'leap', 'fact', 'opinion', 'always', 'possibility', 'opinion', 'erroneous']\n",
      "\n",
      "link: https://en.wikipedia.org/wiki/Data_analysis\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"How some of the processed and tokenised paragraphs are saved: <br>\"))\n",
    "for paragraph in cleaned_paragraphs[:10]:\n",
    "    tokens = paragraph['tokens']\n",
    "    link = paragraph['link']\n",
    "\n",
    "    print(f\"tokens: {tokens}\\n\")\n",
    "    print(f\"link: {link}\\n\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c66a7f-8e48-4b8e-a5f5-ef32da94d613",
   "metadata": {},
   "source": [
    "# 3. Ευρετήριο (Indexing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505bb83-33e1-44b5-b1d1-92cfd0dc153d",
   "metadata": {},
   "source": [
    "Δημιουργία ανεστραμμένου ευρετήριου από τις επιλεγμένες και επεξεργασμένες παραγράφους και αποθήκευσή του σε αρχείο JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91790f45-59fc-4315-acd1-c2e8c24f8dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Inverted Index <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Paragraph ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data</td>\n",
       "      <td>{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 532, 31, 38, 43, 44, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 74, 75, 77, 79, 80, 81, 82, 83, 86, 87, 88, 89, 526, 92, 93, 95, 97, 101, 102, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 134, 135, 136, 142, 143, 144, 145, 146, 149, 150, 151, 159, 161, 163, ...}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analysis</td>\n",
       "      <td>{0, 1, 514, 5, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 528, 529, 27, 35, 36, 40, 44, 59, 61, 63, 65, 66, 67, 75, 77, 78, 82, 92, 113, 116, 120, 121, 122, 123, 124, 127, 134, 135, 137, 142, 143, 145, 146, 152, 168, 172, 173, 178, 180, 203, 212, 255, 297, 299, 304, 318, 319, 323, 340, 350, 360, 363, 387, 400, 401, 410, 429, 432, 435, 449, 454, 472, 475, 487, 510}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>process</td>\n",
       "      <td>{0, 512, 132, 5, 516, 265, 12, 13, 268, 269, 270, 271, 273, 275, 276, 21, 277, 23, 278, 279, 26, 27, 280, 282, 31, 419, 429, 56, 326, 333, 80, 339, 468, 87, 347, 350, 479, 480, 481, 401, 486, 402, 377}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inspecting</td>\n",
       "      <td>{0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cleansing</td>\n",
       "      <td>{0}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4958</th>\n",
       "      <td>simulated</td>\n",
       "      <td>{532}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>instability</td>\n",
       "      <td>{532}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>implicit</td>\n",
       "      <td>{533}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>demanding</td>\n",
       "      <td>{533}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>unstable</td>\n",
       "      <td>{533}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4963 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Token  \\\n",
       "0            data   \n",
       "1        analysis   \n",
       "2         process   \n",
       "3      inspecting   \n",
       "4       cleansing   \n",
       "...           ...   \n",
       "4958    simulated   \n",
       "4959  instability   \n",
       "4960     implicit   \n",
       "4961    demanding   \n",
       "4962     unstable   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                       Paragraph ID  \n",
       "0     {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 532, 31, 38, 43, 44, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 74, 75, 77, 79, 80, 81, 82, 83, 86, 87, 88, 89, 526, 92, 93, 95, 97, 101, 102, 108, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 134, 135, 136, 142, 143, 144, 145, 146, 149, 150, 151, 159, 161, 163, ...}  \n",
       "1                                                                     {0, 1, 514, 5, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 528, 529, 27, 35, 36, 40, 44, 59, 61, 63, 65, 66, 67, 75, 77, 78, 82, 92, 113, 116, 120, 121, 122, 123, 124, 127, 134, 135, 137, 142, 143, 145, 146, 152, 168, 172, 173, 178, 180, 203, 212, 255, 297, 299, 304, 318, 319, 323, 340, 350, 360, 363, 387, 400, 401, 410, 429, 432, 435, 449, 454, 472, 475, 487, 510}  \n",
       "2                                                                                                                                                                                                                                         {0, 512, 132, 5, 516, 265, 12, 13, 268, 269, 270, 271, 273, 275, 276, 21, 277, 23, 278, 279, 26, 27, 280, 282, 31, 419, 429, 56, 326, 333, 80, 339, 468, 87, 347, 350, 479, 480, 481, 401, 486, 402, 377}  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                               {0}  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                               {0}  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                             ...  \n",
       "4958                                                                                                                                                                                                                                                                                                                                                                                                                                          {532}  \n",
       "4959                                                                                                                                                                                                                                                                                                                                                                                                                                          {532}  \n",
       "4960                                                                                                                                                                                                                                                                                                                                                                                                                                          {533}  \n",
       "4961                                                                                                                                                                                                                                                                                                                                                                                                                                          {533}  \n",
       "4962                                                                                                                                                                                                                                                                                                                                                                                                                                          {533}  \n",
       "\n",
       "[4963 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_inverted_index(cleaned_paragraphs):\n",
    "    inverted_index = defaultdict(set)\n",
    "    \n",
    "    # Look through each tokenized paragraph and assign a unique ID\n",
    "    for paragraph_id, paragraph in enumerate(cleaned_paragraphs):\n",
    "        # Get the tokens from each paragraph\n",
    "        tokens = paragraph['tokens']\n",
    "        \n",
    "        # Add each token to the inverted index with its paragraph ID\n",
    "        for token in tokens:\n",
    "            inverted_index[token].add(paragraph_id)\n",
    "             \n",
    "    return inverted_index\n",
    "\n",
    "\n",
    "def store_inverted_index(inverted_index):\n",
    "    try:\n",
    "        # Convert sets to lists to save in JSON file\n",
    "        serializable_index = {}\n",
    "        for term, paragraph_ids in inverted_index.items():\n",
    "            serializable_index[term] = list(paragraph_ids)\n",
    "\n",
    "        # Save the converted index to the file\n",
    "        with open('inverted_index.json', 'w') as file:\n",
    "            json.dump(serializable_index, file, indent = 4)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"____Error saving inverted index____\\n{e}\")\n",
    "\n",
    "# Build inverted index from cleaned paragraphs\n",
    "inverted_index = build_inverted_index(cleaned_paragraphs)\n",
    "\n",
    "# Store generated inverted index\n",
    "store_inverted_index(inverted_index)\n",
    "\n",
    "\n",
    "# Convert the inverted index into a list of token and paragraph IDs\n",
    "index = list(inverted_index.items())\n",
    "# Create a data frame from the inverted index\n",
    "inverted_df = pd.DataFrame(index, columns = ['Token', 'Paragraph ID'])\n",
    "# Display the inverted index\n",
    "display(Markdown(\"Inverted Index <br>\"))\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(inverted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861c544-9ba8-4163-82e5-3dbdb13b64f7",
   "metadata": {},
   "source": [
    "# 4. Μηχανή αναζήτησης (Search Engine) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334124ca-2280-4e33-b913-df9c7ea0c99a",
   "metadata": {},
   "source": [
    "α) Επεξεργασία ερωτήματος (Query Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9990651-605c-46be-817e-5b2906320007",
   "metadata": {},
   "source": [
    "Μετατροπή ερωτήματος από infix σε postfix μορφή και ό,τι δεν συμπεριλαμβάνεται στην άλγεβρα Boole, γίνεται lemmatized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f4cbe77-abda-4b29-b49c-03b85640d1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Example of how queries are processed <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original queryn (Infix):   ( data AND analysis ) OR NOT science\n",
      "Converted query (Postfix): ['data', 'analysis', 'AND', 'science', 'NOT', 'OR']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def infix_to_postfix(query):\n",
    "    # Define operator precedence (higher value means higher precedence)\n",
    "    precedence = {'NOT': 3, 'AND': 2, 'OR': 1}\n",
    "    \n",
    "    # Output and operator stack\n",
    "    output = []  \n",
    "    operators = []\n",
    "\n",
    "    # Split the query into tokens\n",
    "    tokens = query.split()\n",
    "    \n",
    "    # Process each token\n",
    "    for token in tokens:\n",
    "        # If the token is an operator handle based on precedence\n",
    "        if token in precedence:\n",
    "            # Pop operators with higher or equal precedence from the stack\n",
    "            while operators and precedence.get(operators[-1], 0) >= precedence[token]:\n",
    "                output.append(operators.pop())\n",
    "            # Push the current operator to the stack\n",
    "            operators.append(token)  \n",
    "\n",
    "        # If the token is left parenthesis push it onto the stack\n",
    "        elif token == '(':\n",
    "            operators.append(token)\n",
    "\n",
    "        # If the token is right parenthesis pop until the matching left parenthesis\n",
    "        elif token == ')':\n",
    "            while operators and operators[-1] != '(':\n",
    "                output.append(operators.pop())\n",
    "            # Remove left parenthesis from stack\n",
    "            operators.pop()  \n",
    "\n",
    "        # If the token is a word or other charachters \n",
    "        else:\n",
    "            # Lemmatize and turn into lowecase\n",
    "            token = lemmatizer.lemmatize(token.lower())\n",
    "            # Rremove word or number charachters\n",
    "            if token.isalnum():\n",
    "                output.append(token)\n",
    "\n",
    "    # Pop any remaining operators from the stack and append them to output\n",
    "    while operators:\n",
    "        output.append(operators.pop())\n",
    "\n",
    "    # Return the query in postfix notation\n",
    "    return output\n",
    "\n",
    "\n",
    "display(Markdown(\"Example of how queries are processed <br>\"))\n",
    "test_query = \"( data AND analysis ) OR NOT science\"\n",
    "# Convert the query from infix to postfix notation\n",
    "test_postfix_query = infix_to_postfix(test_query)\n",
    "\n",
    "# Print the original query and its postfix conversion\n",
    "print(f\"Original queryn (Infix):   {test_query}\")\n",
    "print(f\"Converted query (Postfix): {(test_postfix_query)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d084d88c-7164-40a6-be17-1e40ef8f12d7",
   "metadata": {},
   "source": [
    "Συλλογή παραγράφων με βάση το ήδη επεξεργασμένο ερώτημα. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0c1eae0-0af5-4e9a-85c2-d8fc4895716d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Matching paragraph IDs for example query:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 42, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 116, 117, 120, 121, 122, 123, 124, 126, 127, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 164, 166, 168, 169, 171, 172, 173, 176, 177, 178, 180, 181, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 252, 253, 254, 255, 256, 258, 259, 260, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 360, 362, 363, 364, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 450, 451, 452, 454, 455, 456, 457, 458, 459, 460, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533}\n"
     ]
    }
   ],
   "source": [
    "def evaluate_postfix(postfix_tokens, inverted_index, num_paragraphs):\n",
    "    # Evaluating the postfix expression\n",
    "    stack = []  \n",
    "    \n",
    "    # Handling NOT operations\n",
    "    all_paragraphs = set(range(num_paragraphs))  \n",
    "\n",
    "    # Look through each token in the expression and preform nessesary operations\n",
    "    for token in postfix_tokens:\n",
    "        if token == 'AND':\n",
    "            # Pop the top two sets\n",
    "            right = stack.pop()  \n",
    "            left = stack.pop()\n",
    "            # Push the result of addition to stack\n",
    "            stack.append(left & right)  \n",
    "\n",
    "        elif token == 'OR':\n",
    "            right = stack.pop()\n",
    "            left = stack.pop()\n",
    "            # Push the result of union to stack\n",
    "            stack.append(left | right)  \n",
    "\n",
    "        # If the token is NOT operator calculate the difference \n",
    "        elif token == 'NOT':\n",
    "            operand = stack.pop()\n",
    "            # Push ducuments that are not in list to stack\n",
    "            stack.append(all_paragraphs - operand)  \n",
    "\n",
    "        # If the token is search term retrieve the matching paragraph IDs from inverted index\n",
    "        else:\n",
    "            # Push matching paragraph IDs to stack\n",
    "            stack.append(inverted_index.get(token, set())) \n",
    "\n",
    "    # Return the matching paragraph IDs if there are any or empty set\n",
    "    if stack:\n",
    "        return stack.pop()\n",
    "    else:\n",
    "        return set()\n",
    "\n",
    "\n",
    "test_matching_paragraphs = evaluate_postfix(test_postfix_query, inverted_index, len(cleaned_paragraphs))\n",
    "display(Markdown(\"Matching paragraph IDs for example query:\"))\n",
    "print(f\"{test_matching_paragraphs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9949db3-9917-4c6a-9fc2-acf027ad0539",
   "metadata": {},
   "source": [
    "<br>β) Κατάταξη αποτελεσμάτων (Ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd2b54-f6ab-49c4-8e3e-3e63f86eb681",
   "metadata": {},
   "source": [
    "Δημιουργία πίνακα TF-IDF με βάση τα αποτελέσματα του ερωτήματος. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "739e1233-c684-4bbc-809e-34eaaa13ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(results, cleaned_paragraphs):\n",
    "    # Return nothing if there are no results\n",
    "    if not results:\n",
    "        return None, [], [], None\n",
    "\n",
    "    # Store the filtered paragraphs and their IDs\n",
    "    filtered_paragraphs = []\n",
    "    filtered_ids = []\n",
    "\n",
    "    # Extract the text and IDs of paragraphs that match the query results\n",
    "    for paragraph_id in results:\n",
    "        # Join the tokens of each paragraph into a single string for processing\n",
    "        filtered_paragraphs.append(' '.join(cleaned_paragraphs[paragraph_id]['tokens']))\n",
    "        filtered_ids.append(paragraph_id)\n",
    "\n",
    "    # Initialize and compute the TF-IDF matrix of the paragraphs\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = vectorizer.fit_transform(filtered_paragraphs)\n",
    "\n",
    "    # Return the TF-IDF matrix, paragraphs, their IDs and TF-IDF vectorizer\n",
    "    return tfidf_matrix, filtered_paragraphs, filtered_ids, vectorizer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd2cfc2-bfad-4af0-b7ae-6e4ee47fa8cf",
   "metadata": {},
   "source": [
    "Κατάταξη αποτελεσμάτων με τον αλγόριθμο Vector Space Model και επιστροφή της παραγράφου με μεγαλύτερη τη βαθμολόγηση από κάθε σχετικό σύνδεσμο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42a827cf-0075-47e9-ac56-3d25b9162856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_space_model(cleaned_query, tfidf_matrix, original_paragraphs, filtered_ids, vectorizer):\n",
    "    # Join the query tokens into a string\n",
    "    cleaned_query = ' '.join(cleaned_query)\n",
    "\n",
    "    # Transform the query into a TF-IDF vector using the TF-IDF vectorizer\n",
    "    query_vector = vectorizer.transform([cleaned_query])\n",
    "\n",
    "    # Compute the cosine similarity between the query and the TF-IDF matrix\n",
    "    cosine_similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "\n",
    "    # Store the paragraph with the biggest score for each link\n",
    "    link_top_scores = {}\n",
    "\n",
    "    # Look through each paragraph and its similarity score\n",
    "    for paragraph_id, score in zip(filtered_ids, cosine_similarities):\n",
    "        # Retrieve the original paragraph data to print\n",
    "        original = original_paragraphs[paragraph_id]\n",
    "        # Extract the link of current paragraph\n",
    "        link = original['link']  \n",
    "\n",
    "        # If the link is new or the score is higher than the existing one update the record\n",
    "        if link not in link_top_scores or score > link_top_scores[link]['score']:\n",
    "            link_top_scores[link] = {\n",
    "                'paragraph_id': paragraph_id,\n",
    "                'link': link,\n",
    "                'text': original['text'],\n",
    "                'score': score\n",
    "            }\n",
    "\n",
    "    # Sort the results in descending order\n",
    "    sorted_scores = sorted(\n",
    "        link_top_scores.values(),\n",
    "        key = lambda x: x['score'],\n",
    "        reverse = True\n",
    "    )\n",
    "\n",
    "    # Return highest ranked paragraphs \n",
    "    return sorted_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448c57e-4e92-4652-b3ba-6488b0504c51",
   "metadata": {},
   "source": [
    "Κατάταξη αποτελεσμάτων με τον αλγόριθμο Okapi BM25 και επιστροφή της παραγράφου με τη μεγαλύτερη βαθμολόγηση από κάθε σχετικό σύνδεσμο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cce26782-a24e-4b86-84f5-6c00183a2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def okapi_bm25(cleaned_query, filtered_paragraphs, filtered_ids, original_paragraphs):\n",
    "    # Tokenize the filtered paragraphs\n",
    "    tokenized_paragraphs = []\n",
    "\n",
    "    # For every paragraph\n",
    "    for paragraph in filtered_paragraphs:\n",
    "        # Split into tokens\n",
    "        tokens = paragraph.split(' ')\n",
    "        tokenized_paragraphs.append(tokens)\n",
    "\n",
    "    # Initialize BM25 Okapi and fit it on the tokenized paragraphs\n",
    "    bm25 = BM25Okapi(tokenized_paragraphs)\n",
    "\n",
    "    # Compute the BM25 scores for the query\n",
    "    bm25_scores = bm25.get_scores(cleaned_query)\n",
    "\n",
    "    # Keep track of the highest ranked paragraph for each link\n",
    "    link_top_scores = {}\n",
    "\n",
    "    # Look through the filtered paragraph IDs and their BM25 scores\n",
    "    for paragraph_id, score in zip(filtered_ids, bm25_scores):\n",
    "        # Retrieve original paragraph data for printing\n",
    "        original = original_paragraphs[paragraph_id]\n",
    "        link = original['link']\n",
    "\n",
    "        # Store the paragraph only if it has the highest score for this link\n",
    "        if link not in link_top_scores or score > link_top_scores[link]['score']:\n",
    "            link_top_scores[link] = {\n",
    "                'paragraph_id': paragraph_id,\n",
    "                'link': link,\n",
    "                'text': original['text'],\n",
    "                'score': score\n",
    "            }\n",
    "\n",
    "    # Sort the results descending order\n",
    "    sorted_scores = sorted(\n",
    "        link_top_scores.values(),\n",
    "        key = lambda x: x['score'],\n",
    "        reverse = True\n",
    "    )\n",
    "\n",
    "    # Return highest ranked paragraphs\n",
    "    return sorted_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22096737-f0fc-44ec-b4a0-75d1f3d58262",
   "metadata": {},
   "source": [
    "Δημιουργία μηχανής αναζήτησης (Search Engine) με τη δυνατότητα επιλογής αλγόριθμου αναζήτησης και εισαγωγή ερωτήματος από τον χρήστη. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a81d521a-3b49-460c-9496-01da8376f59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4518af663684409b9c2caccac34de0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(ToggleButtons(description='Select ranking algorithm', options=('Boolean retrieval', 'Vector Spa…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def search_engine(inverted_index, original_paragraphs, cleaned_paragraphs):\n",
    "    # Select the ranking algorithm\n",
    "    toggle_buttons = widgets.ToggleButtons(\n",
    "        options = ['Boolean retrieval', 'Vector Space Model', 'Okapi BM25'],\n",
    "        description = 'Select ranking algorithm'\n",
    "    )\n",
    "    \n",
    "    space = widgets.HTML(value = '<br>')\n",
    "\n",
    "    # Enter search queries\n",
    "    input_text = widgets.Text(\n",
    "        placeholder = 'Input search query here',\n",
    "        layout = widgets.Layout(width = '70%')\n",
    "    )\n",
    "    \n",
    "    # Button to activate searching\n",
    "    search_button = widgets.Button(\n",
    "        description = 'Search',\n",
    "        button_style = 'primary'\n",
    "    )\n",
    "    \n",
    "    # Display search results\n",
    "    output = widgets.Output()\n",
    "\n",
    "    # Handles the search when the button is clicked\n",
    "    def search(b):\n",
    "        # Clear previous results\n",
    "        output.clear_output()  \n",
    "        # Get the selected ranking algorithm\n",
    "        algorithm = toggle_buttons.value  \n",
    "        # Get query that user entered\n",
    "        query = input_text.value  \n",
    "\n",
    "        # Convert the query to postfix and evaluate using the inverted index\n",
    "        postfix_query = infix_to_postfix(query)\n",
    "        results = evaluate_postfix(postfix_query, inverted_index, len(cleaned_paragraphs))\n",
    "        \n",
    "        # Apply TF-IDF transformation on the resulting paragraphs\n",
    "        tfidf_matrix, filtered_paragraphs, filtered_ids, vectorizer = tf_idf(results, cleaned_paragraphs)\n",
    "        # Process query for ranking\n",
    "        cleaned_query = clean_text(query)  \n",
    "\n",
    "        # Display search results based on the selected ranking algorithm\n",
    "        with output:\n",
    "            if filtered_paragraphs:\n",
    "                print(f\"Total matching paragraphs: {len(filtered_ids)}\\n\")\n",
    "\n",
    "                # Display results with Boolean retrieval\n",
    "                if algorithm == 'Boolean retrieval':\n",
    "                    displayed_links = set()\n",
    "                    for i, paragraph_id in enumerate(filtered_ids):\n",
    "                        original = original_paragraphs[paragraph_id]\n",
    "                        if original['link'] not in displayed_links:\n",
    "                            displayed_links.add(original['link'])\n",
    "                            print(f\"Link: {original['link']}\\n{original['text']}\")\n",
    "                    print(f\"Total links shown: {len(displayed_links)}\\n\")\n",
    "\n",
    "                # Display ranked results with VSM\n",
    "                elif algorithm == 'Vector Space Model':\n",
    "                    ranked_results = vector_space_model(cleaned_query, tfidf_matrix, original_paragraphs, filtered_ids, vectorizer)\n",
    "                    displayed_links = set()\n",
    "                    for result in ranked_results:\n",
    "                        displayed_links.add(result['link'])\n",
    "                        print(f\"Link: {result['link']}      (Score: {result['score']:.3f})\\n{result['text']}\")\n",
    "                    print(f\"Total links shown: {len(displayed_links)}\\n\")\n",
    "                \n",
    "                # Display ranked results with okapi BM25\n",
    "                elif algorithm == 'Okapi BM25':\n",
    "                    ranked_results = okapi_bm25(cleaned_query, filtered_paragraphs, filtered_ids, original_paragraphs)\n",
    "                    displayed_links = set()\n",
    "                    for result in ranked_results:\n",
    "                        displayed_links.add(result['link'])\n",
    "                        print(f\"Link: {result['link']}      (Score: {result['score']:.3f})\\n{result['text']}\")\n",
    "                    print(f\"Total links shown: {len(displayed_links)}\\n\")\n",
    "                \n",
    "            else:\n",
    "                # If no results match the query\n",
    "                print(f\"No results found for '{query}' using {algorithm}.\")\n",
    "\n",
    "    # Connect the search button to the search function\n",
    "    search_button.on_click(search)\n",
    "\n",
    "    # Display widgets\n",
    "    display(widgets.VBox([toggle_buttons, space, input_text, search_button, output]))\n",
    "\n",
    "search_engine(inverted_index, original_paragraphs, cleaned_paragraphs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e50fe-e653-4033-b2f5-4e3b2a4d6ea9",
   "metadata": {},
   "source": [
    "# 5. Αξιολόγηση συστήματος"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79310f9-b3fe-459c-805c-a407ad382b55",
   "metadata": {},
   "source": [
    "Εισαγωγή και επεξεργασία δεδομένων από το CISI dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf16e782-8a0b-40d3-9b79-7f3b4d075304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and process CISI documents\n",
    "def read_documents():\n",
    "    # File path to the CISI documents\n",
    "    fp = '/Users/vivh/ergasia/cisi/CISI.ALL/CISI.ALL'\n",
    "\n",
    "    with open(fp, 'r') as f:\n",
    "        # To merge content across lines\n",
    "        merged = ''  \n",
    "\n",
    "        # Read file line by line and merge content while preserving field tags\n",
    "        for a_line in f:\n",
    "            # Identify field tags (.I, .X)\n",
    "            if a_line.startswith('.'):  \n",
    "                merged += '\\n' + a_line.strip()\n",
    "            else:\n",
    "                # Add text to the merged content\n",
    "                merged += ' ' + a_line.strip()  \n",
    "\n",
    "    # Store processed documents\n",
    "    documents = []  \n",
    "    # Temporary storage for document text\n",
    "    content = ''  \n",
    "    # Temporary storage for document ID\n",
    "    doc_id = '' \n",
    "\n",
    "    # Process content line by line\n",
    "    for a_line in merged.split('\\n'):\n",
    "        # New document identifier\n",
    "        if a_line.startswith('.I'):\n",
    "            # Save previous document\n",
    "            if doc_id and content:  \n",
    "                documents.append({'id': doc_id, 'text': content.strip()})\n",
    "\n",
    "            # Extract document ID\n",
    "            doc_id = a_line.split(' ')[1].strip()  \n",
    "            # Reset for the new document\n",
    "            content = ''  \n",
    "        \n",
    "        # End of document identifier    \n",
    "        elif a_line.startswith('.X'): \n",
    "            if doc_id and content:\n",
    "                documents.append({'id': doc_id, 'text': content.strip()})\n",
    "                \n",
    "            doc_id = ''\n",
    "            content = ''\n",
    "            \n",
    "        else:\n",
    "            # Add the content excluding the tags\n",
    "            content += a_line[3:].strip() + ' '\n",
    "\n",
    "    # Last document in the file\n",
    "    if doc_id and content:\n",
    "        documents.append({'id': doc_id, 'text': content.strip()})\n",
    "    \n",
    "    # Save processed documents to a JSON file\n",
    "    store_things(documents, 'cisi_documents.json')\n",
    "    return documents\n",
    "\n",
    "\n",
    "# Read and process CISI queries\n",
    "def read_queries():\n",
    "    fp = '/Users/vivh/ergasia/cisi/CISI.QRY'\n",
    "\n",
    "    with open(fp, 'r') as f:\n",
    "        merged = '' \n",
    "\n",
    "        for a_line in f:\n",
    "            if a_line.startswith('.'):\n",
    "                merged += '\\n' + a_line.strip()\n",
    "            else:\n",
    "                merged += ' ' + a_line.strip() \n",
    "\n",
    "    queries = [] \n",
    "    content = ''  \n",
    "    qry_id = '' \n",
    "\n",
    "    for a_line in merged.split('\\n'):\n",
    "        if a_line.startswith('.I'):\n",
    "            if qry_id and content: \n",
    "                queries.append({'id': qry_id, 'text': content.strip()})\n",
    "                \n",
    "            qry_id = a_line.split(' ')[1].strip() \n",
    "            content = '' \n",
    "        \n",
    "        elif a_line.startswith('.W') or a_line.startswith('.T'): \n",
    "            content += a_line.strip()[3:] + ' '\n",
    "\n",
    "    if qry_id and content:\n",
    "        queries.append({'id': qry_id, 'text': content.strip()})\n",
    "\n",
    "    store_things(queries, 'cisi_queries.json')\n",
    "    return queries\n",
    "\n",
    "\n",
    "# Function to read and process CISI relevance mappings\n",
    "def read_mappings():\n",
    "    fp = '/Users/vivh/ergasia/cisi/CISI.REL'\n",
    "\n",
    "    with open(fp, 'r') as f:\n",
    "        # Store processed mappings\n",
    "        mappings = []  \n",
    "\n",
    "        # Read file line by line\n",
    "        for a_line in f:\n",
    "            # Split the line into components\n",
    "            voc = a_line.strip().split()  \n",
    "            # Extract query ID\n",
    "            qry_id = voc[0].strip() \n",
    "            # Extract document ID\n",
    "            doc_id = voc[1].strip()  \n",
    "\n",
    "            # Append the mapping as a dictionary\n",
    "            mappings.append({'query_id': qry_id, 'doc_id': doc_id})\n",
    "\n",
    "    store_things(mappings, 'cisi_mappings.json')\n",
    "    return mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20336f84-42ec-48d3-bf57-bdde77e85219",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How some of the CISI documents are saved: <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "text: 18 Editions of the Dewey Decimal Classifications Comaromi, J.P. The present study is a history of the DEWEY Decimal Classification.  The first edition of the DDC was published in 1876, the eighteenth edition in 1971, and future editions will continue to appear as needed.  In spite of the DDC's long and healthy life, however, its full story has never been told.  There have been biographies of Dewey that briefly describe his system, but this is the first attempt to provide a detailed history of the work that more than any other has spurred the growth of librarianship in this country and abroad.\n",
      "\n",
      "id: 2\n",
      "text: Use Made of Technical Libraries Slater, M. This report is an analysis of 6300 acts of use in 104 technical libraries in the United Kingdom. Library use is only one aspect of the wider pattern of information use.  Information transfer in libraries is restricted to the use of documents.  It takes no account of documents used outside the library, still less of information transferred orally from person to person.  The library acts as a channel in only a proportion of the situations in which information is transferred. Taking technical information transfer as a whole, there is no doubt that this proportion is not the major one.  There are users of technical information - particularly in technology rather than science - who visit libraries rarely if at all, relying on desk collections of handbooks, current periodicals and personal contact with their colleagues and with people in other organizations.  Even regular library users also receive information in other ways.\n",
      "\n",
      "id: 3\n",
      "text: Two Kinds of Power An Essay on Bibliographic Control Wilson, P. The relationships between the organization and control of writings and the organization and control of knowledge and information will inevitably enter our story, for writings contain, along with much else, a great deal of mankind's stock of knowledge and information.  Bibliographical control is a form of power, and if knowledge itself is a form of power, as the familiar slogan claims, bibliographical control is in a certain sense power over power, power to obtain the knowledge recorded in written form.  As writings are not simply, and not in any simple way, storehouses of knowledge, we cannot satisfactorily discuss bibliographical control as simply control over the knowledge and information contained in writings.\n",
      "\n",
      "id: 4\n",
      "text: Systems Analysis of a University Library; final report and research project Buckland, M.K. The establishment of nine new universities in the 1960's provoked a highly stimulating re-examination of the nature, purpose and management of academic libraries.  Long-established attitudes and methods were questioned, but although changes were made, the basic difficulty remained - a lack of objective information about the best ways of providing a library service in a university. The report of the UGC Committee on Libraries (the Parry Repot [267]), which, in general, endorsed these changes, also stressed the need for research into all aspects of academic library provision.\n",
      "\n",
      "id: 5\n",
      "text: A Library Management Game: a report on a research project Brophy, P. Although the use of games in professional education has become widespread only during the last decade, the method has been used in a number of fields for many hundreds of years. Its origins have been traced to simple war games, used in military training when the \"real thing\" was either unavailable or too dangerous.  In more recent times, these games have become more and more sophisticated, and many now use large electronic computers to handle the complex calculations involved. Since 1956, when the first well-developed management game was introduced, the technique has spread rapidly into a wide variety of disciplines and today it is used at all levels of education, from primary school classes to courses for experienced professional men and women.  One of the main causes of this \"game explosion\" has been the rapid development of sophisticated management techniques, such as simulation and mathematical modelling, which have been made possible by rapid advances in computer technology.\n",
      "\n",
      "id: 6\n",
      "text: Abstracting Concepts and Methods Borko, H. Graduate library school study of abstracting should be more than a how-to-do-it course. It should include general material on the characteristcs and types of abstracts, the historical development of abstracting publications, the abstract-publishing industry (especially in the United States), and the need for standards in the preparation and evaluation of the product. These topics we call concepts. The text includes a methods section containing instructions for writing various types of abstracts, and for editing and preparing abstracting publications. These detailed instructions are supplemented by examples and exercises in the appendix. There is a brief discussion of indexing of abstract publications. Research on automation has been treated extensively in this work, for we believe that the topic deserves greater emphasis than it has received in the past. Computer use is becoming increasingly important in all aspects of librarianship. Much research effort has been expended on the preparation and evaluation of computer-prepared abstracts and extracts. Students, librarians, and abstractors will benefit from knowing about this research and understanding how computer programs were researched to analyze text, select key sentences, and prepare extracts and abstracts. The benefits of this research are discussed. Abstracting is a key segment of the information industry. Opportunities are available for both full-time professionals and part-time or volunteer workers. Many librarians find such activities pleasant and rewarding, for they know they are contributing to the more effective use of stored information. One chapter is devoted to career opportunities for abstractors.\n",
      "\n",
      "id: 7\n",
      "text: Academic Library Buildings A Guide to Architectural Issues and Solutions Ellsworth, R.E. This book attempts to present representative examples of successful architectural solutions to the important problems librarians and architects face in planning new college and university library buildings or in remodeling and enlarging existing structures.  It does not attempt to make case study evaluations, as was done by Ellsworth Mason for Brown and Yale.  Nor does it present examples of unsuccessful solutions except to show how to avoid mistakes, and in these cases the libraries will not be identified.\n",
      "\n",
      "id: 8\n",
      "text: The Academic Library Essays in Honor of Guy R. Lyle Farber, E.I. As important for staff members' individual development as was the apprenticeship in administration, perhaps the most significant attitude one acquired while working for Guy was engendered by his insistence that librarians must be interested in and knowledgeable about the content of the materials with which they dealt.  His love of literature, his respect for scholarship, his admiration for good writing and reading were manifested in many ways, but most notably in his admonition that, though we were primarily a research library, we must constantly keep in mind our obligation to collect contemporary poetry, fiction and belles-letters.  It was primarily up to the library staff, he felt, to be responsible for these as well as for \"general\" books which crossed disciplinary lines or fell between the disciplines, those books which a faculty mostly concerned with research materials is apt to overlook.  And in building this portion of the collection, \"there is no substitute for a thorough acquaintance with books through a reading of critical reviews and the books themselves.\"  This counsel is from The President, the Professor, and the College Library, but the importance of its thrust--the need to keep up with the world of books and publishing--was continually impressed upon us.\n",
      "\n",
      "id: 9\n",
      "text: Access to Libraries in College Hyman, R.T. This study assumed that an additional use study held less promise than an analytical consideration of concepts. The basic approach was a survey comparing traditional and current professional ideas on direct access.  Principal data-gathering instruments were documentary analysis and opinion questionnaire. Findings of the documentary analysis included the following: Research from 1890 to 1970 on the direct shelf approach and browsing left the problems largely unresolved and evidently resistant to established methods of use and user research.  The need for an exhaustive study of concepts was confirmed. Open shelf libraries--organized through shelf classification and relative location--were meant to arouse the intellectual, social, and political interest of the average citizen and affect his democratic self-realization. Definitions of \"browsing\" varied greatly: self-indulgence by the untutored in objectionable works; beneficial self-education for the general reader; valuable guidance for the scholar in his research.\n",
      "\n",
      "id: 10\n",
      "text: Access to Periodical Resources Palmour, V.E. The purpose of this study was to develop, evaluate, and recommend a national plan  for improving access to periodical resources.  About 48 percent of all academic interlibrary loans are for periodical materials, with the bulk of the loans being satisfied in the form of photocopies.  A major consideration in the long-range improvement of the interlibrary loan system is the possible augmentation with a national system for acquiring, storing, and satisfying loan requests for periodical materials. This study focused on the physical access to the periodical literature.  Based on the needs of the library community, design features were developed, and included the following: Service should be made available to all users without any restriction other than access through a library. Initially, the service should be confined primarily to rapid, dependable delivery of photocopies of journal articles. The collection of a center should be comprehensive in subject coverage excluding only medicine. All worthwhile journals should be collected irrespective of language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "documents = read_documents()\n",
    "\n",
    "display(Markdown(\"How some of the CISI documents are saved: <br>\"))\n",
    "for paragraph in documents[:10]:\n",
    "    d_id = paragraph['id']\n",
    "    text = paragraph['text']\n",
    "\n",
    "    print(f\"id: {d_id}\")\n",
    "    print(f\"text: {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eb307ac-4cb7-4715-b30b-e0743648a6f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How some of the CISI queries are saved: <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 1\n",
      "text: What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n",
      "\n",
      "id: 2\n",
      "text: How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests?\n",
      "\n",
      "id: 3\n",
      "text: What is information science?  Give definitions where possible.\n",
      "\n",
      "id: 4\n",
      "text: Image recognition and any other methods of automatically transforming printed text into computer-ready form.\n",
      "\n",
      "id: 5\n",
      "text: What special training will ordinary researchers and businessmen need for proper information management and unobstructed use of information retrieval systems? What problems are they likely to encounter?\n",
      "\n",
      "id: 6\n",
      "text: What possibilities are there for verbal communication between computers and humans, that is, communication via the spoken word?\n",
      "\n",
      "id: 7\n",
      "text: Describe presently working and planned systems for publishing and printing original papers by computer, and then saving the byproduct, articles coded in data-processing form, for further use in retrieval.\n",
      "\n",
      "id: 8\n",
      "text: Describe information retrieval and indexing in other languages. What bearing does it have on the science in general?\n",
      "\n",
      "id: 9\n",
      "text: What possibilities are there for automatic grammatical and contextual analysis of articles for inclusion in an information retrieval system?\n",
      "\n",
      "id: 10\n",
      "text: The use of abstract mathematics in information retrieval, e.g. group theory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = read_queries()  \n",
    "\n",
    "display(Markdown(\"How some of the CISI queries are saved: <br>\"))\n",
    "for paragraph in queries[:10]:\n",
    "    d_id = paragraph['id']\n",
    "    text = paragraph['text']\n",
    "\n",
    "    print(f\"id: {d_id}\")\n",
    "    print(f\"text: {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "730d643a-1826-429d-a6ba-34205d5e4b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "How CISI mappings are saved: <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>111</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3110</th>\n",
       "      <td>111</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3111</th>\n",
       "      <td>111</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112</th>\n",
       "      <td>111</td>\n",
       "      <td>503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3113</th>\n",
       "      <td>111</td>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3114 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query_id doc_id\n",
       "0           1     28\n",
       "1           1     35\n",
       "2           1     38\n",
       "3           1     42\n",
       "4           1     43\n",
       "...       ...    ...\n",
       "3109      111    422\n",
       "3110      111    448\n",
       "3111      111    485\n",
       "3112      111    503\n",
       "3113      111    509\n",
       "\n",
       "[3114 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mappings = read_mappings()\n",
    "\n",
    "display(Markdown(\"How CISI mappings are saved: <br>\"))\n",
    "# Convert mappings to data frame\n",
    "mappings_df = pd.DataFrame(mappings)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(mappings_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7536a64-4317-42ec-8cdb-fd7d7c5c0d66",
   "metadata": {},
   "source": [
    "Υπολογισμός ακρίβειας, ανάκλησης, F1-score και μέσης ακρίβειας με αγλόριθμο αναζήτησης Okapi BM25 για τα έγγραφα και ερωτήματα του CISI dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d95ccb4-284e-4c39-8282-cc0fdce5eb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Using the CISI dataset to evaluate search engine<br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What problems and concerns are there in making up descriptive titles? What difficulties are involved in automatically retrieving articles from approximate titles? What is the usual relevance of the content of articles to their titles?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['429', '1299', '1421', '1055', '722', '666', '76', '1090', '1281', '676', '38', '413', '64', '759', '928', '1195', '65', '212', '510', '799', '1265', '589', '541', '813', '195', '1118', '848', '1091', '1124', '1009', '154', '582', '1000', '953', '767', '576', '992', '803', '851', '831', '978', '1230', '1369', '603', '465', '1449', '276', '655', '650', '783', '711', '219', '620', '894', '1432', '869', '820', '52', '201', '338', '524', '269', '415', '483', '196', '1418', '1064', '609', '482', '886', '466', '86', '1002', '322', '192', '225', '726', '1436', '1286', '1164', '1162', '604', '757', '53', '680', '204', '150', '776', '1349', '788', '1089', '906', '221', '402', '495', '875', '215', '920', '811', '854', '193', '651', '493', '863', '921', '40', '861', '715', '775', '246', '333', '1373', '189', '1028', '1197', '1227', '1196', '1272', '865', '981', '904', '354', '614', '403', '588', '687', '551', '90', '919']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.302"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.848"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.446<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can actually pertinent data, as opposed to references or entire articles themselves, be retrieved automatically in response to information requests?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['381', '597', '1156', '1055', '862', '1078', '892', '526', '1352', '488', '797', '788', '339', '1155', '596', '1158', '1363', '898', '1103', '552', '10', '1138', '1126', '660', '1118', '1120', '562', '711', '783', '1170', '1147', '207', '1130', '451', '695', '218', '223', '1124', '483', '309', '58', '773', '644', '484', '394', '165', '551', '1231', '1327', '871', '706', '891', '382', '1394', '550', '271', '479', '71', '188']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.034"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.077"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.047<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is information science?  Give definitions where possible.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1181', '1077', '160', '599', '1037', '1277', '1249', '158', '837', '1169', '899', '496', '1255', '163', '1198', '123', '845', '592', '1445', '582', '1258', '1455', '1309', '1116', '784', '29', '1330', '900', '346', '57', '1016', '1095', '1373', '1241', '671', '1339', '481', '958', '241', '74', '839', '429', '853', '826', '1410', '898', '1013', '591', '1273', '685', '718', '478', '488', '568', '1404', '815', '893', '228', '78', '1266', '1201', '97', '1160', '157', '922', '446', '1082', '801', '774', '1342', '244', '542', '269', '622', '1347', '1393', '379', '1265', '809', '595', '811', '1371', '657', '1231', '816', '46', '194', '915', '1433', '913', '887', '17', '1354', '758', '168', '1379', '645', '1194', '1429', '285', '715', '775', '365', '82', '124', '307', '326', '1072', '1457', '530', '779', '1021', '1239', '1418', '731', '10', '1079', '945', '5', '738', '71', '58', '896', '1066', '1075', '564', '476', '977', '399', '1450', '208', '795', '68', '500', '52', '666', '16']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.036"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.114"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.055<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image recognition and any other methods of automatically transforming printed text into computer-ready form.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['739', '320', '601', '527', '420', '1341', '421', '80', '556', '252', '980', '1252', '653', '495', '1399', '26', '571', '862', '672', '231', '581', '596', '376', '1105', '94', '484', '648', '351', '1191', '1190', '530', '809', '521', '476', '769', '1042', '473', '875', '50', '42', '748', '19', '516', '478', '953', '1092', '962', '758', '1020', '611', '802', '390', '731', '552', '151', '798', '208', '58', '3', '1014', '263', '1371', '1396', '922', '686', '1165', '787', '150', '1004', '796', '36', '1316', '1415', '907', '628', '855', '402', '1229', '415', '1104', '353', '1046', '1352', '431', '1056', '873', '1247', '886', '1013', '872', '1160', '305', '715', '725', '383', '965', '993', '1136', '331', '789', '1189', '1333', '770', '635', '1378', '874', '621', '180', '130', '632', '191', '109', '1183', '1256', '826', '67', '1423', '585', '10', '618', '1152', '397', '848', '904', '528', '1427', '952', '1335', '600', '12', '310', '165', '399', '825', '728', '692', '400', '735', '1261', '1449', '776', '1349', '142', '1380', '132', '512']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.027"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.500"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.052<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What special training will ordinary researchers and businessmen need for proper information management and unobstructed use of information retrieval systems? What problems are they likely to encounter?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What possibilities are there for verbal communication between computers and humans, that is, communication via the spoken word?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1045', '400', '386', '1144', '341', '49', '26', '79', '688', '1382', '581', '542', '212', '1240', '807', '667', '419', '489', '657', '131', '517', '680', '160', '498', '150', '666', '820', '563', '636', '1323', '562', '661', '677', '1392', '466', '566', '564', '321', '1175', '512', '649', '329', '687', '577', '643', '1091', '71', '589', '478', '600', '835', '51', '38', '653', '315', '420', '1215', '1381', '676', '1366', '450', '1222', '1388', '402', '662', '620', '1267', '756', '576', '527', '421', '363', '761', '233', '1314', '447', '644', '350', '483', '390', '552', '1358', '791', '946', '476', '1362', '480', '507', '608', '798', '592', '1261', '68', '571', '1265', '1309', '1124']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.010"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 1.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.020<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe presently working and planned systems for publishing and printing original papers by computer, and then saving the byproduct, articles coded in data-processing form, for further use in retrieval.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['446', '484', '135', '1364', '615', '675', '1072', '611', '728', '26', '508', '461', '571', '165', '1248', '512', '376', '159', '67', '534', '790', '1180', '1179', '610', '389', '1391', '731', '648', '706', '375', '530', '664', '986', '514', '463', '1171', '490', '120', '1136', '993', '501', '606', '1323', '148', '252', '1264', '687', '429', '528', '704', '644', '473', '617', '641', '28', '686', '826', '565', '898', '703', '630', '156', '659', '798', '243', '454', '451', '1092', '445', '866', '562', '175', '627', '459', '58', '925', '495', '526', '690', '381', '889', '388', '1009', '378', '1078', '478', '596', '779', '754', '481', '179', '1191', '636', '634', '1190', '590', '660', '518', '327', '594', '498', '523', '114', '707', '600', '762', '681', '197', '1120', '321', '319', '839', '637', '670', '129', '71', '773', '737', '531', '516', '620', '458', '1259', '538', '1170', '1305', '68', '1419', '126', '689', '625', '591', '746', '448', '1448', '716', '857', '595', '785', '806', '566', '497', '462', '579', '309', '66', '176', '827', '575', '480', '883', '851', '328', '519', '61', '1196', '769', '1413', '1327', '434', '1175', '1125', '487', '73', '895', '525', '509', '1282', '254', '1027', '1139', '1405', '502', '483', '488', '151', '382', '1307', '780', '871', '820', '318', '474', '1081', '503', '1053', '486', '492', '510', '680', '709', '137', '472', '805', '267', '1089', '567', '1117', '733', '1124', '1091', '727', '1377', '705', '702', '1126', '1054', '257', '1392', '695', '468', '894', '807', '1197', '30', '966', '547', '812', '452', '626', '515', '131', '603', '479', '1422', '797', '174', '813', '1255', '123', '199', '755', '539', '44', '661', '560', '450', '1134', '688', '650', '78', '323', '329', '592', '471', '631', '956', '1362', '835', '1368', '838', '460', '1164', '1162', '853', '619', '496', '63', '829', '334', '29', '608', '51', '125', '655', '1153', '1158', '1130', '1414', '363', '259', '817', '82', '761', '1258', '810', '1201', '160', '598']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.007"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.250"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.014<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe information retrieval and indexing in other languages. What bearing does it have on the science in general?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['159', '434', '52', '1010', '595', '456', '1124', '1443', '590', '825', '1024', '1175', '168', '702', '746', '148', '644', '82', '1448', '257', '388', '514', '477', '195', '888', '1421', '19', '199', '500', '134', '1142', '1427', '1222', '47', '1118', '857', '709', '73', '519', '1430', '597', '1169', '692', '497', '631', '320', '269', '160', '85', '1067', '650', '463', '838', '439', '1161', '25', '553', '309', '534', '158', '1259', '468', '1391', '319', '1249', '706', '484', '1407', '557', '1273', '1113', '845', '129', '819', '1068', '610', '398', '414', '1348', '823', '1349', '1262', '1442', '1201', '784', '582', '1318', '701', '6', '1398', '263', '1342', '1245', '568', '335', '54', '1084', '1447', '246', '787', '229', '1351', '118', '667', '540', '12', '882', '1384', '261', '972', '1292', '306', '1204', '1231', '4', '1401', '1241', '740', '699', '292', '1105', '563', '767', '654', '1203', '930', '880', '206', '929', '265', '1381', '331', '161', '242', '1256', '43', '849', '1018', '84', '1150', '164', '352', '171', '978', '1023', '310', '42', '282', '1021', '260', '228', '426', '364', '842', '405', '9', '1455', '694', '348', '354', '1075', '1399', '248', '476', '8', '949', '950', '141', '340', '359', '207', '1416', '919', '250', '928', '1020']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.011"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.111"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.021<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What possibilities are there for automatic grammatical and contextual analysis of articles for inclusion in an information retrieval system?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1120', '571', '135', '175', '565', '179', '1144', '1136', '483', '986', '1327', '212', '309', '446', '830', '682', '72', '1419', '989', '490', '591', '572', '291', '497', '482', '916', '1298', '126', '114', '71', '534', '691', '1012', '421', '630', '1092', '606', '27', '615', '1437', '454', '617', '564', '1121', '517', '67', '180', '786', '17', '1173', '381', '73', '419', '1124', '676', '601', '494', '267', '28', '595', '64', '1109', '990', '1114', '659', '1225', '458', '538', '865', '621', '626', '970', '575', '514', '459', '850', '611', '1255', '762', '1105', '445', '151', '478', '822', '1125', '106', '1024', '158', '1171', '507', '254', '1139', '960', '375', '1170', '474', '1078', '666', '1241', '1229', '648', '567', '501', '481', '1053', '889', '1163', '382', '531', '376', '1427', '1409', '707', '827', '898', '1054', '222', '1038', '815', '513', '526', '544', '25', '165', '1098', '1405', '319', '522', '646', '477', '826', '530', '136', '461', '1179', '434', '703', '287', '120', '288', '1128', '874', '690', '1350', '1413', '574', '525', '1143', '1112', '523', '245', '294', '1282', '1448', '66', '1077', '535', '1305', '123', '607', '725', '451', '1223', '140', '1191', '1081', '1358', '389', '1307', '378', '1190', '317', '532', '925', '1110', '780', '74', '448', '4', '1401', '579', '670', '137', '1267', '660', '484', '636', '871', '243', '252', '1264', '159', '883', '1080', '1073', '594', '1007', '213', '1104', '129', '486', '49', '642', '553', '119', '1293', '839', '1175', '10', '993', '468', '150', '644', '1227', '671', '560', '54', '1106', '528', '318', '321', '948', '1410', '347', '637', '128', '1022', '1326', '639', '1289', '336', '1180', '1084', '1447', '1126', '1360', '1361', '1016', '737', '727', '731', '641', '895', '866', '57', '1283', '327', '590', '447', '1362', '1035', '202', '1341', '610', '433', '373', '131', '1309', '546', '537', '1207', '716', '1367', '566', '1391', '704', '695', '1209', '85', '325', '681', '16', '1127', '982', '244', '452', '1011', '1113', '504', '664', '547', '798', '1317', '406', '472', '200', '689', '557', '59', '408', '1099', '687', '773', '846', '593', '674', '1460', '174', '612', '515', '449', '652', '1051', '1348', '582', '95', '1328', '257', '1093', '723', '1436', '132', '134', '840', '177', '388', '1281', '890', '966', '702', '542', '502', '1044', '292', '508', '627', '796', '1418', '1378', '18', '386', '842', '806', '1074', '231', '726', '947', '1057', '809', '511', '1196', '364', '709', '634', '562', '779', '329', '492', '224', '706', '409', '512', '1010', '728', '80', '955', '157', '754', '519', '61', '190', '984', '310', '228', '1215', '820', '872', '694', '620', '1091', '941', '801', '1236', '785', '1152', '115', '1349', '742', '529', '1256', '860', '833', '825', '979', '693', '510', '1261', '1117', '880', '1416', '104', '720', '647', '1259', '739', '1137', '600', '491', '848', '1062', '699', '1193', '645', '897', '340', '625', '358', '320', '917', '710', '1067', '951', '556', '1377', '1366', '400', '683', '849', '348', '1197', '802', '68', '387', '350', '1072', '1339', '700', '1415', '197', '1290', '597', '1249', '843', '701', '1375', '250', '1085', '1004', '1195', '884', '997', '1230', '795', '1148', '603', '44', '1111', '262', '1456', '89', '954', '102', '999', '852', '467', '868', '752', '332', '399', '211', '13', '141', '744', '741', '740', '394', '841', '1000', '465', '1001', '117', '1', '192', '654', '576', '838', '268', '380', '396', '998', '265', '295', '124', '1333', '48', '697', '1402', '1043', '609', '911', '862', '1445', '1457', '724', '677', '1049', '1040', '1417', '888', '390', '398', '335', '354', '1395', '443', '476', '1363', '1337', '1206', '208', '1277', '168', '1425', '1147']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.033"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.500"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.062<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The use of abstract mathematics in information retrieval, e.g. group theory.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1385', '536', '1411', '229', '558', '471', '25', '664', '1340', '518', '259', '1231', '174', '67', '895', '1315', '1015', '643', '321', '549', '590', '1027', '575', '479', '1219', '73', '1282', '827', '1081', '31', '445', '1387', '1125', '368', '532', '610', '1191', '1173', '644', '803', '1190', '1047', '972', '227', '829', '1187', '1064', '168', '1117', '525', '641', '660', '456', '1365', '557', '1360', '627', '1201', '1045', '1244', '810', '1186', '574', '1161', '1326', '1309', '160', '1233', '17', '308', '228', '1220', '1204', '1348', '343', '397', '1202', '1399', '1248', '1333', '1262', '118', '1443', '1150', '1217', '544', '356', '667', '846', '349', '901', '1398', '93', '1455', '247', '1077', '982', '1119', '824', '1292', '1334', '1160', '647', '758', '1046', '1224', '1227', '1329', '1386', '1357', '226', '572', '542', '396', '1037', '819', '1393', '64', '1427', '1185', '911', '1188', '387', '350', '1339', '195', '62', '335', '1066', '1075', '476', '1311', '291', '19', '320', '1416', '1082', '250']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.101"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.538"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.171<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the need for information consolidation, evaluation, and retrieval in scientific research?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['474', '575', '965', '128', '484', '560', '383', '1098', '134', '381', '771', '513', '6', '899', '378', '88', '1106', '147', '194', '966', '388', '481', '1432', '440', '1174', '259', '385', '1099', '163', '544', '666', '1120', '688', '1256', '1315', '900', '807', '1170', '1346', '905', '98', '1095', '871', '176', '202', '199', '1418', '148', '1264', '553', '526', '769', '654', '1284', '512', '243', '456', '606', '375', '274', '619', '703', '185', '95', '1009', '1289', '1342', '479', '690', '1110', '27', '1144', '1323', '889', '818', '1179', '537', '763', '891', '962', '1200', '1211', '132', '1197', '426', '462', '4', '1401', '405', '328', '160', '439', '937', '254', '314', '1273', '626', '543', '311', '796', '1154', '896', '667', '151', '174', '1427', '341', '1121', '1082', '1344', '1178', '603', '1352', '129', '1130', '1061', '370', '107', '821', '190', '220', '9', '728', '1444', '600', '266', '704', '1047', '1455', '1348', '360', '1155', '1308', '450', '616', '490', '813', '1408', '286', '948', '343', '139', '178', '685', '1345', '1330', '102', '8', '1347', '340', '93', '576', '312', '556', '391', '113', '257', '1270', '557', '17', '692', '475', '97', '1146', '46', '1151', '1279', '642', '353', '438', '96', '105', '1403', '961', '116', '1335', '104', '32', '172', '109', '1296', '304', '395', '960', '1203', '1250', '1219', '295', '1321', '15', '953', '561', '1268', '1454', '65', '287', '943', '658', '1288', '922', '491', '1379', '422', '612', '952', '436', '293', '936', '856', '1442', '775', '1058', '1372', '907', '504', '1450', '985', '1262', '915', '1217', '164', '540', '355', '351', '1023', '1083', '1183', '1209', '31', '350', '1328', '1409', '946', '1070', '964', '734', '672', '467', '1410', '649', '732', '1382', '963', '730', '348', '1390', '1257', '424', '221', '1113', '399', '633', '338', '296', '1205', '239', '601', '420', '982', '1241', '1207', '1254', '431', '1011', '828', '74', '602', '423', '1378', '645', '1350', '1068', '1406', '863', '1135', '921', '815', '918', '941', '1242', '1227', '278', '902', '1067', '256', '482', '861', '1036', '173', '1336', '246', '1381', '366', '1031', '736', '739', '1424', '1182', '1065', '892', '994', '1355', '849', '184', '1018', '757', '520', '1149', '1150', '1210', '1050', '103', '1251', '978', '958', '260', '158', '12', '108', '115', '945', '5', '317', '1249', '614', '427', '1052', '825', '949', '489', '76', '291', '208', '559', '357', '1277', '168', '1039', '52', '1449', '1048', '1425', '1020', '217', '400']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.154"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.417"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.225<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give methods for high speed publication, printing, and distribution of scientific journals.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['552', '1182', '725', '686', '1108', '1167', '748', '543', '41', '1209', '1157', '696', '767', '691', '1097', '1061', '190', '613', '1418', '778', '616', '1432', '1276', '1460', '1338', '1363', '193', '831', '1335', '258', '113', '203', '110', '889', '573', '618', '225', '198', '763', '821', '253', '624', '759', '905', '1290', '1210', '683', '1177', '635', '820', '560', '804', '845', '1350', '685', '1369', '1355', '735', '580', '721', '37', '199', '97', '200', '770', '1114', '1176', '194', '722', '76', '755', '933', '657', '195', '1055', '150', '210', '1373', '111', '1047', '744', '588', '756', '614', '429', '515', '196', '472', '622', '189', '1060', '977', '1301', '776', '415', '87', '201', '757', '1156', '1090', '183', '204', '506', '638', '1109', '255', '1299', '1396', '1131', '219', '167', '1241', '943', '1023', '1083', '65', '10', '1293', '986', '1352', '623', '466', '112', '1071', '715', '775', '1207', '1147', '676', '1232', '1262', '898', '447', '1014', '355', '973', '161', '381', '507', '388', '589', '197']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.028"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.308"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.052<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What criteria have been developed for the objective evaluation of information retrieval and dissemination systems?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1098', '611', '565', '1120', '646', '866', '481', '1106', '128', '137', '515', '59', '1139', '591', '486', '57', '1078', '889', '222', '1105', '1341', '523', '445', '49', '579', '1375', '474', '1298', '519', '1171', '175', '434', '513', '179', '827', '461', '727', '459', '780', '120', '1264', '490', '375', '571', '690', '625', '615', '135', '123', '1126', '67', '606', '801', '224', '670', '134', '1114', '1143', '575', '348', '525', '18', '826', '213', '986', '1281', '508', '27', '265', '1127', '534', '676', '1367', '72', '244', '421', '74', '514', '378', '482', '553', '309', '448', '504', '159', '1417', '1054', '484', '850', '1012', '327', '243', '728', '1099', '1362', '1175', '458', '538', '381', '373', '376', '1136', '595', '190', '446', '560', '644', '4', '1401', '630', '1358', '1180', '358', '839', '955', '671', '1207', '637', '528', '695', '1125', '254', '731', '590', '1092', '1416', '1170', '659', '1040', '449', '648', '501', '136', '1053', '674', '707', '80', '1038', '386', '865', '382', '526', '720', '497', '454', '1062', '1405', '319', '1121', '1179', '703', '529', '1256', '694', '114', '1128', '620', '1413', '574', '388', '1144', '960', '1112', '627', '1282', '1448', '66', '1077', '535', '825', '1305', '1418', '607', '451', '1223', '140', '512', '634', '1191', '1081', '389', '691', '1307', '647', '1190', '468', '1427', '532', '1173', '925', '1110', '408', '158', '621', '126', '636', '660', '645', '1419', '252', '151', '762', '898', '883', '180', '1080', '594', '150', '682', '1104', '129', '874', '28', '642', '119', '1293', '73', '820', '478', '610', '993', '54', '467', '318', '321', '948', '267', '1410', '483', '347', '1022', '1326', '639', '1289', '64', '336', '1084', '1447', '16', '1361', '737', '641', '895', '317', '1283', '951', '1124', '1035', '202', '725', '165', '433', '131', '1309', '546', '537', '1241', '716', '556', '250', '566', '1391', '916', '704', '1209', '601', '85', '564', '325', '681', '702', '567', '494', '666', '982', '452', '1011', '1113', '292', '815', '822', '664', '626', '1337', '547', '654', '726', '798', '786', '1109', '262', '406', '117', '970', '477', '472', '689', '557', '687', '773', '846', '593', '398', '1460', '174', '572', '612', '652', '1051', '1348', '582', '95', '257', '1437', '1093', '795', '723', '1436', '132', '10', '177', '364', '245', '966', '295', '542', '197', '990', '208', '502', '609', '1255', '796', '1378', '842', '806', '231', '947', '1057', '809', '419', '1196', '617', '544', '709', '1327', '562', '779', '1215', '492', '706', '1091', '1010', '115', '1415', '335', '157', '754', '61', '354', '1363', '310', '228', '1350', '872', '1044', '71', '941', '1227', '1236', '1007', '530', '294', '989', '785', '291', '871', '1349', '742', '860', '833', '1360', '979', '693', '510', '1261', '1117', '880', '1225', '1259', '739', '1137', '600', '491', '848', '699', '1193', '897', '340', '320', '917', '710', '1067', '1377', '531', '1366', '400', '25', '683', '849', '1073', '1229', '1197', '802', '68', '387', '350', '1328', '517', '1072', '1339', '700', '890', '1290', '597', '1249', '843', '701', '1085', '1004', '1195', '884', '997', '1230', '1148', '603', '44', '1111', '1456', '89', '1163', '1409', '954', '102', '999', '522', '852', '1016', '868', '1317', '329', '752', '332', '409', '399', '287', '507', '211', '288', '13', '17', '141', '840', '744', '741', '740', '394', '841', '1000', '465', '1267', '1001', '1', '192', '1074', '576', '838', '268', '380', '396', '998', '124', '1333', '48', '1024', '830', '697', '212', '1402', '1043', '911', '862', '1445', '1457', '724', '984', '447', '677', '1049', '888', '390', '1152', '200', '106', '1395', '104', '443', '476', '1206', '511', '1277', '168', '1425', '1147']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.117"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.659"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.198<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query ID: 14\n",
      "Query: What future is there for automatic medical diagnosis?\n",
      "No matches found.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much do information retrieval and dissemination systems, as well as automated libraries, cost? Are they worth it to the researcher and to industry?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1264', '314', '1114', '327', '126', '801', '1205', '1353', '1269', '623', '507', '1126', '236', '1009', '528', '6', '512', '437', '140', '119', '942', '598', '1106', '941', '730', '166', '683', '1058', '383', '1062', '1451', '1320', '368', '581', '355', '759']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.167"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.073"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.102<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What systems incorporate multiprogramming or remote stations in information retrieval?  What will be the extent of their use in the future?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1258', '883', '631', '636', '481', '1124', '580', '1346', '993', '716', '131', '621', '907', '348', '1362', '655', '916', '32', '386', '801', '123', '53', '847', '485', '423', '1144', '1290', '72', '661', '491', '1356', '897', '482', '1437', '1251', '795', '134', '1045', '1079', '1241', '846', '977', '1383', '1', '1273', '401', '873', '1090', '24', '1043', '1457', '685', '80', '950', '1294', '915', '310', '1088', '320', '718', '1417', '1388', '1439', '1268', '870', '1354', '1390', '112', '901', '453', '1344', '767', '143', '1429', '922', '902', '1082', '878', '1238', '935', '943', '1438', '17', '367', '1149', '100', '418', '1025', '923', '561', '166', '400', '185', '142', '938']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.021"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.077"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.033<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means of obtaining large volume, high speed, customer usable information retrieval output.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['252', '512', '319', '625', '1207', '104', '113', '395', '893', '894', '1193', '591', '1229', '103', '371', '1432', '660', '595', '376', '636', '1347', '495', '813', '603', '1299', '608', '102', '694', '880', '709', '77', '150', '1163', '1376', '833', '1371', '897', '1304', '493', '428', '789', '892', '962', '517', '1286', '1230', '308', '1252']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.062"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.115"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.081<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What methods are there for encoding, automatically matching, and automatically drawing structures extended in two dimensions, like the structural formulas for chemical compounds?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['668', '677', '1452', '701', '1261', '690', '671', '694', '592', '150', '687', '709', '890', '1092', '669', '569', '673', '705', '674', '600', '1460', '704', '679', '682', '696', '1286', '472', '838', '1180', '1215', '699', '1414']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.125"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.364"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.186<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Techniques of machine matching and machine searching systems. Coding and matching methods.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['175', '483', '820', '179', '200', '487', '1298', '500', '1292', '1398', '603', '814', '790', '1199', '661', '1252', '890', '521', '737', '1391', '357', '668', '151', '731', '117', '670', '254', '321', '1164', '738', '34', '1162', '705', '190', '708', '316', '1127', '1126', '446', '1416', '422', '563', '527', '17', '1092', '278', '798', '663', '643', '302', '824', '1242', '360', '616', '571', '1450', '429', '317', '327', '945', '5', '341', '633', '1124', '561', '72', '244', '962', '1396', '683', '565', '815', '1191', '373', '1105', '1190', '827', '408', '690', '158', '1125', '309', '1044', '73', '1121', '1419', '889', '424', '530', '451', '1179', '1163', '998', '1326', '1053', '1035', '615', '758', '659', '666', '425', '842', '1360', '611', '1341', '553', '707', '332', '525', '543', '1327', '1098', '822', '423', '475', '1041', '1061', '598', '806', '1057', '377', '865', '1381', '802', '1157', '192', '116', '262', '1382', '4', '1401', '55', '252', '478', '265', '769', '1194', '625', '1100', '1024', '1133', '1367', '1016', '1358', '71', '821', '1220', '1278', '911', '19', '441', '472', '1260', '1184', '41', '198', '228', '1422', '146', '232', '222', '42', '390', '816', '407', '641', '1161', '773', '199', '1099', '115', '1172', '1323', '79', '473', '299', '751', '875', '269', '46', '1167', '1226', '1428', '50', '847', '51', '150', '1095', '376', '52', '411', '1155', '208', '1345', '545', '980', '148', '1097', '207', '1142', '225', '673', '837', '77', '1135', '6', '1042', '956', '1429', '669', '763', '256', '1158', '259', '817', '1009', '82', '194', '333', '953', '1108', '1240', '994', '1355', '122', '1454', '792', '206', '667', '1314', '784', '680', '748', '282', '722', '629', '1325', '516', '195', '1070', '1250', '552', '93', '470', '503', '9', '1018', '570', '105', '290', '1369', '903', '352', '153', '1399', '1118', '604', '608', '1389', '1432', '160', '811', '339', '657', '47', '1082']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.086"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.284"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.133<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing automated information systems.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['827', '134', '336', '595', '1139', '180', '177', '128', '572', '979', '1298', '865', '815', '874', '1114', '860', '433', '895', '174', '916', '406', '868', '990', '644', '986', '136', '1120', '531', '1255', '190', '849', '1175', '1038', '458', '538', '135', '254', '1121', '630', '1092', '517', '1125', '1128', '1136', '611', '574', '1143', '459', '375', '1112', '474', '445', '1077', '535', '530', '1171', '607', '481', '591', '497', '1223', '140', '501', '1053', '707', '27', '565', '67', '615', '532', '175', '1173', '1110', '1170', '179', '158', '74', '621', '1078', '648', '571', '123', '1105', '421', '120', '606', '1080', '826', '319', '526', '1179', '682', '213', '114', '1104', '49', '642', '553', '119', '1293', '703', '1405', '66', '671', '54', '1413', '1106', '434', '1305', '690', '948', '454', '1410', '1191', '490', '347', '523', '1022', '1326', '639', '1289', '64', '525', '1084', '1447', '72', '1361', '1190', '461', '389', '1282', '126', '1012', '57', '1283', '381', '137', '670', '1035', '202', '1341', '378', '373', '1309', '546', '243', '252', '1448', '925', '537', '1241', '1207', '376', '1307', '780', '1367', '451', '1209', '660', '28', '85', '159', '676', '534', '325', '482', '1127', '494', '1081', '446', '982', '244', '1011', '1113', '504', '1264', '822', '1098', '484', '839', '513', '514', '646', '1419', '786', '1109', '579', '970', '309', '477', '560', '993', '557', '59', '1099', '846', '593', '1054', '594', '129', '674', '1460', '612', '449', '652', '1051', '1348', '582', '95', '1180', '267', '1437', '1093', '883', '723', '737', '327', '131', '1436', '1362', '132', '165', '528', '486', '1281', '727', '1358', '575', '245', '478', '866', '542', '483', '1126', '566', '637', '321', '716', '850', '704', '695', '889', '796', '318', '1378', '18', '386', '842', '641', '231', '1144', '947', '1057', '73', '547', '773', '681', '809', '419', '687', '544', '452', '1391', '626', '17', '1124', '590', '257', '515', '798', '691', '224', '567', '664', '1010', '80', '4', '1401', '1427', '955', '157', '627', '472', '151', '310', '228', '1350', '502', '689', '872', '694', '941', '801', '1227', '1236', '388', '966', '1007', '709', '617', '294', '989', '1196', '291', '1349', '742', '529', '1256', '833', '825', '1360', '762', '693', '408', '1261', '508', '492', '382', '659', '880', '1416', '820', '720', '1225', '512', '647', '739', '1137', '150', '491', '848', '1062', '317', '699', '1193', '645', '897', '340', '562', '320', '917', '710', '1067', '951', '556', '1327', '728', '1366', '400', '25', '683', '634', '1073', '610', '806', '1229', '706', '1418', '348', '802', '779', '387', '350', '1328', '1339', '700', '620', '890', '1290', '597', '1249', '754', '843', '701', '785', '1375', '250', '725', '1085', '1004', '1195', '884', '997', '1230', '795', '1148', '898', '1111', '262', '1456', '89', '1163', '519', '16', '61', '1409', '954', '102', '999', '731', '636', '522', '10', '364', '852', '1215', '1016', '467', '1117', '1317', '71', '197', '1259', '752', '332', '600', '409', '399', '871', '287', '507', '211', '288', '468', '13', '141', '840', '744', '601', '510', '741', '448', '740', '394', '841', '292', '1000', '465', '1267', '1001', '117', '1', '666', '192', '1074', '654', '726', '576', '960', '268', '380', '396', '998', '265', '1377', '295', '124', '1333', '48', '625', '1024', '830', '697', '212', '1402', '1197', '1043', '609', '44', '911', '862', '1072', '1445', '1457', '724', '984', '447', '677', '1049', '1040', '222', '888', '390', '1152', '115', '398', '200', '335', '603', '329', '106', '354', '702', '564', '1395', '104', '443', '476', '1044', '1363', '1337', '1206', '358', '208', '511', '1277', '1415', '168', '68', '838', '1425', '1147', '1091', '1417']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.181"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.646"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.283<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The need to provide personnel for the information field.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['339', '216', '131', '137', '254', '553', '1206', '412', '163', '123', '1094', '134', '125', '471', '497', '1224', '140', '17', '138', '648', '323', '898', '899', '132', '360', '136', '341', '583', '796', '1256', '1128', '1114', '388', '1070', '133', '199', '410', '1424', '60', '1016', '151', '514', '373', '1412', '1164', '1162', '905', '454', '773', '175', '363', '1325', '598', '1076', '1308', '68', '707', '770', '1179', '114', '1081', '1027', '1168', '640', '505', '460', '462', '37', '1432', '722', '107', '461', '405', '1323', '376', '243', '1207', '828', '156', '618', '325', '328', '1271', '419', '1382', '970', '1411', '257', '148', '665', '736', '1149', '1263', '1120', '973', '174', '1009', '821', '439', '676', '1348', '801', '641', '160', '482', '966', '557', '950', '504', '755', '207', '1343', '556', '472', '101', '400', '371', '1075', '791', '1218', '457', '1355', '116', '661', '198', '573', '917', '1230', '272', '344', '915', '1260', '1088', '1418', '636', '1403', '1310', '384', '586', '852', '1248', '906', '1388', '1157', '221', '1332', '215', '510', '1214', '832', '1074', '1061', '1071', '1176', '1415', '1242', '380', '778', '1140', '789', '953', '823', '1454', '943', '1020', '20', '1385', '203', '1021', '100', '1250', '617', '1045', '86', '1202', '945', '5', '1063', '354', '317', '1044', '1186', '1229', '1347', '1450', '551', '94', '735', '1346', '1215']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.032"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.240"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.056<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automated information in the medical field.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['216', '1027', '1114', '410', '174', '215', '148', '136', '203', '221', '1120', '514', '1071', '1128', '133', '131', '137', '163', '60', '373', '1412', '1094', '1164', '1162', '454', '254', '175', '363', '17', '553', '598', '1076', '471', '707', '770', '1179', '497', '323', '114', '1081', '1168', '640', '505', '460', '648', '462', '37', '899', '722', '107', '461', '132', '360', '140', '339', '1323', '1224', '376', '243', '1207', '828', '156', '583', '138', '123', '618', '796', '325', '328', '125', '341', '419', '1382', '970', '1411', '257', '665', '736', '199', '1149', '1263', '134', '1009', '821', '439', '676', '1348', '801', '641', '160', '388', '773', '482', '966', '557', '504', '1256', '755', '412', '151', '1343', '556', '472', '101', '400', '371', '1075', '791', '1218', '457', '1355', '116', '661', '198', '1070', '573', '917', '1230', '272', '344', '915', '1260', '1088', '636', '1403', '905', '1310', '384', '586', '1016', '852', '1248', '906', '1388', '1157', '1332', '510', '68', '1214', '832', '1074', '1061', '1176', '1415', '1242', '380', '778', '1140', '789', '953', '823', '1424', '1271', '898', '1454', '943', '1020', '20', '1385', '1325', '1021', '100', '1308', '1250', '973', '617', '1045', '86', '405', '1202', '945', '5', '1063', '354', '317', '1044', '1186', '950', '1206', '1229', '1347', '1450', '551', '94', '1432', '735', '207', '1346', '1215', '1418']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.047"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.170"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.074<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of use of books in libraries. Relation to need for automated information systems .\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['202', '177', '874', '979', '336', '406', '916', '990', '114', '1073', '378', '947', '459', '593', '535', '1309', '948', '126', '1139', '1053', '1125', '180', '388', '478', '560', '865', '860', '501', '1038', '174', '381', '136', '27', '572', '433', '137', '67', '1298', '358', '408', '670', '458', '1109', '538', '648', '502', '1170', '364', '925', '511', '691', '325', '1114', '449', '1349', '319', '1410', '454', '986', '1361', '641', '1236', '1193', '542', '630', '553', '165', '1110', '582', '262', '461', '267', '1035', '179', '399', '140', '846', '481', '497', '175', '1358', '25', '115', '849', '382', '252', '123', '472', '839', '73', '1171', '445', '17', '594', '644', '1360', '880', '1264', '779', '434', '327', '421', '537', '310', '16', '1007', '660', '1348', '615', '1012', '1120', '4', '1401', '376', '28', '1190', '1362', '132', '1417', '611', '526', '1333', '443', '532', '1080', '213', '1448', '607', '347', '135', '547', '375', '866', '1255', '917', '773', '1173', '664', '490', '54', '250', '1425', '621', '610', '546', '1418', '131', '1175', '409', '257', '1317', '795', '66', '1350', '848', '128', '895', '534', '645', '842', '1339', '993', '523', '200', '1152', '951', '1117', '525', '514', '49', '843', '704', '80', '309', '398', '120', '646', '64', '674', '579', '119', '1099', '254', '190', '340', '386', '1121', '61', '1092', '244', '1230', '517', '348', '982', '1128', '1136', '1241', '796', '72', '574', '1143', '1367', '528', '728', '637', '1112', '474', '1375', '1391', '1124', '725', '1077', '530', '970', '1256', '1011', '1196', '591', '245', '1223', '85', '504', '1051', '465', '872', '484', '723', '707', '1206', '1277', '557', '117', '565', '1363', '224', '1378', '350', '243', '158', '74', '898', '1395', '507', '1078', '786', '141', '762', '373', '687', '1437', '1105', '1419', '620', '1415', '897', '827', '544', '606', '889', '1044', '850', '826', '1179', '955', '682', '288', '129', '1104', '1249', '292', '452', '642', '321', '1293', '10', '1024', '396', '703', '1405', '515', '671', '883', '1413', '1106', '1305', '690', '724', '1144', '1191', '508', '1022', '1326', '597', '639', '1289', '1084', '1447', '268', '809', '389', '1057', '1282', '18', '1147', '654', '57', '1283', '447', '575', '354', '1341', '295', '798', '941', '1207', '208', '1307', '780', '451', '1209', '556', '159', '676', '482', '801', '1127', '494', '1081', '446', '647', '1113', '911', '815', '822', '1098', '513', '1267', '477', '699', '1456', '595', '59', '636', '1054', '150', '222', '1460', '612', '868', '652', '95', '1180', '1093', '737', '1436', '1062', '134', '486', '1281', '1001', '512', '727', '294', '1229', '483', '1126', '966', '566', '716', '387', '695', '617', '997', '318', '529', '231', '862', '291', '197', '884', '785', '467', '681', '1328', '419', '840', '1259', '626', '700', '590', '1085', '1040', '211', '1366', '1111', '567', '1010', '1427', '394', '287', '157', '1072', '1091', '627', '151', '228', '706', '1445', '960', '1457', '689', '841', '694', '852', '335', '1337', '265', '1377', '1227', '71', '1197', '192', '380', '709', '989', '742', '998', '833', '564', '625', '825', '693', '601', '1261', '1049', '492', '659', '1416', '448', '820', '720', '1225', '739', '1137', '491', '1043', '317', '168', '984', '562', '320', '710', '1067', '390', '888', '1215', '1327', '400', '683', '634', '806', '106', '802', '890', '1290', '754', '701', '1004', '1195', '1148', '89', '1163', '519', '1409', '954', '571', '102', '999', '731', '522', '1016', '752', '332', '600', '871', '468', '13', '744', '510', '741', '531', '740', '1000', '1', '666', '1074', '726', '576', '124', '48', '830', '697', '212', '1402', '609', '44', '677', '603', '329', '702', '104', '476', '68', '838']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.029"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.312"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.053<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Educational and training requirements for personnel in the information field. Possibilities for this training.  Needs for programs providing this training.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['896', '924', '648', '692', '405', '220', '1166', '1423', '1206', '1239', '1325', '923', '22', '1007', '558', '513', '743', '934', '371', '945', '5', '1275', '858', '1246', '197', '548', '356', '1219', '1387']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.448"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.250"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.321<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "International systems for exchange and dissemination of information.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1284', '440', '1231', '1289', '130', '1245', '1436', '1435', '360', '1362', '1303', '323', '717', '452', '138', '1256', '411', '1378', '611', '98', '1078', '1298', '49', '121', '591', '1412', '1431', '1009', '866', '1153', '490', '1297', '179', '18', '175', '341', '97', '807', '363', '796', '481', '137', '1367', '1281', '711', '513', '460', '947', '241', '497', '375', '633', '228', '941', '311', '629', '1368', '327', '59', '1391', '588', '213', '112', '127', '376', '755', '773', '728', '123', '676', '1396', '889', '80', '801', '482', '12', '1341', '529', '400', '224', '164', '1415', '1125', '607', '1128', '535', '574', '469', '1077', '1112', '1139', '1121', '254', '1158', '1105', '1103', '1116', '474', '66', '85', '1038', '1094', '1156', '1155', '1053', '1191', '1171', '1092', '539', '1190', '1166', '122', '1305', '1223', '540', '599', '458', '1161', '538', '135', '347', '459', '362', '1101', '136', '202', '372', '1096', '1361', '565', '585', '1122', '1405', '152', '640', '630', '166', '453', '445', '2', '1106', '839', '707', '1309', '29', '454', '60', '1102', '820', '429', '1173', '965', '140', '1098', '803', '1373', '338', '74', '646', '461', '621', '131', '648', '1143', '572', '1012', '57', '126', '1089', '837', '575', '982', '133', '1099', '1011', '730', '1037', '598', '1110', '373', '1100', '475', '636', '1114', '942', '655', '477', '1022', '1326', '560', '1136', '1115', '1084', '1447', '147', '1220', '1181', '642', '346', '1081', '1059', '158', '1027', '658', '592', '1113', '1138', '1095', '582', '95', '456', '1407', '733', '532', '163', '27', '471', '501', '972', '1080', '967', '1408', '1179', '537', '639', '631', '114', '1104', '1107', '722', '1364', '1198', '516', '67', '842', '656', '449', '652', '496', '119', '321', '1208', '907', '910', '1076', '1264', '161', '378', '671', '1174', '1164', '434', '129', '546', '243', '252', '684', '899', '1162', '786', '844', '1178', '3', '1410', '971', '845', '526', '533', '156', '1170', '771', '525', '827', '846', '1169', '624', '487', '606', '421', '1282', '835', '1129', '1428', '660', '1460', '544', '692', '32', '1258', '1283', '553', '1296', '330', '703', '723', '664', '814', '719', '1224', '462', '132', '1144', '120', '783', '690', '948', '1307', '1241', '1207', '1295', '1123', '466', '419', '478', '901', '319', '180', '142', '615', '1145', '1013', '463', '218', '15', '1421', '96', '159', '1134', '509', '1127', '494', '257', '1042', '176', '54', '1413', '392', '1244', '704', '1054', '34', '1120', '815', '826', '386', '1130', '686', '970', '761', '274', '1189', '828', '584', '583', '536', '1299', '665', '682', '1293', '916', '444', '770', '1108', '488', '81', '1437', '1093', '1446', '590', '568', '145', '1404', '328', '578', '853', '616', '900', '339', '925', '554', '528', '486', '885', '780', '1358', '451', '1209', '680', '64', '72', '78', '381', '389', '1126', '325', '1124', '1370', '1201', '797', '446', '174', '914', '736', '199', '1151', '318', '128', '216', '310', '1018', '28', '718', '1383', '63', '641', '523', '1323', '231', '580', '79', '33', '829', '473', '851', '1057', '73', '352', '505', '681', '334', '819', '314', '336', '1132', '439', '1392', '388', '604', '626', '1167', '937', '1035', '1419', '433', '267', '1448', '1168', '1349', '518', '134', '125', '672', '160', '177', '762', '1109', '727', '162', '1382', '37', '90', '567', '534', '623', '790', '1390', '1010', '214', '1411', '764', '545', '220', '993', '895', '4', '1401', '955', '990', '670', '148', '1266', '157', '425', '716', '850', '345', '225', '696', '612', '695', '769', '1051', '1348', '1430', '6', '1180', '151', '1350', '258', '712', '1263', '406', '340', '737', '956', '679', '23', '502', '244', '420', '442', '30', '504', '557', '763', '236', '721', '1146', '822', '1160', '1192', '547', '602', '922', '514', '644', '245', '1227', '259', '817', '674', '542', '1165', '577', '1032', '966', '309', '483', '799', '1232', '566', '637', '484', '139', '883', '865', '1196', '705', '563', '515', '155', '579', '450', '324', '691', '1356', '678', '53', '371', '930', '41', '986', '293', '206', '1442', '173', '675', '1422', '1427', '935', '165', '924', '784', '595', '809', '687', '848', '1318', '169', '1255', '627', '190', '472', '743', '562', '1047', '622', '619', '184', '506', '593', '367', '798', '951', '556', '594', '1149', '470', '618', '1393', '694', '412', '1426', '981', '379', '772', '628', '107', '1175', '958', '348', '946', '178', '260', '964', '957', '480', '495', '426', '408', '963', '457', '701', '688', '811', '62', '248', '813', '150', '1055', '661', '320', '657', '47', '1253', '816', '512', '1265', '589', '1248', '821', '17']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.034"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.667"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.065<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost and determination of cost associated with systems of automated information.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['865', '490', '690', '615', '336', '74', '629', '822', '1100', '639', '839', '584', '158', '497', '591', '671', '321', '433', '27', '623', '214', '842', '367', '1305', '324', '482', '495', '1264', '1151', '1410', '572', '466', '1361', '177', '723', '1139', '1027', '1390', '126', '1297', '180', '704', '17', '348', '1258', '1368', '594', '496', '813', '1298', '1114', '1092', '218', '1421', '851', '737', '334', '174', '1404', '80', '1358', '311', '1132', '1013', '675', '807', '1396', '515', '889', '790', '446', '958', '450', '486', '202', '848', '166', '809', '523', '136', '990', '916', '922', '12', '957', '176', '528', '457', '406', '1196', '674', '811', '1054', '644', '1120', '784', '408', '1124', '986', '694', '426', '400', '1248', '512', '1125', '607', '1128', '535', '574', '469', '1077', '1112', '1121', '175', '254', '375', '137', '1158', '1105', '1103', '1116', '474', '66', '85', '1038', '1094', '1156', '1155', '1053', '1191', '1078', '1171', '539', '1190', '1166', '122', '1223', '540', '599', '179', '458', '1161', '538', '135', '347', '363', '123', '459', '362', '1101', '372', '1096', '565', '585', '1122', '1405', '152', '640', '1367', '630', '453', '445', '2', '1106', '707', '1309', '29', '454', '60', '1102', '429', '717', '1173', '965', '140', '323', '1098', '803', '376', '1373', '338', '646', '461', '621', '131', '611', '648', '1143', '1012', '57', '1089', '837', '575', '982', '133', '481', '1099', '1011', '730', '1037', '598', '1110', '373', '241', '513', '475', '942', '655', '477', '1022', '1326', '560', '1136', '1115', '327', '1084', '1447', '147', '1362', '1220', '1181', '642', '346', '1081', '1059', '658', '592', '1113', '1138', '1095', '582', '95', '456', '1407', '733', '532', '163', '471', '501', '972', '440', '1080', '967', '1408', '1179', '537', '631', '121', '1431', '114', '1104', '1107', '722', '1364', '1198', '516', '67', '656', '449', '652', '119', '460', '1208', '138', '907', '910', '1076', '161', '378', '1174', '1164', '434', '129', '546', '243', '252', '684', '899', '1162', '786', '844', '1178', '3', '971', '845', '1289', '49', '526', '533', '156', '1170', '771', '525', '827', '846', '1169', '624', '487', '606', '421', '1282', '835', '1129', '1428', '660', '1460', '544', '692', '32', '1283', '553', '1296', '330', '703', '664', '814', '719', '1224', '462', '132', '1144', '120', '783', '711', '947', '948', '1307', '1241', '1207', '1295', '1123', '419', '478', '1303', '901', '319', '142', '1145', '1153', '463', '15', '96', '159', '1134', '509', '1127', '494', '257', '1042', '213', '54', '1413', '633', '392', '1244', '34', '796', '815', '1378', '18', '826', '386', '98', '1130', '686', '970', '761', '1245', '274', '1189', '828', '1284', '583', '536', '1299', '665', '682', '1293', '444', '770', '1108', '488', '81', '1437', '1093', '1446', '590', '127', '568', '145', '328', '578', '853', '130', '616', '900', '339', '925', '554', '1281', '885', '780', '451', '1209', '680', '64', '72', '78', '381', '389', '1126', '325', '1370', '1201', '797', '914', '736', '199', '1412', '318', '128', '216', '310', '97', '1018', '28', '718', '1383', '63', '641', '1323', '231', '580', '79', '33', '829', '473', '1057', '73', '352', '505', '59', '681', '773', '819', '314', '588', '439', '1392', '452', '388', '604', '626', '1167', '937', '1035', '1419', '267', '1448', '1168', '1349', '518', '1436', '134', '125', '672', '160', '762', '1109', '727', '162', '1382', '37', '90', '567', '676', '534', '411', '1010', '866', '1411', '764', '545', '220', '993', '895', '4', '1401', '112', '955', '670', '148', '1266', '157', '425', '716', '850', '345', '1435', '225', '696', '612', '695', '769', '1051', '1348', '1430', '6', '1180', '151', '1350', '258', '712', '1263', '340', '956', '679', '23', '502', '244', '420', '442', '30', '504', '557', '763', '360', '236', '721', '1146', '1160', '1192', '1341', '941', '801', '547', '602', '514', '245', '1227', '259', '817', '542', '1165', '577', '1009', '1032', '966', '309', '1391', '483', '799', '1232', '566', '637', '484', '139', '883', '705', '563', '155', '529', '1256', '579', '691', '224', '1356', '678', '53', '371', '930', '41', '293', '206', '1442', '173', '1422', '1427', '820', '935', '165', '924', '595', '687', '1318', '169', '1255', '627', '190', '472', '743', '562', '1047', '622', '619', '755', '228', '184', '506', '593', '798', '951', '556', '1149', '470', '618', '164', '1393', '412', '1426', '981', '379', '772', '728', '628', '107', '1175', '946', '178', '260', '964', '480', '963', '701', '688', '341', '62', '248', '150', '1055', '661', '320', '657', '47', '1253', '1231', '816', '636', '1265', '589', '821', '1415']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.055"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.625"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.100<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computerized information retrieval systems.  Computerized indexing systems.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1293', '1078', '74', '773', '375', '727', '1197', '798', '693', '1193', '461', '865', '565', '376', '257', '1366', '458', '512', '538', '434', '591', '884', '1139', '117', '389', '595', '72', '1448', '1298', '644', '609', '159', '57', '566', '446', '1445', '1136', '590', '660', '1126', '1283', '1419', '630', '611', '507', '459', '615', '889', '478', '445', '381', '348', '135', '1127', '254', '378', '1092', '1170', '1125', '67', '1171', '1120', '501', '504', '1010', '822', '637', '1038', '481', '530', '400', '659', '474', '1012', '827', '796', '826', '497', '648', '606', '319', '1144', '593', '1143', '175', '707', '1053', '1121', '120', '526', '645', '523', '517', '825', '179', '703', '1128', '1255', '966', '1413', '574', '1179', '1124', '690', '709', '27', '114', '140', '1112', '670', '641', '532', '1077', '534', '1223', '514', '510', '535', '579', '525', '607', '484', '451', '309', '158', '682', '779', '594', '1110', '421', '1405', '454', '180', '1282', '1173', '123', '925', '556', '986', '213', '780', '621', '1215', '388', '336', '883', '1307', '128', '1341', '1080', '49', '28', '64', '553', '54', '151', '1104', '993', '1305', '66', '1035', '948', '433', '119', '522', '689', '1105', '671', '482', '1180', '1191', '165', '642', '243', '252', '1081', '483', '676', '244', '737', '1410', '490', '267', '126', '1190', '1289', '830', '1230', '1209', '486', '531', '1264', '406', '639', '325', '1054', '557', '866', '916', '1109', '1022', '1326', '528', '801', '1106', '674', '1084', '1447', '1241', '1207', '73', '716', '68', '318', '695', '137', '508', '612', '129', '1051', '1348', '617', '546', '59', '1391', '347', '494', '600', '815', '1361', '537', '687', '547', '245', '382', '542', '1436', '970', '262', '136', '560', '373', '895', '134', '872', '492', '839', '177', '1024', '1114', '806', '681', '575', '515', '202', '1309', '795', '472', '571', '990', '452', '321', '1236', '1327', '1437', '1093', '626', '634', '567', '786', '1007', '1367', '704', '1072', '850', '1113', '294', '989', '291', '1281', '610', '706', '982', '1358', '809', '846', '1011', '742', '327', '1362', '860', '1460', '833', '513', '1360', '979', '1098', '85', '723', '646', '477', '627', '1261', '131', '132', '880', '449', '652', '1416', '754', '720', '1225', '702', '647', '1099', '739', '620', '231', '1137', '582', '95', '691', '874', '491', '224', '1057', '1062', '317', '699', '174', '502', '897', '572', '519', '61', '917', '1427', '212', '710', '1378', '18', '664', '386', '1067', '785', '190', '228', '25', '71', '683', '1196', '731', '849', '898', '1073', '694', '701', '4', '1401', '1229', '947', '955', '1418', '157', '419', '802', '387', '871', '390', '842', '350', '1328', '562', '1117', '1339', '1350', '700', '544', '890', '448', '1259', '1290', '1175', '80', '597', '1249', '941', '728', '1227', '408', '843', '468', '820', '762', '1375', '250', '310', '725', '1085', '1004', '1195', '997', '150', '1148', '529', '1256', '1363', '1111', '197', '320', '625', '1377', '1456', '89', '1163', '636', '16', '1409', '954', '1349', '1277', '102', '999', '848', '10', '364', '852', '1016', '467', '868', '1317', '951', '752', '332', '409', '399', '287', '211', '288', '13', '340', '141', '840', '744', '44', '601', '741', '740', '394', '841', '292', '1000', '603', '465', '1267', '1001', '1', '1147', '666', '192', '1074', '654', '726', '576', '960', '268', '380', '396', '998', '329', '265', '295', '124', '1333', '48', '697', '1402', '17', '1043', '911', '862', '1457', '724', '984', '447', '677', '1049', '1040', '222', '888', '838', '1152', '115', '398', '200', '335', '106', '354', '564', '1395', '104', '443', '476', '1044', '1337', '1206', '358', '208', '511', '168', '1425', '1091', '1415', '1417']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.132"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.591"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.216<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computerized information systems in fields related to chemistry.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['696', '156', '116', '676', '1092', '1120', '1164', '1162', '1460', '641', '460', '618', '722', '85', '151', '691', '755', '198', '739', '150', '371', '86', '1072', '953', '705', '731', '735', '743', '619', '1347', '255', '1452', '635', '1275']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.471"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.267"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.340<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific advantages of computerized index systems.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['74', '512', '390', '1197', '1136', '49', '1144', '1419', '61', '1293', '701', '80', '595', '1413', '773', '780', '1416', '693', '798', '1193', '647', '1170', '690', '492', '321', '566', '398', '1366', '27', '446', '727', '1078', '465', '213', '825', '406', '257', '472', '884', '865', '117', '630', '44', '682', '1361', '511', '350', '262', '375', '1111', '1339', '165', '1283', '687', '389', '400', '731', '224', '1113', '1080', '386', '517', '243', '741', '531', '1277', '699', '740', '603', '609', '606', '1445', '820', '720', '364', '660', '222', '1326', '677', '1010', '507', '461', '523', '1395', '1261', '318', '779', '476', '1099', '641', '510', '373', '889', '1057', '582', '85', '547', '376', '348', '809', '562', '1418', '522', '1230', '126', '202', '1091', '1024', '830', '1124', '212', '796', '600', '190', '575', '571', '1040', '636', '448', '590', '197', '329', '615', '702', '150', '591', '458', '538', '419', '129', '689', '872', '1038', '1341', '1236', '611', '135', '1007', '709', '1143', '670', '617', '336', '294', '501', '989', '291', '742', '826', '67', '593', '594', '128', '860', '1092', '833', '120', '1360', '484', '979', '180', '254', '579', '482', '481', '497', '1035', '459', '319', '244', '986', '1121', '433', '508', '504', '822', '421', '1448', '382', '827', '659', '880', '532', '514', '64', '445', '72', '309', '676', '534', '1225', '739', '1137', '140', '874', '491', '1062', '317', '158', '54', '645', '897', '557', '381', '1125', '526', '917', '1128', '674', '1171', '474', '1110', '710', '574', '883', '1067', '553', '1223', '28', '707', '1109', '703', '1112', '1139', '1327', '993', '948', '1173', '25', '683', '925', '565', '634', '612', '849', '1073', '621', '1077', '1051', '1348', '451', '1209', '1180', '648', '1179', '610', '806', '737', '535', '325', '1229', '706', '114', '1104', '1053', '607', '644', '245', '802', '119', '542', '387', '1328', '483', '637', '671', '916', '434', '59', '179', '700', '1410', '620', '890', '1290', '1289', '525', '597', '267', '1298', '1249', '1436', '1282', '134', '754', '123', '843', '177', '642', '785', '175', '866', '1375', '250', '1241', '990', '1207', '725', '1085', '1004', '1307', '1195', '716', '997', '850', '795', '695', '159', '1148', '898', '639', '1127', '494', '1120', '815', '1105', '530', '970', '1456', '1391', '89', '1163', '378', '519', '16', '546', '252', '1022', '1409', '954', '515', '102', '1084', '1447', '999', '691', '1437', '1093', '10', '852', '1215', '1016', '467', '1117', '1405', '528', '486', '1427', '868', '1317', '1281', '1358', '71', '1106', '1259', '454', '537', '1255', '752', '332', '1126', '1054', '627', '409', '228', '399', '871', '287', '211', '288', '468', '13', '694', '141', '490', '840', '744', '1264', '1305', '1012', '57', '231', '601', '73', '786', '347', '681', '394', '841', '66', '452', '292', '1000', '626', '846', '1114', '1267', '1001', '1', '666', '408', '1191', '1460', '192', '1074', '654', '726', '576', '1081', '723', '136', '1190', '960', '567', '132', '268', '895', '4', '1401', '380', '396', '955', '998', '157', '265', '478', '1377', '1309', '320', '295', '151', '124', '1333', '1350', '48', '625', '697', '704', '982', '502', '1011', '1367', '1402', '1378', '18', '449', '652', '941', '801', '1227', '513', '1043', '911', '862', '1072', '966', '477', '1457', '724', '984', '560', '1196', '447', '1049', '137', '1098', '529', '1256', '646', '888', '95', '839', '1152', '115', '200', '848', '335', '106', '354', '947', '174', '564', '104', '327', '951', '443', '556', '1044', '1362', '1363', '310', '572', '1337', '728', '1206', '358', '1175', '208', '388', '168', '68', '131', '17', '838', '544', '1349', '842', '762', '1425', '340', '1147', '664', '1417', '1415']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.041"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.438"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.075<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information dissemination by journals and periodicals.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['112', '225', '1114', '1055', '905', '10', '1109', '1097', '198', '494', '199', '1432', '472', '821', '379', '2', '1098', '777', '1168', '210', '790', '765', '1352', '782', '587', '177', '933', '977', '1086', '1260', '865', '792', '951', '1172', '788', '65', '766', '800', '237', '750', '1090', '816', '793', '791', '551']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.578"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.194"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.291<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information systems in the physical sciences.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['535', '1297', '1370', '1309', '545', '1348', '313', '111', '1179', '804', '137', '85', '1173', '439', '497', '537', '604', '123', '459', '140', '135', '136', '553', '607', '469', '1386', '646', '1405', '1318', '1283', '1022', '652', '786', '599', '1109', '621', '1341', '131', '555', '572', '1338', '640', '60', '456', '1080', '49', '1362', '1181', '837', '1113', '133', '1207', '355', '1094', '513', '243', '598', '1387', '1027', '1169', '172', '372', '132', '373', '1010', '202', '582', '95', '585', '1161', '1436', '544', '126', '803', '1284', '327', '1428', '1051', '557', '866', '1346', '796', '386', '462', '138', '486', '899', '1123', '96', '1303', '363', '496', '163', '199', '914', '592', '338', '505', '1178', '844', '845', '989', '1349', '2', '323', '773', '1198', '616', '371', '339', '460', '1208', '554', '162', '314', '166', '1067', '350', '1339', '1062', '966', '722', '1016', '1249', '1258', '807', '1192', '98', '686', '819', '761', '334', '1085', '1299', '583', '820', '151', '155', '1111', '692', '636', '160', '885', '764', '112', '1040', '743', '619', '1047', '345', '736', '1337', '1175', '258', '1263', '150', '1146', '79', '602', '259', '817', '577', '47', '1030', '1044', '1328', '139', '311', '1142', '898', '1277', '1087', '1442', '25', '784', '102', '960', '187', '1228', '1345', '268', '755', '618', '789', '48', '766', '628', '958', '100', '1330', '1310', '186', '415', '457', '1444', '109', '1274', '89', '188', '688', '813', '1313', '1055', '398', '1291', '1235', '1344', '106', '1301', '113', '1312', '1395', '1177', '104', '1273', '1270', '185', '357', '289', '632', '1314', '749', '103', '31', '101', '384', '788', '110', '614', '713', '912', '116', '1154', '1315', '1432', '1029', '1449', '685', '1147', '343', '891', '1304', '1068', '226', '1061', '1135', '1242', '256', '1415', '1082', '414', '893', '410', '857', '558', '333', '437', '823', '1271', '1262', '635', '1091', '729', '356', '1188', '1325', '407', '1458', '1398', '195', '1308', '638', '1213', '263', '774', '923', '1342', '933', '1311', '269', '1186', '210', '1347', '613', '1187']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.074"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.344"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.121<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempts at computerized and mechanized systems for general libraries. Problems and methods of automated general author and title indexing systems.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['336', '865', '849', '64', '553', '644', '451', '265', '1298', '117', '1230', '916', '497', '158', '530', '1448', '820', '1124', '595', '830', '1416', '979', '1000', '434', '582', '676', '1197', '72', '860', '822', '709', '1139', '590', '874', '177', '773', '1024', '1259', '510', '262', '398', '660', '1010', '888', '179', '597', '517', '565', '825', '244', '257', '620', '309', '615', '1419', '159', '192', '654', '1241', '1120', '1067', '690', '889', '4', '1401', '175', '609', '73', '1193', '319', '25', '1105', '335', '54', '884', '557', '796', '180', '389', '150', '476', '406', '18', '1053', '798', '1179', '433', '1293', '1012', '348', '1391', '228', '482', '504', '699', '1126', '603', '483', '354', '880', '593', '1191', '998', '292', '848', '212', '645', '693', '1281', '525', '534', '986', '507', '1127', '826', '659', '1366', '1195', '120', '519', '993', '641', '1418', '376', '1084', '1447', '842', '174', '364', '1196', '484', '990', '514', '606', '67', '666', '1436', '1173', '1362', '1229', '1215', '254', '375', '843', '388', '1348', '639', '252', '134', '1035', '291', '151', '128', '136', '706', '795', '1249', '350', '701', '446', '373', '1163', '512', '725', '465', '468', '141', '1081', '1427', '250', '1360', '74', '591', '815', '627', '1091', '890', '951', '85', '287', '1349', '17', '727', '1078', '594', '321', '1209', '740', '454', '458', '477', '538', '123', '168', '1136', '325', '408', '726', '779', '1445', '478', '268', '827', '948', '566', '1256', '1175', '702', '571', '683', '89', '572', '802', '960', '1261', '381', '1113', '1121', '1236', '1072', '1341', '1180', '648', '1283', '611', '670', '340', '1007', '1125', '515', '1114', '610', '1339', '1092', '386', '1457', '1405', '57', '13', '419', '1375', '737', '537', '522', '394', '687', '481', '556', '872', '310', '710', '694', '647', '1111', '1223', '288', '1425', '707', '523', '61', '317', '576', '1327', '1309', '382', '970', '135', '917', '294', '1', '600', '966', '637', '1044', '617', '461', '200', '140', '806', '1057', '703', '114', '925', '1171', '44', '459', '1098', '409', '838', '1460', '841', '1190', '1255', '1074', '1004', '1410', '245', '16', '390', '1144', '1326', '621', '1051', '190', '601', '399', '689', '1333', '634', '1227', '267', '387', '1038', '126', '1358', '378', '839', '531', '1328', '129', '607', '1367', '630', '115', '700', '320', '883', '472', '1143', '332', '866', '997', '222', '1170', '682', '501', '989', '119', '1093', '742', '1147', '447', '833', '502', '467', '1117', '1054', '448', '27', '724', '579', '1085', '1106', '213', '197', '508', '850', '157', '1049', '492', '421', '532', '731', '911', '445', '208', '720', '1225', '1040', '1317', '739', '1016', '1137', '664', '491', '1062', '546', '547', '68', '71', '840', '1413', '897', '165', '526', '211', '1128', '674', '474', '1110', '574', '801', '28', '528', '1109', '1112', '49', '1206', '1437', '10', '852', '1267', '1363', '780', '612', '1080', '1073', '1077', '955', '535', '625', '1104', '243', '452', '542', '224', '846', '575', '671', '295', '59', '327', '1264', '1378', '1377', '1290', '1289', '1282', '786', '754', '809', '642', '982', '785', '652', '941', '1207', '1307', '862', '716', '695', '1148', '898', '494', '1011', '560', '400', '1099', '137', '1043', '947', '1152', '1456', '984', '1022', '1409', '1395', '954', '1277', '102', '999', '358', '202', '691', '1350', '486', '868', '752', '728', '871', '318', '1337', '529', '490', '744', '1305', '231', '741', '347', '681', '66', '626', '1361', '1001', '80', '723', '567', '132', '895', '380', '396', '124', '48', '697', '704', '1402', '449', '513', '677', '646', '95', '329', '106', '562', '564', '104', '443', '511', '131', '544', '1417', '762', '1415', '636']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.121"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.530"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.197<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval systems which provide for the automated transmission of information to the user from a distance.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['519', '400', '1365', '1234', '949', '551']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Methods of coding used in computerized index systems.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1180', '1391', '689', '117', '737', '670', '865', '693', '1197', '1366', '595', '390', '731', '798', '508', '309', '72', '1293', '446', '44', '472', '389', '1092', '257', '321', '682', '1024', '1326', '262', '890', '1193', '889', '690', '603', '512', '381', '820', '1035', '318', '677', '376', '510', '1057', '158', '566', '611', '483', '553', '461', '74', '727', '1078', '212', '522', '825', '1419', '49', '773', '1309', '884', '1124', '571', '1261', '641', '1044', '71', '244', '375', '809', '562', '830', '1283', '687', '1416', '291', '179', '1091', '224', '683', '565', '827', '129', '517', '1230', '741', '531', '27', '478', '1277', '699', '740', '190', '175', '815', '609', '1040', '606', '1105', '1445', '200', '701', '720', '842', '660', '1125', '1121', '742', '1191', '1010', '507', '615', '648', '860', '833', '1190', '448', '647', '989', '254', '1126', '1341', '659', '451', '1360', '222', '1179', '1144', '523', '1127', '610', '1395', '325', '1053', '73', '779', '739', '530', '822', '197', '504', '707', '1163', '400', '703', '709', '150', '1327', '582', '525', '547', '593', '1298', '621', '317', '64', '806', '998', '883', '348', '80', '486', '134', '754', '61', '642', '666', '295', '802', '332', '697', '350', '1339', '208', '850', '840', '601', '1098', '796', '600', '841', '1361', '252', '192', '515', '1152', '4', '1401', '1016', '590', '1358', '327', '265', '575', '1377', '151', '625', '728', '228', '124', '1367', '1175', '16', '329', '911', '862', '702', '1136', '591', '458', '538', '419', '872', '373', '1038', '1236', '135', '630', '1007', '1143', '1054', '408', '617', '336', '294', '1170', '501', '511', '1099', '115', '826', '67', '594', '128', '120', '484', '979', '180', '579', '482', '481', '497', '213', '459', '319', '986', '433', '492', '421', '1448', '382', '880', '532', '514', '354', '445', '676', '534', '1225', '1137', '556', '140', '874', '491', '1062', '406', '54', '1413', '645', '897', '557', '165', '526', '917', '1128', '674', '1171', '474', '1110', '710', '574', '1067', '1223', '28', '1109', '1112', '1139', '993', '948', '1173', '25', '925', '634', '780', '612', '849', '1080', '1073', '1077', '1051', '1348', '1209', '17', '535', '1229', '706', '114', '1104', '1418', '838', '607', '644', '245', '119', '542', '387', '1328', '637', '671', '762', '916', '434', '59', '700', '1410', '620', '1290', '1289', '597', '267', '1249', '1436', '1282', '123', '843', '177', '785', '866', '1375', '250', '1241', '990', '1207', '725', '1085', '1004', '1307', '1195', '716', '997', '795', '695', '340', '159', '1148', '898', '639', '494', '1111', '1147', '1120', '636', '970', '1456', '1415', '89', '378', '519', '546', '243', '1022', '1409', '954', '102', '1084', '1447', '999', '691', '1437', '1093', '10', '364', '852', '1215', '467', '1117', '1405', '528', '1427', '868', '1317', '1281', '1106', '1259', '1417', '454', '537', '1255', '752', '627', '409', '399', '871', '287', '211', '288', '468', '13', '694', '141', '490', '744', '1264', '1305', '126', '1012', '57', '231', '786', '347', '681', '394', '66', '452', '292', '1000', '465', '626', '846', '1114', '1267', '1001', '1', '1460', '1074', '654', '726', '576', '1081', '723', '136', '960', '567', '132', '1113', '268', '895', '380', '396', '955', '157', '320', '202', '1333', '1350', '48', '704', '982', '502', '1011', '1402', '1378', '18', '449', '652', '941', '801', '386', '1227', '513', '1043', '1072', '966', '477', '1457', '724', '984', '560', '1196', '447', '1049', '137', '529', '1256', '646', '888', '95', '839', '398', '848', '335', '106', '85', '947', '174', '564', '104', '951', '443', '476', '1362', '1363', '310', '572', '1337', '1206', '358', '388', '168', '68', '131', '544', '1349', '1425', '664']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.053"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.711"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.098<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Government supported agencies and projects dealing with information dissemination.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['375', '18', '1362', '1298', '889', '481', '360', '341', '717', '1078', '611', '121', '49', '1284', '440', '490', '1297', '591', '175', '363', '179', '137', '1367', '241', '460', '513', '866', '711', '629', '1368', '327', '633', '1281', '376', '138', '123', '311', '1396', '127', '213', '59', '112', '80', '676', '728', '1415', '801', '482', '529', '1256', '1341', '224', '164', '870', '820', '1438', '636', '720', '398']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.034"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.047"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.039<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some of the theories and practices in computer translating of texts from one national language to another?  How can machine translating compete with traditional methods of translating in comprehending nuances of meaning in languages of different structures?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['320', '1443', '175', '1046', '19', '1129', '530', '228', '1077', '1118', '419', '817', '637', '1381', '755', '1385', '1020', '746', '1427', '434', '1333', '1180', '1398', '1136', '105', '227', '1386', '343', '218', '936', '387', '25', '1080', '93', '1391', '671', '516', '1313', '1399', '694', '339', '581', '1159', '697', '890', '1387', '1204', '534', '1261', '206', '327', '1340', '954', '686', '816', '461', '1388', '610', '875', '512', '705', '1065', '668', '874', '1128', '1394', '673', '762', '758', '737', '681', '679', '708', '1133', '1346', '704', '544', '1119', '1160', '1092', '675', '606', '670', '669', '715', '972', '678', '501', '1392', '569', '833', '1213', '1345', '700', '95', '803', '511', '706', '616', '923', '1036', '602', '731', '80', '233', '885', '109', '318', '1389', '691', '682', '412', '781', '1110', '1169', '311', '1141', '1068', '15', '1312', '843', '1140', '1177', '709', '695', '1274', '435', '283', '107', '402', '346', '128', '214', '620', '1407', '7', '567', '442', '285', '955', '642', '961', '1271', '849', '1062', '632', '173', '1368', '176', '505', '129']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.047"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What lists of words useful for indexing or classifying material are available?  Wanted are lists of terms that are descriptive vocabularies of particular fields or schedules of words that are related to each other in meaningful schemes.  Wanted are lists that have been tested, at least to some extent, and found useful for organizing material and for retrieving it.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['641', '676', '636', '814', '674']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can access words in an information retrieval system be kept up to date? Word meanings and usage often change and lists must be dynamic to be current. What definitions of the problem and progress toward solutions have been made in providing necessary flexibility in systems of subject headings, index words, or other symbols used for getting at stored data?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1215', '1091', '329', '567', '807', '363', '1366', '68', '310', '523', '661', '1417', '594', '835', '512', '650', '571', '504', '160', '862', '1144', '533', '450', '1415', '167', '44', '527', '1077', '140', '1328', '758', '702', '129', '85', '728', '193', '1277', '373', '809', '502', '1136', '461', '307', '1418', '1369', '1241', '158', '343', '123', '674', '564', '993', '472', '378', '395', '448', '233', '738', '568', '1090', '78', '465', '737', '1001', '186', '703', '976', '115', '1042', '669', '919', '894', '1454', '346', '958', '204', '156', '879', '345', '1377', '552', '400', '376', '125', '507', '611', '330', '841', '757', '409', '1444', '1368', '1174', '905', '290', '516', '1396', '42', '586', '528', '1254', '977', '428', '1399', '1433', '439', '1000', '148', '202', '137', '521', '541', '73', '851', '107', '888', '486', '1039', '720', '442', '1009', '637', '207', '1432', '733', '295', '579', '441', '813', '408', '635', '1350', '873', '778', '727', '185', '987', '742', '496', '815', '1408', '126', '41', '153', '922', '617', '705', '1135', '422', '311', '280', '799', '1092', '513', '878', '741', '740', '423', '1074', '612', '690', '1255', '598', '732', '729', '243', '124', '604', '609', '546', '857', '495', '743', '105', '772', '842', '529', '1378', '128', '1082', '597', '900', '178', '1370', '623', '475', '618', '1044', '917', '458', '693', '538', '691', '1334', '357', '526', '292', '760', '1352', '121', '511', '92', '631', '1070', '375', '736', '412', '492', '714', '1013', '1252', '474', '964', '867', '692', '1346', '104', '707', '1016', '948', '572', '98', '1123', '426', '822', '490', '358', '981', '970', '1129', '614', '411', '208', '913', '1097', '880', '1142', '59', '217', '187', '1232', '223', '127', '1143', '1376', '683', '145', '380', '89', '491', '1193', '999', '1096', '645', '55', '1407', '180', '1109', '1436', '74', '406', '374', '1426', '1245', '1375', '734', '877', '1356', '751', '313', '1244', '998', '584', '365', '787', '1043', '646', '984', '629', '1099', '808', '205', '83', '299', '337', '1154', '1291', '438', '81', '1453', '111', '206', '748', '638', '108', '1321', '52']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The progress of information retrieval presents problems of maladjustment and dislocation of personnel.  Training and retraining of people to use the new equipment is important at all levels.  Librarians, assistants, technicians, students, researchers, and even executives will need education to learn the purpose, values, and uses of information systems and hardware. What programs have been developed to change the attitudes and skills of traditional workers and help them to learn the newer techniques?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['612', '388', '692', '327', '274', '136', '140', '373', '575', '907', '1051', '593', '821', '357', '409', '291', '408', '248', '945', '5', '598', '795', '556', '341', '579', '174', '479', '1130', '1362', '714', '335', '126', '504', '577', '120', '630', '646', '1090', '151', '1317', '1263', '1047', '298', '1144', '133', '592', '370', '1183', '496', '1274', '636', '637', '1242', '273', '711', '798', '643', '606', '132', '1421', '671', '511', '360', '982', '1405', '1361', '278', '359', '121', '1027', '1215', '780', '1207', '642', '660', '30', '1414', '1450', '1416', '446', '94', '967', '424', '361', '1139', '1398', '830', '302', '426', '90', '489', '627', '474', '422', '1092', '835', '824', '922', '495', '563', '737', '571', '801', '561', '493', '1075', '487', '616', '841', '1313', '279', '1126', '1315', '15', '633', '587', '676', '1124', '500', '754', '709', '1127', '466', '731', '684', '810', '959', '1064', '682', '1234', '1319', '1091', '315', '936', '678', '1353', '317', '962', '620', '623', '963', '527', '800', '785', '602', '706', '715', '603', '506', '69', '522', '564', '663', '316', '427', '867', '662', '56', '734', '1359', '499', '758']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.006"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.056"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.011<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the status of machine translation?  What progress has been made in the use of computers to transfer from one language to another with some degree of automation?  What problems and stumbling blocks have been found and are they considered to be insurmountable limitations or only challenging to the field of documentation on an international scale?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['769', '360', '490', '517', '317', '124', '601', '341', '610', '757', '1031', '482', '483', '682', '1274', '494', '417', '43', '486', '347', '475', '1048', '1098']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.056"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is alphabetical ordering of material considered to be a useful tool in information retrieval?  What studies have been done to compare the effectiveness of alphabetical order with other organization schemes? Is there a generally accepted form of arranging material in alphabetical order, and is there an easy way of achieving this form without going to a great amount of effort?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['62', '351', '93', '962', '353', '520', '132', '1333', '500', '1423', '912', '1372', '1359', '391', '1430', '1408', '1094', '17', '317', '594', '460', '174', '470', '505', '1251', '1277', '994', '1005', '448', '1072', '947', '624', '133', '126', '954', '206', '821', '286', '1449', '91', '6', '921', '463', '94', '889', '496', '154', '908', '1441', '932', '1337', '1079', '1455', '668', '755', '970', '497', '1145', '640', '1379', '948', '347', '1012', '1069', '814', '1429', '416', '977', '572', '250', '885', '1144', '438', '1273', '141', '90', '384', '957', '211', '280', '235', '1017', '558', '884', '1420', '1328', '1016', '409', '343']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average student or researcher has difficulty in comprehending the vocabulary of information retrieval.  It appears important that this new field be understood before it is to be fully accepted.  What basic articles would provide an understanding of the various important aspects of the information storage and retrieval?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['459', '254', '1179', '575', '123', '461', '460', '630', '1405', '472', '68', '131', '1158', '1259', '591', '1364', '655', '889', '1323', '486', '156', '30', '1448', '664', '606', '462', '611', '375', '839', '160', '454', '446', '644', '497', '176', '114', '120', '780', '590', '1164', '501', '259', '1162', '528', '363', '547', '1248', '458', '538', '252', '135', '471', '525', '174', '376', '490', '496', '728', '1362', '592', '197', '761', '175', '1305', '1130', '126', '381', '670', '641', '1190', '838', '309', '1009', '378', '1125', '1170', '481', '478', '334', '257', '595', '600', '1027', '579', '1180', '1124', '137', '598', '566', '1171', '1282', '1136', '29', '327', '707', '857', '755', '1078', '66', '898', '790', '1191', '1081', '323', '452', '594', '488', '773', '434', '1413', '648', '827', '1255', '539', '660', '28', '67', '966', '686', '1092', '619', '151', '1054', '1053', '617', '807', '429', '565', '636', '703', '1153', '1120', '523', '820', '1264', '986', '688', '321', '690', '560', '445', '389', '319', '509', '129', '680', '534', '1377', '562', '631', '716', '61', '1134', '1197', '883', '733', '925', '1419', '1368', '1139', '798', '835', '851', '78', '125', '484', '762', '1089', '1327', '615', '514', '243', '388', '73', '704', '895', '681', '1414', '463', '44', '328', '516', '526', '474', '148', '179', '1175', '26', '450', '487', '480', '1392', '267', '1307', '451', '1422', '448', '318', '199', '956', '620', '705', '518', '853', '492', '826', '1072', '797', '625', '746', '661', '567', '596', '894', '737', '1258', '63', '675', '779', '495', '473', '829', '1091', '1126', '159', '71', '510', '531', '1391', '687', '634', '689', '626', '483', '637', '1201', '769', '627', '727', '603', '866', '817', '785', '608', '709', '993', '502', '695', '512', '813', '1196', '806', '515', '498', '519', '650', '58', '659', '805', '165', '329', '702', '871', '731', '754', '508', '706', '812', '571', '610', '530', '479', '1117', '468', '51', '382', '82', '810', '503']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.072"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.400"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.122<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The difficulties encountered in information retrieval systems are often less related to the equipment used than to the failure to plan adequately for document analysis, indexing, and machine coding.  The position of the programmer is to take a problem and write it in a way in which the equipment will understand.  What articles have been written describing research in maximizing the effectiveness of programming?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['419', '1328', '477', '561', '637', '291', '350', '515', '690', '432', '1427', '459', '593', '822', '454', '175', '883', '179', '428', '144', '1039', '326', '317', '396']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.125"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.231"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.162<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are presently fifty to one hundred technical journals being published.  On the average, two new journals appear every day.  In the many journals published, one to two million articles appear every year.  What attempts have been made to cope with this amount of scientific and technical publication in terms of analysis, control, storage, and retrieval?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['686', '986', '560', '243', '44', '429', '898', '1091', '664', '515', '197', '889', '135', '381', '1158', '478', '151', '199', '454', '755', '327', '592', '156', '820', '174', '1255', '838', '805', '1171', '608', '1362', '496', '376', '1197', '388', '680', '894', '497', '603', '1377', '486', '1392', '446', '68', '707', '1072', '798', '1191', '619', '636', '1081', '617', '600', '655', '637', '472', '1009', '807', '731', '817', '769', '323', '460', '1248', '82', '159', '61', '1364', '28', '661', '26', '737', '257', '620', '1419', '471', '727', '516', '126', '634', '321', '448', '463', '627', '826', '1175', '1327', '160', '129', '461', '596', '487', '538', '531', '993', '575', '567', '1054', '1422', '762', '1190', '688', '434', '67', '123', '790', '1164', '871', '1162', '606', '73', '378', '728', '120', '329', '334', '458', '319', '660', '630', '716', '594', '30', '1305', '502', '375', '702', '810', '641', '176', '925', '165', '309', '525', '615', '591', '484', '813', '508', '445', '267', '1053', '690', '63', '857', '1130', '806', '595', '1448', '175', '318', '1259', '1136', '254', '481', '703', '1089', '363', '1170', '382', '389', '252', '1323', '530', '328', '501', '1414', '259', '512', '148', '131', '71', '590', '1368', '498', '611', '579', '761', '827', '883', '125', '514', '1405', '539', '565', '534', '1413', '706', '610', '459', '492', '956', '510', '966', '523', '480', '1179', '812', '474', '1124', '797', '754', '114', '709', '1258', '598', '479', '1307', '562', '626', '689', '670', '1078', '483', '488', '1264', '1153', '1134', '687', '1201', '746', '503', '650', '566', '468', '659', '495', '528', '681', '452', '179', '705', '779', '839', '780', '547', '1092', '704', '1027', '571', '675', '137', '509', '895', '851', '773', '1196', '519', '490', '1120', '631', '625', '451', '648', '835', '518', '733', '526', '1282', '853', '644', '1125', '1391', '1139', '1117', '473', '829', '1126', '29', '51', '462', '66', '785', '866', '695', '450', '1180', '78', '58']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.079"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.142"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.101<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am looking for information about the impact of automation on libraries and its significance for libraries in general.  This includes the increasing importance of automation in view of the proliferation of information today, and how automation can help libraries cope with this problem.  How will automation affect libraries and how should they react to the idea of automation?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['178', '141', '177', '281', '916', '1012', '11', '136', '406', '970', '1042', '849', '990', '17', '917', '135', '1280', '287', '1212', '6', '1193', '66', '409', '376', '284', '865', '875', '180', '1419', '299', '517']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.258"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.104"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.148<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query ID: 46\n",
      "Query: I am seeking information on the use of data processing in libraries and the mechanization of routine library processes and procedures.  I would like descriptions of both general and specific applications of automation in such areas as circulation, cataloging, acquisitions, serial records, and other record-keeping.  Examples should be based on the operation of a conventional public or university library, or practices in a special library which could also be applied in a public or university library.  Give descriptions of equipment and operations, both present and projected.\n",
      "No matches found.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any established means at present for an international exchange of material about information retrieval?  If there is, does it take the form of an international agency or center which regularly distributes information retrieval methods and research results?  If there is not, in what ways has this material crossed national boundaries?  What seem to have been some of the problems blocking a better international exchange, and is any effort being made to solve some of those problems?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1256', '1245', '12', '1441', '796', '1153', '1004', '323', '664', '1000', '769', '760', '634', '1189', '1031', '1431', '351', '1052', '594', '148', '297', '1423', '888', '1021', '98', '525', '889', '497', '710', '575', '264', '541', '606', '1136', '773', '473', '496', '1025', '595', '353', '1041', '394', '1323', '725', '1134', '228', '481', '17', '432', '1201', '1042', '97', '1014', '1248', '43', '1429', '1440', '234', '600', '37', '1419', '907', '703', '331', '345', '321', '1013', '1117', '1053', '1081', '451', '1079', '946', '122', '621', '93', '516', '471', '1398', '1351', '992', '126', '370', '441', '500', '1408', '730', '197', '518', '1215', '528', '1390', '515', '587', '1414', '235', '639', '1160', '948', '839', '1106', '424', '779', '1422', '437', '338', '736', '158', '244', '1328', '1454', '851', '426', '254', '616', '950', '1240', '1082', '314', '160', '114', '958', '561', '1421', '11', '1309', '523', '826', '1070', '157', '1142', '767', '628', '123', '970', '993', '1448', '349', '815', '9', '429', '1150', '700', '42', '1226', '1295', '369', '884', '422', '943', '298', '340', '1206', '1171', '878', '1342', '476', '802', '1315', '342', '838', '223', '336', '395', '1337', '408', '1167', '389', '212', '951', '1343', '419', '540', '1416', '601', '546', '560', '279', '504', '343', '1382', '916', '961', '1161', '1418', '1427', '1149', '1163', '1298', '163', '549', '890', '1100', '661', '718', '1049', '350', '335', '173', '1101', '325', '113', '502', '1151', '417', '19', '477', '1058', '1425', '310', '168', '1223', '781', '1178', '137', '397', '944', '1098', '1241', '553', '1056', '660', '1257', '482', '278', '568', '256', '7', '1221', '688', '1399', '649', '457', '413', '1292', '344', '654', '185', '770', '724', '583', '373', '1268', '1267', '1044', '308', '428', '862', '585', '307', '467', '1035', '1173', '409', '1181', '393', '404', '105', '582', '265', '848', '1039', '1166', '1202', '258', '1406', '166', '1243', '315', '1280', '818', '1275', '717', '1340', '1093', '1037', '283', '1433', '1444', '1387', '1212', '1459', '978', '882', '593', '25', '1129', '698', '1388', '288', '1204', '988', '1147', '841', '465', '1253', '23', '128', '676', '1232', '652', '1234', '1224', '935', '609', '1443', '1008', '248', '16', '1090']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.104"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information retrieval is still such a new and experimental field that a line distinguishing research and practice is often difficult - even impossible - to draw.  Are there, however, actual centers of research on information retrieval?  If so, in which countries are they located?  Who supports them - government, business, universities, or libraries?  Can information retrieval as a specialized research discipline be said to be emerging, or is it still an amalgam of skills from other fields, such as mathematics, engineering, and library science?  In other words, tell me about information retrieval research.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['462', '375', '1120', '966', '257', '1219', '1009', '703', '388', '148', '160', '151', '1150', '1183', '381', '769', '1323', '1242', '1264', '163', '479', '905', '174', '512', '17', '1432', '943', '871', '807', '1179', '1328', '116', '619', '328', '946', '259', '1408', '1151', '728', '391', '88', '1197', '378', '575', '260', '1424', '1203', '1170', '1347', '311', '1130', '350', '338', '504', '254', '600', '176', '107', '1442', '690', '889', '526', '474', '385', '606', '982', '243', '1382', '438', '314', '132', '450', '1348', '1454', '341', '688', '199', '949', '915', '96', '439', '813', '821', '556', '1011', '436', '828', '129', '348', '1099', '796', '304', '1146', '964', '351', '1346', '1205', '1315', '1020', '1308', '649', '1023', '1209', '666', '1257', '626', '357', '484', '1178', '1378', '481', '1455', '642', '1403', '4', '1401', '1262', '1372', '559', '1418', '1207', '343', '1425', '985', '961', '1149', '603', '941', '896', '1250', '475', '612', '1095', '95', '353', '1273', '818', '1241', '704', '1047', '431', '1450', '31', '98', '109', '978', '400', '295', '490', '899', '8', '560', '340', '194', '1070', '963', '355', '614', '1200', '937', '164', '771', '553', '1277', '667', '190', '1449', '1144', '891', '692', '1284', '1082', '1031', '1121', '147', '960', '900', '953', '1355', '1067', '1381', '1345', '134', '366', '317', '537', '74', '922', '732', '1018', '293', '936', '658', '405', '286', '965', '775', '1350', '952', '1296', '1113', '173', '513', '185', '561', '1052', '1335', '360', '278', '1249', '1061', '945', '420', '645', '5', '616', '456', '1106', '221', '962', '489', '383', '266', '1270', '1268', '1211', '1342', '108', '32', '287', '202', '1379', '730', '948', '633', '256', '1210', '1279', '1154', '399', '557', '1256', '601', '139', '907', '291', '1444', '736', '1336', '103', '1135', '9', '424', '6', '856', '1058', '576', '1036', '395', '1068', '27', '168', '12', '178', '1289', '1321', '482', '1410', '15', '65', '1227', '672', '1390', '1288', '440', '491', '296', '370', '544', '734', '208', '422', '1352', '172', '1110', '902', '1050', '1344', '102', '921', '1251', '763', '274', '128', '158', '654', '918', '685', '113', '543', '863', '105', '602', '739', '1217', '426', '540', '312', '1427', '1083', '427', '104', '892', '1155', '861', '994', '1409', '849', '1330', '93', '184', '467', '115', '757', '220', '246', '239', '1174', '1254', '52', '423', '1039', '958', '1406', '1098', '217', '815', '46', '825', '76', '1182', '1065', '97', '520', '1048']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.104"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most resources have been spent on applying information retrieval techniques to the physical and medical sciences.  But, has information retrieval been used at all in the natural sciences, social sciences, and humanities?  If so, what have been some of the problems which have been encountered with these subject areas and how have they been solved, if at all?  Have the characteristics of these subject areas necessitated the development of new information retrieval techniques? What are the prospcts for future machine control in these areas?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1082', '807', '174', '545', '1362', '575', '151', '123', '1368', '185', '866', '136', '547', '1273', '898', '1147', '268', '664', '1345', '817', '157', '140', '577', '1067', '1202', '1144', '1392', '555', '596', '1342', '602', '885', '1346', '129', '1348', '899', '202', '1140', '505', '609', '533', '1263', '1432', '816', '624', '484', '105', '132', '626', '143', '17', '977', '177', '784', '1270', '403', '573', '96', '1450', '138', '1409', '358', '1216', '989', '544', '888', '635', '339', '802', '946', '134', '614', '821', '546', '858', '1332', '23', '425', '1076', '863', '1056', '1213', '178', '1205', '673', '906', '1219', '16', '366', '861', '963', '119', '1206', '1135', '811', '1014', '654', '296', '696', '988', '80', '436', '1369', '1097', '828', '1221', '667', '194', '856', '84', '1104', '1095', '12', '301', '392', '1373', '1352', '854', '1048', '1105', '440', '921', '1203', '1336', '1184', '1445']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.056"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.206"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.088<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is there any use for traditional classification schemes - DDC, UDC, LC, etc. - in information retrieval systems?  If there is, which scheme appears most suited to machine use and where has it been applied? If there is not, why are these classification schemes irrelevant? Has research shown that a subject classification of knowledge is completely unnecessary in machine systems? Or, have new schemes been devised which appear to be more suited to machine use?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['388', '261', '1430', '1442', '485', '746', '263', '1259', '354', '620', '1144', '16', '798', '801', '1419', '377', '488', '503', '262', '260', '564', '1372', '664', '54', '479', '1356', '809', '663', '200', '1072', '176', '874', '290', '687', '1044', '404', '9', '275', '1421', '323', '47', '936', '797', '380', '947', '728', '1404', '197', '321', '889', '1173', '53', '648', '509', '1264', '58', '459', '732', '490', '990', '670', '447', '1407', '688', '766', '985', '190', '1009', '1411', '1392', '1360', '526', '621', '807', '704', '132', '1183', '762', '654', '1415', '327', '699', '805', '675', '558', '501', '615', '475', '26', '140', '508', '789', '774', '370', '645', '534', '30', '981', '839', '773', '866', '957', '278', '1277', '832', '847', '1251', '1273', '1410', '449', '545', '1020', '71', '1365', '25', '916', '556', '115', '946', '502', '155', '536', '722', '962', '611', '788', '1050', '604', '78', '808', '614', '126', '204', '348', '484', '610', '1328', '1449', '535', '1146', '672', '300', '32', '268', '31', '378', '427', '1018', '1418', '344', '1073', '692', '150', '148', '67', '721', '1196', '390', '745', '276', '713', '1381', '79', '868', '184', '167', '462', '66', '409', '1045', '467', '347', '1203', '199', '743', '205', '164', '225', '757', '625', '725', '638', '2', '198', '803', '1040', '785', '518', '76', '319', '624', '342', '147', '733', '1024', '1242', '286', '203', '145', '36', '532', '295', '771', '907', '1424', '127', '448', '557', '450', '582', '493', '673', '129', '131', '646', '593', '589', '991', '511', '364', '137', '208', '305', '872', '1193', '168', '1055', '193', '983', '15', '1012', '6', '963', '304', '812', '288', '28', '880', '1090', '422', '945', '768', '1038', '1109', '1060', '5', '1373', '106', '597', '1352', '1425', '1452', '113', '443', '69', '1027', '406', '1008', '857', '900', '292', '423', '723', '1058', '1062', '633', '465', '959', '1222', '456', '1375', '408', '1349', '49', '828', '1111', '1036', '386', '992', '1384', '643', '700', '201', '1408', '224', '994', '1355', '429', '520', '402', '977', '711', '1186', '972', '214', '1246', '1064', '425', '222', '345', '94', '85', '905', '1147', '374', '23', '1142', '1041', '183', '1189', '315', '669', '799', '368', '227', '1346', '369', '46', '678', '1206', '930', '926', '1417', '842', '161', '216', '417', '1212', '772', '913', '552', '1079', '269', '811', '181', '873', '1265', '223', '371']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.068"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.258"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.107<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinate indexing utilizes descriptors for controlled language.  Of what use are descriptors in the construction of an index?  How can descriptors be used for searching in an information retrieval system?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1124', '1175', '1139', '1171', '1120', '478', '151', '1448', '1073', '434', '664', '389', '175', '510', '830', '390', '1230', '731', '1024', '179', '388', '595', '796', '1277', '687', '468', '321', '641', '1413', '660', '212', '779', '966', '1144', '566', '591', '458', '538', '446', '620', '159', '530', '866', '642', '556', '989', '1283', '889', '257', '378', '1326', '590', '1010', '762', '798', '825', '565', '648', '1261', '603', '291', '703', '702', '72', '1264', '71', '445', '514', '190', '637', '1180', '483', '611', '1419', '129', '49', '318', '522', '254', '1136', '682', '482', '704', '1092', '1054', '419', '523', '1163', '461', '517', '773', '262', '477', '197', '547', '801', '1091', '1012', '531', '508', '572', '606', '57', '1298', '997', '472', '501', '459', '741', '615', '644', '621', '740', '1126', '645', '44', '582', '593', '742', '504', '809', '224', '526', '1077', '309', '497', '701', '542', '27', '562', '61', '535', '67', '117', '174', '376', '336', '690', '1127', '1366', '575', '1215', '728', '627', '1038', '626', '1427', '534', '1040', '895', '486', '739', '490', '716', '123', '66', '695', '795', '319', '467', '532', '381', '448', '636', '630', '1327', '820', '329', '347', '553', '1410', '699', '1125', '612', '165', '709', '1173', '1361', '883', '158', '317', '677', '54', '839', '135', '670', '140', '1255', '325', '375', '126', '1170', '600', '137', '1035', '474', '597', '168', '609', '1078', '822', '610', '484', '136', '1072', '481', '1099', '512', '202', '659', '1057', '1053', '327', '80', '1225', '396', '64', '707', '827', '320', '454', '646', '1405', '842', '826', '28', '1121', '134', '1179', '120', '114', '1128', '574', '525', '1143', '25', '515', '1309', '1112', '150', '916', '1282', '802', '571', '865', '1305', '1109', '607', '850', '451', '1223', '85', '131', '1191', '68', '1081', '406', '295', '723', '1307', '557', '1190', '1267', '449', '1196', '529', '925', '1110', '780', '74', '579', '1409', '990', '1105', '421', '754', '502', '243', '252', '720', '180', '1080', '594', '386', '986', '213', '1104', '447', '744', '354', '119', '1293', '860', '73', '132', '443', '833', '993', '671', '693', '560', '647', '1106', '528', '948', '267', '511', '838', '947', '128', '1022', '639', '1289', '16', '1084', '1447', '737', '1197', '727', '1395', '890', '1362', '1341', '872', '433', '373', '546', '537', '1241', '1207', '1367', '1114', '1391', '1147', '1209', '1377', '676', '681', '1259', '567', '494', '982', '244', '452', '785', '1011', '1113', '815', '1098', '513', '576', '786', '970', '222', '1415', '1360', '880', '689', '59', '1193', '846', '674', '208', '10', '1460', '868', '652', '1051', '1348', '95', '1437', '1093', '697', '350', '1436', '874', '1062', '625', '348', '200', '1339', '177', '1281', '1358', '245', '1349', '840', '601', '340', '1043', '408', '1044', '841', '1378', '18', '806', '231', '364', '1418', '1328', '1152', '617', '1375', '544', '725', '700', '382', '634', '691', '492', '288', '706', '1111', '400', '124', '4', '1401', '955', '157', '519', '292', '465', '862', '310', '228', '1350', '694', '654', '941', '1363', '1227', '1236', '115', '268', '380', '1007', '409', '294', '871', '1256', '564', '979', '898', '1117', '1416', '1137', '491', '848', '897', '917', '710', '1067', '951', '683', '1425', '849', '1417', '1229', '106', '387', '1290', '1249', '1206', '843', '250', '1085', '1004', '1195', '884', '1148', '1456', '89', '954', '102', '999', '852', '1016', '1317', '752', '332', '399', '287', '507', '211', '13', '17', '141', '394', '1000', '1001', '1', '666', '192', '1074', '726', '960', '998', '265', '1333', '48', '1402', '911', '1445', '1457', '724', '984', '1049', '888', '398', '335', '104', '476', '1337', '358']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.258"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the characteristics of MEDLARS (Medical Literature Analysis and Retrieval System) project which has been undertaken by the National Library of Medicine?  How does it index current medical journals and of what relation is this indexing system to Index Medicus? What are the major components of the MEDLARS project and its major operating details?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['830', '219', '526', '202', '817', '465', '534', '888', '208', '423', '1431', '1317', '134', '158', '115', '649', '515', '342', '406', '1111', '397', '506', '725', '1364', '1276', '315', '882', '900', '898', '755', '428', '539', '1427', '706', '816', '385', '596', '1450', '244', '495', '1229', '956', '1035', '324', '783', '918', '1212', '994', '940', '1312', '1204', '1351', '84', '1420', '417', '247']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can the computer be used in medical science for diagnostic and clinical record keeping purposes?  Have any programs of automation been tried in hospitals?  If so, what have been the results? What problems have been encountered in the use of automation in medicine?  For what purposes can an automated system of clinical records be used?  What are other possible uses of the computer in medicine?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['958', '1147', '1249', '696', '181', '594', '190', '10', '75', '220', '211', '194', '1055', '986', '891', '624', '200', '72', '1050', '1303', '382', '133', '883', '1397', '547', '452', '1188']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the effect on librarians of automation?  Note the new types of technology to be used in the library which will have an effect on the status, position, and function of the librarians.  What changes are being contemplated or have been initiated to introduce automation into the education of librarians?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['283', '1212', '141', '917', '816', '392', '167', '1457', '22', '1042', '17', '187', '994', '547', '1240', '1318', '1012', '178', '323', '177', '1264', '6', '409', '410', '896', '408', '334', '1417', '181', '842', '949', '1253', '285', '264', '1182', '1192', '248', '1450', '46', '515', '961', '415', '257', '952', '1237', '188', '1325', '914', '268', '1403', '941', '1090', '260', '1400', '592', '496', '913', '325', '946', '393', '1246', '756', '31', '1020', '552', '918', '90', '927', '213', '976', '985', '841', '975', '1349', '274', '909', '954', '1239', '7', '839', '405', '1249', '933', '881', '942', '1373', '1324', '221', '593', '1245', '1263', '1242', '910', '1008', '1198', '583', '1441', '240', '1404', '242', '818', '811', '1049', '1322', '1317', '302', '925', '291', '1247', '166', '1014', '1268', '282', '237', '1248', '768', '950', '196', '414', '1365', '1022', '373', '163', '273', '1035', '898', '337', '1356', '238', '926', '974', '1028', '307', '275', '244', '20', '821', '1371', '92', '1357', '217', '403', '1023', '294', '1422', '964', '470', '760', '199', '8', '272', '359', '114', '231', '1358', '795', '345', '151', '993', '1251', '121', '606']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.148"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.471"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.225<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the aims and objectives of the medical literature analysis and retrieval system (MEDLARS)?  How does MEDLARS operate?  What are the possible applications of MEDLARS to future information retrieval systems?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['382', '986', '883', '452', '806', '1051', '526', '72', '603', '446', '67', '481', '591', '1016', '135', '1241', '547', '325', '123', '136', '158', '482', '889', '1179', '514', '630', '659', '114', '525', '1249', '1143', '1121', '128', '1038', '716', '606', '408', '595', '57', '202', '1171', '637', '459', '826', '1136', '228', '1007', '434', '244', '497', '530', '483', '1035', '780', '621', '254', '565', '1114', '615', '809', '175', '703', '478', '579', '165', '515', '1092', '213', '1264', '865', '1255', '376', '1418', '208', '670', '348', '737', '993', '454', '1120', '409', '458', '197', '538', '179', '1081', '617', '27', '611', '1106', '645', '815', '445', '1077', '671', '73', '1341', '309', '1098', '159', '1170', '267', '801', '74', '4', '1401', '1173', '317', '1124', '795', '1125', '1437', '1360', '1410', '1104', '731', '71', '17', '501', '119', '773', '874', '1139', '528', '827', '648', '866', '375', '1109', '916', '490', '134', '28', '1078', '474', '319', '494', '519', '1350', '660', '1327', '1290', '1448', '626', '16', '846', '822', '523', '898', '779', '1053', '676', '850', '707', '798', '137', '120', '310', '1413', '839', '265', '129', '690', '674', '575', '491', '970', '451', '406', '560', '534', '1362', '1207', '1405', '389', '706', '897', '1105', '472', '567', '1282', '461', '484', '594', '542', '373', '1054', '211', '647', '925', '1457', '131', '890', '1307', '294', '982', '190', '1419', '955', '1099', '291', '386', '18', '1147', '1128', '10', '378', '689', '381', '574', '106', '1460', '419', '140', '1112', '1085', '1305', '1277', '1256', '644', '532', '66', '1223', '535', '871', '245', '607', '192', '682', '1110', '421', '1191', '582', '200', '486', '610', '180', '562', '1309', '683', '1180', '1010', '989', '726', '243', '252', '1190', '1293', '157', '1144', '318', '556', '126', '336', '600', '257', '1024', '727', '825', '508', '664', '895', '1080', '513', '49', '64', '468', '553', '54', '1298', '80', '132', '566', '141', '1391', '1358', '1126', '1072', '641', '477', '636', '852', '646', '948', '433', '117', '695', '1339', '728', '447', '212', '396', '642', '151', '504', '700', '1229', '709', '1', '89', '1289', '1175', '321', '593', '634', '590', '687', '1209', '681', '68', '517', '639', '571', '492', '1283', '557', '572', '467', '1022', '1326', '725', '1084', '1447', '250', '150', '704', '612', '358', '1348', '222', '546', '754', '59', '347', '1127', '1111', '61', '1328', '320', '1361', '544', '537', '327', '1012', '564', '744', '522', '1227', '966', '1436', '702', '872', '177', '627', '620', '174', '1043', '1317', '990', '1236', '388', '1093', '465', '502', '786', '1367', '399', '1113', '1417', '785', '1281', '124', '1011', '742', '512', '654', '840', '860', '448', '833', '951', '1349', '979', '693', '601', '510', '85', '723', '1196', '1261', '1117', '880', '449', '652', '1445', '1416', '292', '364', '720', '1225', '1259', '739', '168', '231', '1137', '95', '691', '224', '1057', '1062', '666', '699', '830', '1091', '1193', '329', '1074', '625', '796', '917', '1427', '710', '1378', '1067', '911', '1377', '531', '1215', '1366', '25', '849', '1073', '694', '762', '947', '1197', '820', '802', '387', '842', '350', '476', '400', '1044', '984', '597', '941', '843', '354', '1375', '1004', '1195', '884', '997', '1230', '1148', '529', '1152', '115', '44', '262', '1456', '1163', '1409', '954', '102', '999', '104', '848', '868', '752', '332', '287', '507', '288', '13', '340', '741', '740', '394', '841', '1000', '1267', '1001', '701', '576', '960', '838', '268', '380', '998', '295', '1333', '48', '697', '1402', '609', '862', '724', '677', '1049', '1040', '888', '390', '398', '335', '1395', '443', '1363', '1337', '1206', '511', '1425', '1415']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.018"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.500"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.034<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard method of finding information in today's libraries is through the use of the alphabetically arranged card catalog or the classified catalog based on a classification system such as the DC or LC.  Can these systems be modified for use with automated information retrieval?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['655', '502', '1448', '534', '798', '1124', '472', '1196', '1419', '1197', '606', '334', '1391', '530', '257', '388', '1139', '459', '176', '615', '1125', '611', '445', '866', '434', '67', '1053', '1170', '501', '1264', '839', '648', '259', '986', '1120', '1027', '123', '526', '78', '490', '704', '488', '461', '889', '565', '497', '523', '175', '575', '375', '478', '126', '660', '135', '1158', '484', '376', '254', '966', '670', '664', '179', '66', '1092', '827', '993', '1136', '925', '458', '327', '538', '508', '644', '174', '319', '826', '630', '709', '627', '321', '707', '728', '120', '690', '1191', '378', '737', '1179', '1171', '1190', '515', '446', '617', '562', '267', '591', '509', '525', '137', '1078', '451', '474', '773', '481', '1009', '1072', '1259', '594', '309', '363', '620', '539', '323', '512', '448', '1362', '454', '73', '1405', '625', '243', '883', '486', '797', '28', '462', '129', '895', '659', '381', '703', '452', '687', '1126', '762', '528', '637', '114', '1413', '252', '483', '1164', '1282', '661', '471', '603', '1162', '547', '1305', '1081', '769', '1248', '131', '503', '566', '389', '1307', '853', '1323', '761', '733', '514', '780', '595', '199', '1130', '579', '429', '641', '151', '731', '706', '1117', '159', '71', '328', '382', '1054', '1258', '318', '148', '956', '61', '560', '160', '898', '857', '820', '1180', '727', '487', '1368', '592', '590', '807', '518', '496', '165', '806', '716', '479', '755', '695', '30', '785', '567', '681', '1422', '610', '626', '1377', '1327', '689', '197', '829', '516', '817', '631', '29', '1255', '598', '1089', '44', '746', '680', '473', '1134', '460', '835', '1392', '450', '634', '779', '1364', '1175', '596', '675', '492', '463', '68', '571', '790', '519', '754', '851', '688', '636', '838', '608', '1153', '156', '871', '686', '705', '510', '51', '329', '63', '600', '495', '468', '805', '1201', '125', '531', '702', '812', '619', '26', '813', '1091', '480', '58', '82', '650', '894', '498', '1414', '810']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.047"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.289"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.080<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In catalogs which are either arranged alphabetically or arranged by classification number, the LC entry, printed in readable language, is ultimately important because the individual looking for information has a definite author, title, or subject phrase in his language (probably English in our case) in mind.  Will LC entries and subject headings be used in the same manner in automated systems?\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1230', '848', '990', '1366', '1215', '1197', '1024', '212', '317', '1091', '970', '1196', '1179', '1395', '1415', '874', '838', '796', '354', '866', '1261', '998', '802', '174', '168', '798', '825', '1139', '1124', '1152', '1298', '820', '461', '64', '1000', '16', '572', '562', '1326', '941', '44', '1170', '809', '257', '639', '231', '702', '1180', '1175', '159', '884', '530', '434', '320', '389', '522', '682', '620', '477', '664', '582', '504', '49', '601', '868', '478', '843', '151', '739', '676', '556', '1402', '575', '999', '576', '648', '1436', '1120', '1171', '1448', '373', '1281', '898', '228', '801', '1427', '472', '609', '244', '502', '180', '390', '865', '150', '213', '947', '447', '1099', '262', '697', '136', '158', '483', '542', '1419', '1267', '795', '245', '666', '445', '993', '895', '482', '641', '726', '336', '1277', '1328', '59', '1110', '1349', '476', '179', '396', '1136', '860', '523', '119', '380', '340', '564', '546', '459', '652', '849', '175', '1077', '862', '687', '1074', '611', '1341', '691', '265', '25', '252', '177', '114', '637', '660', '1072', '10', '989', '329', '1391', '517', '630', '595', '419', '309', '617', '123', '1010', '197', '335', '1256', '1225', '1191', '1460', '529', '815', '17', '979', '1327', '1236', '1190', '534', '454', '951', '481', '1054', '1038', '254', '603', '647', '1043', '126', '510', '846', '636', '421', '192', '378', '1040', '202', '1001', '762', '89', '606', '514', '1092', '773', '1114', '1457', '376', '387', '1259', '433', '1405', '28', '468', '1409', '1098', '512', '484', '883', '1339', '1173', '872', '728', '780', '839', '830', '120', '674', '134', '375', '537', '268', '386', '966', '566', '1456', '132', '1012', '1209', '448', '1111', '497', '916', '27', '446', '960', '880', '406', '388', '1137', '129', '1445', '1367', '826', '842', '319', '1109', '1350', '1195', '597', '1309', '243', '694', '644', '571', '986', '612', '1144', '890', '358', '291', '1417', '400', '593', '997', '740', '115', '57', '621', '1057', '779', '128', '85', '190', '72', '528', '642', '553', '1418', '671', '703', '1117', '1361', '786', '690', '1193', '897', '325', '1035', '594', '124', '1362', '80', '1227', '954', '683', '1044', '68', '486', '727', '1348', '1073', '1255', '1', '458', '538', '321', '1049', '135', '1121', '318', '1125', '1128', '574', '1143', '1425', '1112', '474', '600', '535', '607', '627', '131', '850', '591', '1223', '140', '501', '465', '955', '1053', '157', '707', '565', '1148', '67', '615', '532', '287', '806', '74', '443', '1078', '1375', '1105', '1337', '725', '827', '511', '744', '515', '1080', '526', '508', '1104', '742', '645', '208', '1293', '833', '104', '66', '1333', '693', '54', '1413', '1106', '1305', '948', '1410', '61', '490', '347', '1022', '1289', '525', '141', '1084', '1447', '1282', '364', '610', '1283', '381', '467', '137', '670', '888', '925', '1241', '1207', '1307', '451', '709', '1127', '494', '1081', '982', '701', '1011', '1113', '1264', '822', '513', '646', '634', '579', '560', '507', '557', '754', '71', '1229', '295', '449', '1051', '95', '267', '1437', '1093', '723', '737', '327', '350', '165', '1358', '840', '1126', '716', '704', '695', '841', '889', '1363', '1378', '18', '117', '73', '547', '752', '681', '250', '544', '731', '452', '626', '590', '1147', '224', '1377', '567', '4', '1401', '310', '689', '677', '222', '1007', '294', '1360', '408', '200', '492', '382', '659', '1416', '720', '491', '1062', '699', '917', '710', '1067', '706', '348', '700', '1290', '1249', '785', '1085', '1004', '1163', '519', '102', '852', '1016', '1317', '332', '409', '399', '871', '211', '288', '13', '741', '531', '394', '292', '654', '48', '625', '911', '724', '984', '398', '106', '1206']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.019"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.556"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.038<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directions in Library Networking Bibliographic control before and after MARC is reviewed.  The capability of keying into online systems brought an interdependence among libraries, the service centers that mediate between them, and the large utilities that process and distribute data.  From this has developed the basic network structure among libraries in the United States.  The independent development of major networks has brought problems in standardization and coordination. The authors point out that while technology has led toward centralization of automated library services, new developments are now pushing toward decentralization.  Coordination is a requirement to avoid fragmentation in this new environment.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['528', '960', '1379', '1058', '642', '202', '1375', '387', '964', '244', '497', '688', '646', '357', '1456', '325', '390', '484', '612', '142', '129', '1207', '608', '490', '1426', '67', '1359', '517', '1186', '968', '1065', '1321', '518', '1029', '805', '309', '1202', '350', '628', '1167', '531', '1025', '772']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.023"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.022"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.022<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Testing of a Book and Its Index as a Information Retrieval System The retrieval performance of book indexes can be measured in terms of their ability to direct a user selectively to text material whose identity but not location is known.  The method requires human searchers to base their searching strategies on actual passages from the book rather than on test queries, natural or contrived.  It circumvents the need for relevance judgement, but still yields performance indicators that correspond approximately to the recall and precision ratios of large document retrieval system evaluation.  A preliminary application of the method to the subject indexing of two major encyclopedias showed one encyclopedia apparently superior in both the finding and discrimination abilities of retrieval performance.  The method is presently best suited for comparative testing since its ability to yield absolute or reproducible measures is as yet not established.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1175', '1419', '530', '207', '357', '874', '52', '1040', '383', '9', '148', '165', '1215', '136', '1066', '642', '352', '1117', '240', '505', '587', '358', '1201', '831', '217', '432', '1304', '1256', '1432', '1235', '850', '85', '1128', '767', '37', '268', '879', '723', '1216', '1436', '1011', '410', '1352', '996', '455', '171', '881', '1343']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.022"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Combined Use of Bibliographic Coupling and Cocitation for Document Retrieval A linkage similarity measure which takes into account both the bibliographic coupling of documents and their cocitations (both cited and citing papers) produced improved document retrieval over a measure based only on bibliographic coupling.  The test collection consisted of 1712 papers whose relevance to specific queries had been judged by users.  To evaluate the effect of using cocitation data, we calculated for each query two measures of similarity between each relevant paper and every other paper retrieved. Papers were then sorted by the similarity measures, producing two ordered lists.  We then compared the resulting predictions of relevance, partial relevance, and non-relevance to the user's evaluations of the same papers. Overall, the change from the bibliographic coupling measure to the linkage similarity measure, representing the introduction of cocitation data, resulted in better retrieval performance.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['523', '492', '528', '805', '806', '61', '79', '956', '590', '962', '74', '448', '894', '28', '575', '1195', '731', '813', '625', '754', '737', '319', '820', '522', '296', '755', '807', '812', '295', '955', '615', '194', '702', '393', '785', '895', '488', '470', '1358', '581', '71', '596', '1099', '531', '176', '481', '1078', '595', '1062', '720', '141', '726', '593', '609', '390', '302', '1170', '586', '685', '162', '1039', '525', '845', '297', '483', '1038', '1230', '484', '1321', '382', '75', '1070', '149', '288', '1448', '458', '538', '1445', '137', '620', '1337', '841', '591', '1175', '630', '641', '897', '1410', '250', '244', '1040', '639', '1186', '1263', '855', '1424', '417', '1214', '389', '152']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.022"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Biases in Large Interactive Document Retrieval Systems The way that individuals construct and modify search queries on a large interactive document retrieval system is subject to systematic biases similar to those that have been demonstrated in experiments on judgements under uncertainty.  These biases are shared by both naive and sophisticated subjects and cause the inquirer searching for documents on a large interactive system to construct and modify queries inefficiently.  A searching algorithm is suggested that helps the inquirer to avoid the effect of these biases.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Requests:  An Approach to Weighted Boolean Searches This article concerns the problem of how to permit a patron to represent the relative importance of various index terms in a Boolean request while retaining the desirable properties of a Boolean system. The character of classical Boolean systems is reviewed and related to the notion of fuzzy sets.  The fuzzy set concept then forms the basis of the concept of a fuzzy request in which weights are assigned to index terms. Ther properties of such a system are discussed, and it is shown that such systems retain the manipulability of traditional Boolean requests.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['773', '660', '1363', '562', '706', '488', '1138', '58', '1103', '483', '479', '596', '597', '1124', '381', '644', '862', '871', '394', '1155', '484', '711', '1156', '451', '165', '207', '1130', '1078', '1120', '309', '552', '1126', '1055', '1170', '797', '551', '218', '10', '695', '1327', '1118', '223', '1352', '1158', '898', '339', '526', '788', '71', '382', '783', '891', '1147', '1394', '550', '892', '271', '1231', '188']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.017"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.083"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.028<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Comparison of an In-House Information Retrieval System With a Commercial Search Service A commercially available online search was used as a standard for comparative searching and evaluation of an in-house information system based on automatic indexing.  System features were identified and evaluated on the basis of their usefulness in various kinds of searching, their ease in implementation, and how they are influenced by differences in user type or specific applications.  Some common features of the commercial system, such as online instruction, user-specified print formats, dictionary display, and truncation, are seen to be unnecessary or impractical for the in-house system.  In designing the in-house system, therefore, detald consideration must be given to the applications, operating environment, and real user needs.  While a commercial system can serve as a useful standard for comparative evaluation, one must be careful not to attempt to duplicate it blindly in-house.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.083"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Measurement in Information Science:  Objective and Subjective Metrical Space It is argued that in information science we have to distinguish physical, objective, or document space from perspective, subjective, or information space.  These two spaces are like maps and landscapes: each is a systematic distortion of the other.  However, transformation can be easily made once the two spaces are distinguished.  If the transformations are omitted we only get unhelpful physical solutions to information problems.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['944', '1014', '943', '541', '988', '393', '1419', '321', '634', '1147', '373', '525', '265', '1309', '279', '308', '518', '497', '1387', '958', '818', '1429', '993', '137', '1342', '664', '473', '587', '582', '688', '568', '314', '338', '950', '515', '437', '1153', '1253', '1070', '1149', '1037', '616', '128', '560', '1337', '244', '628', '1433', '93', '606', '394', '1444', '649', '1178', '335', '553', '1106', '769', '1422', '992', '1171', '349', '1160', '1181', '1448', '1142', '661', '1215', '248', '1351', '1245', '1093', '796', '228', '457', '585', '826', '123', '496', '1049', '1298', '17', '345', '1058', '1406', '223', '185', '163', '422', '724', '408', '652', '1008', '1340', '916', '583', '889', '1161', '621', '1441', '1021', '1098', '1416', '575', '25', '113', '166', '1173', '43', '1052', '523', '1151', '331', '350', '1427', '42', '1031', '315', '471', '160', '1044', '1202', '1440', '234', '1248', '342', '323', '258', '516', '1388', '500', '340', '1454', '1315', '148', '413', '1399', '600', '98', '1082', '126', '1221', '676', '736', '256', '1232', '502', '343', '1398', '432', '173', '7', '1443', '476', '594', '546', '419', '1101', '426', '660', '1136', '1039', '1328', '1189', '297', '1081', '978', '888', '718', '369', '1150', '1226', '1431', '441', '890', '477', '1212', '654', '37', '1292', '773', '1390', '409', '158', '1042', '395', '19', '1090', '1241', '725', '1224', '838', '951', '429', '1421', '482', '16', '307', '779', '1256', '1201', '1206', '862', '1418', '1423', '310', '264', '12', '1425', '1134', '344', '1053', '1323', '157', '451', '1166', '1295', '1100', '1013', '122', '1163', '417', '639', '717', '1414', '1257', '424', '839', '1223', '549', '907', '540', '1243', '114', '1129', '1280', '851', '1275', '254', '1004', '1167', '325', '389', '730', '481', '1382', '283', '710', '1459', '703', '882', '336', '467', '1117', '1035', '23', '948', '698', '770', '1268', '815', '288', '760', '1204', '970', '601', '1056', '370', '841', '1000', '1343', '465', '1408', '1267', '935', '428', '1041', '504', '97', '781', '767', '528', '235', '278', '878', '404', '961', '848', '884', '11', '1234', '212', '1240', '946', '609', '595', '351', '298', '802', '593', '1025', '700', '397', '1079', '9', '105', '561', '353', '168', '197']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.083"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Model of Cluster Searching Based on Classification The use of document clusters has been suggested as an efficient file organization for a document retrieval system.  It is possible that by using this information about the relationships between documents that the effectiveness of the system (i.e., its ability to distinguish relevant from non-relevant documents) may also be improved.  In this paper a probabilistic model of cluster searching  based on query classification is described.  This model is tested with retrieval experiments which indicate that it can be more effective than heuristic cluster searches and cluster searches based on other models.  It can also be more effective than a full search in which every document is compared to the query.  The efficiency aspects of the implementation of the model are discussed.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['575', '577', '310', '661', '483', '446', '515', '631', '715', '68', '826', '722', '1170', '704', '1164', '1162', '1134', '959', '498', '1120', '630', '703', '58', '429', '1343', '84', '1298', '654', '450', '1448', '42', '963', '625', '426', '872', '466', '561', '502', '721', '773', '591', '1144', '69', '1136', '194', '67', '799', '678', '582', '1171', '962', '1417', '590', '1309', '725', '706', '307', '853', '798', '47', '699', '726', '647', '571', '423', '534', '808', '1057', '639', '528', '461', '1368', '493', '1116', '758', '539', '500', '890', '1367', '294', '481', '1227', '482', '66', '673', '465', '315', '467', '710', '640', '6', '780', '839', '452', '105', '516', '64', '587', '822', '1008', '1075', '278', '107', '690', '1179', '599', '532', '17', '638', '807', '597', '1254', '990', '713', '685', '352', '958', '41', '1353', '130', '456', '40', '222', '155', '1321', '774', '1334', '1001', '1346', '720', '1201', '836', '277', '848', '789', '818', '1014', '1090', '574', '694', '781', '821', '1358', '238', '1157', '211', '751', '854', '291', '1347', '217', '1416', '533', '50', '1167', '616', '1397', '205', '11', '897', '417', '1133', '1344', '1182']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.006"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.077"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.011<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Technology of Library and Information Networks Current online library network technology is described, including the physical and functional aspects of networks.  Three types of networks are distinguished:  search service (e.g., SDC, Lockheed), customized service that provide bibliographic files (e.g., OCLC, Inc., RLIN), and service center (e.g., NELINET, INCOLSA).  It is predicted that as technology evolves more services will be provided outside the library directly to the user through his home or office.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['375', '376', '619', '497', '979', '918', '935', '400', '970', '298', '304', '249', '964', '1365', '406', '181', '22', '1033', '331', '151', '1347', '172', '1072', '556', '1174', '837']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.115"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.086"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.098<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Use of Titles for Automatic Document Classification An experimental computer program has been developed to classify documents according to the 80 sections and five major section groupings of Chemical Abstracts (CA).  The program uses pattern recognition techniques supplemented by heuristics.  During the \"training\" phase, words from pre-classified documents are selected, and the probability of occurrence of each word in each section of CA is computed and stored in a reference dictionary.  The \"classification\" phase matches each word of a document title against the dictionary and assigns a section number to the document using weights derived from the probabilities in the dictionary.  Heuristic techniques are used to normalize word variants such as plurals, past tenses, and gerunds in both the training phase and the classification phase.  The dictionary lookup technique is supplemented by the analysis of chemical nomenclature terms into their component word roots to influence the section to which the documents are assigned.  Program performance and human consistency have been evaluated by comparing the program results against the published sections of CA and by conducting an experiment with people experienced in the assignment of documents to CA sections.  The program assigned approximately 78% of the documents to the correct major section groupings of CA and 67% of the correct sections or cross-references at a rate of 100 documents per second.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['71', '1248', '589', '388', '1415', '447', '1091', '898', '409', '1024', '1366', '1342', '1194', '617', '849', '133', '1416', '588', '861', '1432', '1259', '1340', '476', '1047', '400', '1072', '803', '470', '1272', '1314', '1346', '909', '417', '634', '549', '96', '953', '222', '1065', '984', '774', '1079', '902', '407', '290', '239', '1031', '1005', '1351', '12', '1198', '456', '284', '463', '599', '265', '331', '130', '1318']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.017"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.031"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.022<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brief Communications Some of the automatic classification procedures used in information retrieval derive clusters of documents from an intermediate similarity matrix, the computation of which involves comparing each of the documents in the collection with all of the others.  It has recently been suggested that many of these comparisons, specifically those between documents having no terms in common, may be avoided by means of the uyse of an inverted file to the document collection.  This communication shows that the approach will effect reductions in the number of interdocument comparisons only if the documents are each indexed by a limited number of indexing terms; if exhaustive indexing is used, many document pairs will be compared several times over and the computation will be greater than when conventional approaches are used to generate the similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['570', '328', '1120', '277', '362', '679', '1143']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.031"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Application of a Minicomputer to Thesaurus Construction The Use of a minicomputer in various phases of creating the thesaurus for the National Information Center for Special Education Materials (NICSEM) database is described.  The minicomputer is used to collect, edit, and correct candidate thesaurus terms.  The use of the minicomputer eases the process of grouping terms into files of similar concepts and facilitates the generation of products useful in vocabulary review and in term structuring.  Syndetic relations, indicated by assigning coded identification numbers, are altered easily in the design phase to reflect restructuring requirements.  Because thesaurus terms are already in machine- readable form, it is simple to prepare print programs to provide permuted, alphabetic, hierarchical, and chart formatted term displays.  Overall, the use of the minicomputer facilitates initial thesaurus entry development by reducing clerical effort, editorial staff decisions, and overall processing times.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['511', '1421', '506', '1076', '1325', '1415', '868', '1366', '378', '581', '825', '174', '593', '1408', '947', '446', '1363', '329', '811', '860', '158', '136', '223', '409', '86', '826', '1449', '842', '141', '1369', '80', '92', '1090', '727', '788', '1328', '140', '620', '728', '945', '5', '47', '764', '571', '371', '959', '278', '1416', '1396', '131', '657', '1058', '1079', '207', '391', '1339', '1372', '145', '1404', '885', '1253', '841', '1371', '1277', '89', '1183', '1248', '743', '27', '165', '963', '1096', '222', '1128', '311', '1417', '474', '1373', '1207', '978', '495', '64', '1454', '938', '470', '1052', '476', '1206', '832', '436', '561', '313', '1365', '459', '1359', '815', '934', '1039', '413', '839', '1229', '1419', '438', '427', '517', '1386', '325', '138', '582', '173', '124', '899', '107', '154', '1002', '193', '417', '1330', '395', '908', '473', '20', '228', '202', '490', '439', '1457', '496', '1240', '1051', '150', '966', '1108', '1082', '453', '1099', '686', '291', '1387', '433', '282', '923', '615', '567', '1338', '198', '846', '156', '95', '308', '400', '1364', '239', '245', '933', '1231', '475', '926', '471', '971', '1433', '932', '243', '613', '1286', '639', '691', '257', '794', '901', '1069', '503', '1394', '1403', '440', '911', '747', '335', '100', '33', '108', '950', '1460', '631', '97', '793', '850', '1374', '1370', '524', '1233', '1324', '324', '242', '1393', '595']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaptive Design for Decision Support Systems Decision Support Systems (DSS) represent a concept of the role of computers within the decision making process.  The term has become a rallying cry for researchers, practitioners, and managers concerned that Management Science and Management Information Systems fields have become unnecessarily narrow in focus.  As with many rallying cries, the term is not well defined.  For some writers, DSS simply mean interactive systems for use by managers.  To others, the key issue is support, rather than system.  They focus on understanding and improving the decision process; a DSS is then designed using any available and suitable technology. Some researchers view DSS as a subfield of MIS, while others regard it as an extension of Management Science techniques.  The former define Decision Support as providing managers with access to data and the latter as giving them access to analytic models.  The key argument of this paper is that the term DSS is relevant to situations where a \"final\" system can be developed only through an adaptive process of learning and evolution.  The design strategy must then focus on getting finished; this is very different from Management Science and Data Processing approaches.  The research issued for DSS center around adaption and evolution; they include managerial learning representation of tasks and user behavior, design architecture and strategies for getting started.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['359', '164', '973', '1069', '1434']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Automatic Method for Extracting Significant Phrases in Scienfific or Technical Documents A new method is described to extract significant phrases in the title and the abstreact of scientific or technical documents.  The method is based upon a text structure analysis and uses a relatively small dictionary. The dictionary has been constructed based on the knowledge about concepts in the field of science or technology and some lexical knowledge.  For significant phrases and their component items may be used in different meanings among the fields.  A text analysius approach has been applied to select significant phrases as substantial and semantic information carriers of the contents of the abstract.  The results of the experiment for five sets of documents have shown that the significant phrases are effectively extracted in all cases, and the number of them for every document and the processing time is fairly satisfactory.  The information representation of the document, partly using the method, is discussed with relation to the construction of the document information retrieval system.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1124', '483', '666', '175', '820', '1054', '1281', '448', '565', '419', '136', '179', '1327', '566', '68', '571', '1419', '71', '1190', '564', '582', '317', '309', '1191', '1215', '636', '446', '72', '1460', '641', '486', '1175', '484', '319', '49', '449', '825', '329', '1080', '517', '523', '553', '659', '1144', '522', '1298', '461', '707', '472', '321', '575', '228', '576', '137', '1128', '202', '1391', '726', '17', '447', '131', '1207', '542', '381', '1126', '560', '327', '151', '898', '126', '224', '1127', '132', '421', '982', '865', '664', '320', '1448', '511', '1361', '1136', '373', '1105', '64', '510', '123', '826', '644', '754', '135', '842', '95', '73', '1195', '1366', '660', '1044', '815', '840', '1417', '723', '1092', '478', '572', '621', '310', '1427', '1326', '376', '702', '61', '1121', '1255', '409', '682', '562', '150', '1171', '1109', '1091', '728', '1112', '1098', '642', '1125', '158', '737', '889', '519', '1179', '1416', '544', '1114', '1360', '801', '1120', '513', '1457', '1309', '347', '822', '482', '388', '626', '652', '600', '433', '1230', '1099', '512', '1418', '44', '390', '773', '1405', '796', '514', '28', '1350', '1043', '1053', '1073', '731', '534', '556', '1409', '140', '1051', '257', '1035', '703', '1348', '838', '724', '243', '294', '1227', '966', '690', '252', '244', '1077', '114', '557', '727', '916', '481', '497', '890', '529', '1328', '1163', '1016', '615', '48', '254', '762', '443', '607', '648', '895', '434', '335', '798', '332', '986', '1225', '174', '1024', '526', '911', '117', '704', '1415', '27', '610', '830', '630', '627', '1084', '1447', '646', '603', '492', '827', '54', '1223', '74', '89', '408', '1180', '190', '1078', '1173', '102', '354', '85', '1341', '637', '1358', '535', '1362', '1395', '197', '528', '128', '595', '671', '474', '1057', '507', '530', '670', '451', '591', '1139', '525', '970', '990', '459', '501', '502', '779', '739', '67', '192', '839', '740', '742', '1104', '504', '1038', '1377', '676', '639', '222', '606', '611', '1196', '532', '1367', '66', '1256', '989', '180', '400', '1170', '454', '1410', '399', '157', '267', '725', '917', '809', '625', '574', '134', '531', '593', '947', '1111', '120', '1283', '537', '709', '1436', '1010', '325', '1339', '1349', '601', '382', '567', '1143', '993', '4', '1401', '318', '515', '291', '1305', '998', '1337', '955', '16', '984', '1040', '802', '694', '833', '695', '129', '213', '1413', '340', '25', '546', '159', '212', '1152', '700', '806', '795', '620', '468', '386', '850', '1261', '848', '866', '1264', '1277', '490', '1081', '954', '200', '477', '1011', '883', '458', '465', '1093', '250', '538', '697', '1012', '245', '124', '119', '387', '617', '701', '398', '674', '590', '1110', '378', '1363', '375', '852', '445', '677', '1241', '80', '786', '380', '165', '691', '720', '681', '177', '609', '683', '1067', '1282', '744', '843', '1206', '115', '1074', '579', '706', '849', '687', '1289', '860', '925', '1106', '1000', '1425', '1022', '897', '57', '1267', '752', '358', '491', '1062', '547', '1197', '780', '494', '1113', '741', '699', '874', '104', '476', '647', '846', '1209', '389', '262', '1293', '948', '1229', '1117', '1333', '1378', '350', '336', '1193', '18', '1437', '452', '208', '508', '1072', '59', '292', '467', '1307', '106', '1317', '1007', '268', '716', '612', '265', '364', '951', '634', '597', '295', '868', '1085', '872', '141', '710', '871', '654', '941', '1402', '288', '594', '231', '1259', '406', '211', '1236', '693', '287', '1249', '689', '1001', '348', '168', '841', '1137', '1290', '1049', '1147', '884', '880', '10', '979', '645', '785', '1148', '888', '1445', '960', '1456', '862', '1375', '1004', '997', '999', '13', '394', '1', '396']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.023"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.444"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.044<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer-Passage Retrieval by Text Searching Passage retrieval (already operational for lawyers) has advantages in output form opver references retrieval and is economically feasible. Previous experiments in passage retrieval for scientists have demonstrated recall and false retrieval rates as good or better than those of present reference retrieval services.  The present experiment involved a greater variety of forms of retrieval question.  In addition, search words were selected independently by two different people for each retrieval question. The search words selected, in combination with the computer procedures used for passage retrieval, produced average recall ratios of 72 and 67%, respectively, for the two selectors.  The false retrieval rates were (except for one predictably difficult question) respectively 13 and 10 falsely retrieved sentences per answer-paper retrieved.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['636', '487', '820', '603', '806', '523', '519', '810', '520', '150', '197', '381', '1392', '1197', '429', '477', '868', '876']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.444"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial-Match Retrieval Using Indexed Descriptor Files In this paper we describe a practical method of partial-match retrieval in very large data files.  A binary code word, called a descriptor, is associated with each record of the file.  These record descriptors are then used to form a derived descriptor for a block of several records, which will serve as an index for the block as a whole; hence, the name \"indexed descriptor files.\"  First the structure of these files is described and a simple, efficient retrieval algorithm is presented.  Then its expected behavior, in terms of storage accesses, is analyzed in detail.  Two different file creation procedures are sketched, and a number of ways in which the file organization can be \"tuned\" to a particular application is suggested.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1124', '1108', '530', '812', '61', '429', '600', '755', '27', '495', '174', '490', '1160', '47', '73', '630', '1417', '1381', '445', '748', '802', '745', '625', '16', '433', '42', '79', '781', '1044', '960', '1346', '849', '189', '962', '821', '167', '1135', '627', '910', '219', '466', '1174', '609', '198', '1350', '1098', '808', '1074', '432', '652', '638', '585', '1001', '841', '1181', '628', '1104', '1100', '70', '154', '1163', '1354', '87', '846', '31']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.444"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cooperation and Competition Among Library Networks Recenty technological advances and the success of OCLC, Inc. has led to the emergence of three additional nonprofit library networks:  the Research Libraries Information Network (RLIN) of the Research Libraries Group, Inc., the University of Toronto Library Automation System (UTLAS), and the Washington Library Network (WLN).  This paper examines the economic and technological factors affecting the evolution of these networks and also explores the role of those state and regional (multistate) networks that broker OCLC services.  The competitive and cooperative nature of network relationships is a major theme of the discussion.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['119', '481', '1186', '285', '960', '1248', '1052', '1212', '917', '978', '257', '878', '96', '918', '929', '22', '1068', '902', '6', '484', '246', '1441', '476', '1402', '1111', '575', '610', '546', '953', '1271', '1200', '1057', '89', '1387', '458', '538', '1315', '59', '60', '752', '418', '1309', '716', '471', '1254', '28', '1030', '758', '78', '549', '176', '199', '725', '168', '469', '461', '396', '84', '751', '1044', '154']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.444"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Integrated Understander A new type of natural language parser is presented.  The idea behind this parser is to map input sentences into the deepest form of the representation of their meaning and inferences, as is appropriate.  The parser is not distinct from an entire understanding system.  It uses an integrated conception of inferences, scripts, plans and other knowledge to aid in the parse.  Furthermore, it does not attempt to parse everything it sees.  Rather, it determines what is most interesting and concentrates on that, ignoring the rest.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['393', '1338', '358', '14', '22']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.444"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Networks and Resource Sharing in the United States: An Historical and Philosophical Overview This paper discusses the origins of library networks and traces their development in the United States in the late 1960s through the present. The concept of resource sharing, with particular attention to the inter- library loan and programs for the cooperative acquisition and storage of materials, is examined in relationship to library networks.  In particular, attention is given to the question of how these two major components of library cooperation, which have tended to be separate, might become more closely integrated.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['884', '849', '1152', '992', '556', '1071', '1171', '1427', '481', '572', '417', '796', '702', '1223', '704', '312', '1153', '709', '628', '993', '438', '513']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.091"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.033"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.049<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization of Titles and Their Retrieval This paper presents a method of normalizations of English titles and their retrieval.  The title expressed by a noun phrase or a noun clause is converted to a function-expression by parsing.  For the retrieval with a reasonable recall rate as well as a high precision rate, the function- expression is transformed to a predicate-governor form, and then normalized to a standard form.  Therefrom, various items are extracted and recorded in a hierarchical tree-like inverted file.  In order to keep the recall rate in a reasonable value, several retrieval stages are implemented based on the key-term and case-label matching.  The retrieval is controlled by the preciseness of the specification of case-labels for each key-term.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['862', '919', '479', '58', '1191', '637', '824', '68', '1190', '1460', '489', '706', '883', '136', '1396', '877', '597']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.033"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cascaded ATN Grammars A generalization of the notion of ATN grammar, called a cascaded ATN (CATN), is prescribed.  CATN's permit a decomposition of complex language understanding behavior into a sequence of cooperating ATN's with separate domain of responsibility, where each stage (called an ATN transducer) takes its input from the output of the previous stage.  The paper includes an extensive discjussion of the principles of factoring-conceptual factoring reduces the number of places that a given fact needs to be represented in a grammar, and hypothesis factoring reduces the number of distinct hypotheses that have to be considered during parsing.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.033"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithms for Processing Partial Match Queries Using Word Fragments Algorithms are given to process partially specified queries in a compressed database system.  The proposed methods handle effectively queries that use either whole words or word fragments as language elements. The methods are compared and critically evaluated in terms of the design and retrieval costs.  The analyses show that the method which exploits the interdependence of fragments as well as the relevance of fragments to records in the file has maximum design cost and least retrieval cost.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1366', '523', '620', '321', '512', '1358', '875', '807', '446', '507', '865', '615', '702', '571', '214', '492', '860', '822', '500', '27', '594', '690', '737', '842', '872', '222', '617', '158', '1252', '1264', '1230', '1417', '962', '294', '299', '408', '466', '813', '811', '17', '490', '704', '792', '629', '591', '510', '250', '497', '979', '675', '295', '218', '520', '639', '468', '465', '984', '1365', '126', '952', '840', '921', '809', '324', '1421', '491', '614', '1450', '192', '74', '1371', '281', '292', '249', '1353', '288', '1410', '279', '305', '974', '255', '380', '831', '400', '364', '1396', '348', '496', '848', '1449', '1305', '495', '1258', '849', '1060', '938', '83', '839', '1363', '623', '884', '1368', '1040', '515', '1376', '167', '1374', '795', '879', '482', '326', '271', '16', '834', '723', '897', '584', '957', '12', '367', '551', '976', '1203', '331', '56', '774', '1151', '724', '80', '1390', '1248', '1071', '939', '189', '307', '950', '457', '353']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A General Formulation of Bradford's Distribution:  The Graph-Oriented Approach From the detailed analysis of eight previously published mathematical models, a general formulation of Bradford's distribution can be deduced as follows:  y = a log(x + c) + b, where y is the ratio of the cumulative frequency of articles to the total number of articles and x is the ratio of the rank of journals to the total number of journals.  The parameters a, b, and c are the slope, the intercept, and the shift in a straight line to log rank, respectively.  Each of the eight models is a special case of the general formulation and is one of five types of formulation.  In order to estimate three unknown parameters, a statistical method using root-weighted square error is proposed.  A comparative experiment using 11 databases suggests that the fifth type of formulation with three unknown parameters is the best fit to the observed data.  A further experiment shows that the deletion of the droop data leads to a more accurate value of parameters and less error.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1196', '587', '409', '581', '380', '492', '1073', '750', '1221', '795', '517', '862', '1033']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lexical Problems in Large Distributed Information Systems The lexical problems in large information systems are created by the necessity of handling a great number of names and their interrelations. Such lexical problems are not covered completely by the concept data dictionaries, which are mostly concerned with database scheme design rather than the execution of operations.  In this paper we introduce our view of a lexical subsystem as a separate component in an information system architecture, to deal with linguistic and control functions concerning the lexical problems in local and network environments.  The lexical suybsystem is a special efficiently organized program package, which plays the role of a \"linguistic filter\" in a broad sense for lexically incorrect queries, promotes integration of databases and information retrieval systems, and facilitates the creation of local information systems.  We hope that lexical subsystems can become productive for any large, especially distributed, information system.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['497', '1416', '1171', '175', '179', '135', '27', '1448', '459', '1011', '553', '67', '607', '336', '64', '490', '483', '611', '572', '140', '376', '993', '310', '538', '1093', '451', '458', '1053', '593', '1136', '916', '815', '523', '674', '373', '126', '606', '213', '1298', '690', '883', '347', '1105', '595', '158', '128', '1081', '884', '617', '180', '525', '1143', '621', '682', '481', '114', '948', '955', '707', '375', '839', '1223', '1362', '575', '1241', '826', '574', '1128', '528', '325', '779', '202', '594', '350', '254', '579', '1106', '434', '630', '244', '461', '129', '511', '535', '737', '123', '565', '664', '1092', '652', '408', '321', '1114', '1207', '484', '1038', '822', '970', '120', '474', '137', '394', '874', '546', '1173', '504', '1309', '378', '1080', '998', '59', '1012', '119', '1098', '136', '381', '445', '660', '615', '1256', '648', '421', '1358', '319', '1139', '703', '1113', '947', '1077', '1405', '796', '1121', '513', '486', '72', '1170', '1035', '654', '591', '1418', '197', '639', '515', '809', '1144', '1022', '243', '582', '646', '1326', '849', '1341', '389', '1125', '1305', '332', '1057', '1419', '726', '74', '1215', '1124', '889', '642', '159', '798', '340', '1109', '841', '724', '1078', '252', '842', '257', '612', '1112', '66', '676', '157', '1391', '388', '501', '637', '419', '620', '57', '476', '482', '670', '1264', '590', '132', '641', '1180', '1410', '1456', '1148', '309', '526', '727', '477', '566', '706', '862', '532', '85', '28', '1236', '177', '433', '694', '1110', '659', '951', '827', '228', '600', '1193', '1427', '449', '846', '1099', '560', '802', '49', '448', '806', '320', '1328', '1179', '1436', '671', '644', '866', '567', '1349', '291', '1367', '80', '141', '773', '941', '508', '472', '1348', '454', '1104', '1413', '1072', '626', '960', '1016', '294', '1293', '716', '329', '681', '494', '124', '327', '1191', '865', '990', '478', '534', '502', '54', '1437', '1051', '446', '1282', '1190', '131', '1460', '982', '317', '1227', '1289', '542', '1084', '1447', '17', '1378', '704', '1361', '512', '925', '1307', '786', '780', '1283', '16', '267', '529', '1073', '507', '386', '1120', '742', '537', '838', '231', '1054', '850', '689', '1209', '514', '723', '406', '897', '318', '871', '710', '492', '1127', '115', '134', '1360', '601', '695', '986', '725', '636', '848', '250', '1163', '917', '400', '739', '102', '1010', '557', '1049', '645', '627', '18', '1375', '1339', '544', '701', '1196', '73', '547', '700', '348', '795', '709', '1350', '151', '165', '95', '556', '699', '491', '634', '1111', '1126', '1445', '872', '1004', '666', '1147', '89', '1281', '895', '677', '25', '245', '387', '1007', '687', '174', '1366', '801', '465', '728', '966', '335', '843', '1261', '571', '531', '691', '888', '1091', '1062', '1000', '452', '880', '989', '1395', '68', '287', '467', '1425', '1175', '898', '702', '1267', '288', '295', '1255', '358', '168', '860', '1074', '609', '443', '117', '211', '890', '224', '597', '762', '1327', '610', '354', '517', '647', '150', '212', '382', '1117', '4', '1401', '562', '1137', '44', '1043', '190', '825', '693', '1067', '1225', '398', '720', '603', '61', '820', '997', '265', '1229', '833', '409', '1402', '744', '979', '396', '1044', '1197', '683', '292', '1230', '222', '530', '1290', '754', '519', '48', '390', '1024', '984', '1259', '104', '1333', '731', '1417', '192', '1001', '840', '1317', '468', '785', '10', '1277', '999', '1249', '522', '1415', '697', '1085', '1195', '752', '1377', '71', '262', '268', '741', '1409', '954', '740', '1337', '1206', '1363', '447', '364', '510', '852', '576', '380', '868', '399', '13', '1457', '625', '1', '830', '911', '564', '208', '1040', '1152', '200', '106']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.014"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.636"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.027<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Relational Model in Information Retrieval The relational model has received increasing attention during the past decade.  Its advantages include simplicity, consistency, and a sound theoretical basis.  In this article, the naturalness of viewing information retrieval relationally is demonstrated.  The relational model is presented, and the relational organization of a bibliographical database is shown. The notion of normalization is introduced and first, second, third, and fourth normal forms are demonstrated.  Relational languages are discussed, including the relational calculus, relational algebra, and SEQUEL. Numerous examples pertinent to information retrieval are presented in these relational languages.  Advantages of the relational approach to information retrieval are noted.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['523', '553', '1112', '613', '691', '185', '1261', '189', '752', '293', '186', '645', '21']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electronic Information Interchange in an Office Environment This paper describes an architectural approach that provides information exchange across a broad spectrum of user applications and office automation offerings.  Some of the architectures described herein are currently implemented in existing IBM products.  These and other architectures will provide the basis for document interchange capability between products such as the IBM 5520 Administrative System, the IBM System/370 Distributed Office Support System (DISOSS), and the IBM Displaywriter System. Specifically described is a document distribution architecture and its associated data streams and others.  A general overview of the architectures as opposed to a detailed technical description is provided.  The architectures described are protocols for interchange between application processes; they do not address the specific user interface.  The document distribution architectures utilize SNA for data transmission and communications control facilities.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['617', '703', '136', '529', '1365', '375', '126', '180', '1430', '54', '655', '1207', '78', '624', '287', '512', '186', '1009', '957', '332', '380', '1211', '495', '1275', '704', '760', '269', '1237', '1400', '1071', '924', '1147']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Use of Automatic Relevance Feedback in Boolean Retrieval Systems A technique is described for automatic reformulation of boolean queries.  Based on patron relevance judgements of an initial retrieval, prevalence measures are derived for terms appearing in the retrieved set of documents that reflect a term's distribution among the relevant and non-relevant documents.  These measures are then used to guide the construction of a boolean query for a subsequent retrieval.  To illustrate the technique, a series of tests is described of its application to a small data base in an experimental environment.  Results compare favourably with feedback as employed in a SMART-type system.  MOre extensive testing is suggested to validate the technique.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['810', '1124', '487', '636', '603', '564', '660', '479', '731', '754', '446', '522', '575', '511', '662', '637', '1139', '962', '1274', '633', '630', '706', '579', '643', '663', '388', '785', '571', '824', '627', '780', '489', '835', '623', '1091', '737', '151', '612', '959', '422', '466', '1127', '1144', '798', '409', '1421', '133', '642', '126', '315', '30', '496', '278', '830', '1207', '357', '1092', '493', '682', '1126', '963', '606', '495', '317', '734', '1090', '593', '1359', '474', '758', '427', '563', '646', '1234', '841', '500', '801', '715', '1450', '1130', '1361', '709', '867', '174', '676', '69', '120', '616', '692', '1313', '1398', '302', '499', '408', '1362', '577', '136', '1215', '598', '327', '504', '967', '341', '373', '1405', '1027', '506', '1051', '1414', '527', '714', '1416', '360', '620', '1183', '1317', '291', '1064', '56', '1047', '121', '1315', '587', '602', '273', '426', '556', '945', '5', '821', '90', '907', '132', '359', '592', '795', '936', '316', '15', '982', '298', '678', '140', '1353', '279', '671', '922', '800', '1242', '370', '711', '335', '1319', '561', '684', '1075', '424', '361', '1263', '274', '94', '248']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interacting in Natural Language With Artificial Systems:  The Donau Project This paper is intended to propose a new methodological approach to the conception and development of natural language understanding systems. This new contribution is supported by the design, implementation, and experimentation of DONAU:  a general purpose domain oriented natural language understanding system developed and presently running at the Milan Polytechnic Artificial Intelligence Project.  The system is based on a two level modular architecture intended to overcome the lack of flexibility and generality often pointed out in many existing systems, and to facilitate the exchange of results and actual experiences between different projects. The horizontal level allows an independent and parallel development of the single segments of the system (syntactic analyser, information extractor, legality controller).  The vertical level ensures the possibility of changing (enlarging or redefining) the definition of the semantic domain on which each particular version of the system is oriented and specialized in a simple, incremental, and user-oriented way.  In the paper the general architecture of the system and the mode of operation of each segment are illustrated in detail.  Linguistic models, knowledge representation, and parsing algorithms are described and illustrated by means of selected examples.  Performance evaluations of the system in the application version on data base inquiry are reported and discussed.  Promising directions for future research are presented in the conclusions.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['595', '534', '134', '1164', '1162', '1175', '479', '1399', '72', '1241', '1118', '168', '1407', '161', '716', '343', '1339', '830', '564', '946', '1395', '596', '772', '1049', '331', '1254', '315', '828', '657', '735', '178', '1169', '1356', '198', '922', '81', '249', '367', '75', '1095', '845', '918', '1178', '1403', '1030', '1122', '1200', '1253', '237', '578']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate String Matching Approximate matching of strings is reviewed with the aim of surveying techniques suitable for finding an item in a database when there may be a spelling mistake or other error in the keyword.  The methods found are classified as either equivalence or similarity problems. Equivalence problems are seen to be readily solved using canonical forms. For similarity problems difference measures are surveyed, with a full description of the well-established dynamic programming method relating this to the approach using probabilities and likelihoods.  Searches for approximate matches in large sets using a difference function are seen to be an open problem still, though several promising ideas have been suggested.  Approximate matching (error correction) during parsing is briefly reviewed.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['317', '316', '706', '1098', '1105', '356', '121', '1024', '58', '395', '582', '291', '1078', '553', '830', '818', '730', '955', '11', '1213', '1294', '824', '827', '505', '194', '127', '1377']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an Online Microfiche Catalog for Technical Service and Retrieval of Bibliographic Data A prototype system is created that integrates a microfiche catalog into an online computer system for bibliographic control.  Costs and operational data are collected and analyzed.  The system permits the more economical microfiche storage of catalog records than would be feasible for comparable online magnetic disk storage.  Experimental tests demonstrate the feasibility of the online microfiche catalog system for use in library technical services and retrieval of bibliographic data.  The primary result of the project is the creation of a completely operational facility, including all equipment, software, procedures, and data bases necessary to demonstrate the system.  A second set of results is derived from the experimental use of the system and the evaluation of costs and times for various operations.  The cost effectiveness of the online microfiche catalog is demonstrated.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['17', '497', '164', '1419', '128', '809', '693', '207', '487', '808', '1184', '300', '352', '205', '1131', '602']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Access to Information Systems.  An Evaluation Study of Its Acceptance by End Users The question is asked whether it is feasible to use subsets of natural languages as query languages for data bases in actual applications using the question answering system \"USER SPECIALTY LANGUAGES\" (USL). Methods of evaluating a natural language based information system will be discussed.  The results (error and language structure evaluation) suggest how to form the general architecture of application systems which use a subset of German as query language.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['317', '637', '445', '1327', '514', '1427', '1139', '434', '151', '1164', '1162', '530', '1171', '1136', '329', '1024', '378', '19', '396', '1124', '1366', '814', '572', '461', '900', '609', '595', '390', '168', '901', '539', '10', '175', '1185', '702', '1175', '641', '1120', '179', '159', '1443', '801', '78', '477', '597', '1225', '825', '498', '796', '1382', '798', '692', '779', '755', '802', '895', '1215', '328', '136', '1077', '1118', '614', '1099', '450', '1326', '1414', '866', '1129', '817', '1027', '585', '1180', '320', '761', '746', '1226', '389', '257', '25', '576', '197', '1043', '1267', '30', '342', '1409', '902', '760', '174', '357', '687', '1047', '1280', '480', '1046', '769', '789', '1323', '556', '479', '1055', '269', '397', '146', '447', '37', '443', '688', '1459', '149', '830', '788', '838', '873', '343', '65', '1393', '558', '1045', '432', '909']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some Considerations Relating to the Cost-Effectiveness of Online Services in Libraries In 1978 Collier presented some hypothetical data on economic aspects of the use of online services as compared with subscriptions to printed services in libraries.  Collier's view of the economics of online searching seems misleadingly pessimistic because:  1.  It looks only at costs but not at effectiveness in comparing the two modes of access and searching.  An analysis combining cost and effectiveness aspects (i.e., a cost-effectiveness analysis) would give a completely different picture.  2.  The way the cost data are presented is grossly unfair to the online mode of access and use.  This work contains corrected information regarding online and printed services in libraries.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1365', '1376', '799', '1366', '126', '842', '614', '1248', '728', '1377', '292', '217', '734', '957', '879', '986', '1396', '364', '365', '307', '190', '123', '724', '9', '348', '584', '1015', '358', '1324', '205', '376', '295', '962', '1008', '222', '408', '1368', '1417', '1378', '306', '959', '979', '1221', '162', '204', '575', '1264', '1353', '4', '1401', '161', '839', '841', '1060', '224', '792', '594', '984', '757', '840', '1415', '972', '942', '547', '721', '10', '976', '470', '529', '2', '281', '938', '866', '970', '208', '1360', '946', '297', '1020', '1418', '743', '1252', '153', '92', '1258', '865', '1453', '12', '265', '507', '1018', '279', '17', '1266', '638', '1265', '816', '193', '363', '31', '186', '1362', '115', '900', '963', '1203', '706', '459', '817', '1205', '244', '367', '189', '1230', '1032', '952', '1241', '305', '914', '214', '1212', '1457', '72', '617', '250', '296', '831', '932', '338', '1236', '1390', '930', '1215', '845', '206', '223', '774', '965', '583', '597', '661', '1280', '294', '913', '1433', '194', '1410', '1371', '1245', '409', '267', '177', '1006', '1325', '290', '974', '291', '987', '207', '268', '375', '1440', '234', '334', '167', '140', '353', '1450', '1009', '892', '185', '645', '257', '246', '980', '331', '197', '1400', '925', '336', '983', '1189', '1056', '1239', '216', '87', '950', '260', '187', '300', '601', '905', '1043', '1373', '881', '935', '860', '655', '854', '249', '1367', '219', '977', '552', '288', '624', '934', '1184', '1394', '857', '1058', '184', '1211', '1090', '1350', '973', '811', '1253', '592', '936', '985', '293', '836', '515', '304', '991', '90', '337', '339', '933', '834', '616', '14', '1393', '23', '1003', '136', '555', '948', '135', '910', '1445', '342', '1066', '386', '32', '896', '961', '36', '33', '352', '911', '1437', '1423', '1021', '220', '1192', '1432', '1068', '916', '202', '556', '374', '504', '620', '142', '1079', '856', '381', '872', '1439', '1349', '80', '1049', '1352', '1012', '141', '944', '351', '1403', '589', '1422', '245', '178', '243', '593', '325', '273', '849', '660', '200', '1358', '122', '183', '921', '929', '909', '917', '280', '1395', '452', '939', '1183', '406', '823', '373', '907', '883', '818', '1240', '16', '303', '502', '1193', '844', '472', '56', '1071', '903', '203', '393', '22', '411', '873', '1369', '1216', '922', '298', '926', '1363', '978', '847', '966', '990', '1147', '1404', '366', '850', '888', '887', '551', '1231', '283', '225', '550', '192', '908', '884', '201', '1055', '258', '947', '808', '1317', '981', '1007', '788', '276', '1206', '1237', '1441', '1013', '182', '928', '846', '1051', '264', '354', '874', '1017', '388', '91', '875', '266', '433', '1152', '404', '282', '955', '270', '918', '382', '789', '1042', '843', '248', '1397', '756', '1424', '949', '654', '20', '6', '340', '1425', '858', '143', '1318', '573', '1229', '1057', '371', '1149', '766', '370', '878', '263', '607', '405', '768', '171', '967', '906', '964', '832', '432', '1355', '195', '394', '1379', '1246', '67', '414', '1053', '1242', '982', '402', '1263', '1197', '181', '943', '975', '1380', '269', '1359', '1052', '1011', '387', '163', '261', '46', '413', '1384', '998', '1249', '543', '994', '997', '64', '278', '848', '924', '262', '767', '235', '937', '919', '951', '188', '8', '275', '198', '240', '210', '1354', '323', '1412', '1357', '11', '587', '915', '431', '1247', '1238', '147', '272', '891', '1005', '559', '462', '230', '1372', '786', '383', '407', '923', '24', '1257', '302', '209', '285', '885', '410', '211', '783', '904', '1243', '647', '941', '286', '322', '651', '7', '238', '1196', '960', '274', '120', '18', '301', '1028', '1033', '1268', '287', '196', '215', '1023', '988', '1275', '931', '886', '251', '1451', '968', '863', '1086', '969', '861', '1085', '119', '945', '242', '5', '1019', '379', '1014', '75', '232', '284', '859', '852', '782', '870', '912', '415', '1434', '94', '940', '927', '1270']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-Citation Context Analysis and the Structure of Paradigms Many information scientists are concerned with the operation of document retrieval systems serving scientists in various fields.  The scientists served by these systems are often members of what have been called invisible colleges, groups of scientists in frequent communication with one another and involved with highly specialized subject matters.  Often such groups are considered to share an intellectual perspective regarding this subject matter, which is sometimes referred to as a paradigm.  The purpose of this paper is to show how it is possible to identify paradigms, using the techniques of citation analysis.  I will operationalize the notion of paradigm as a 'consensual structure of concepts in a field.' Suppose we have obtained a set of papers pertaining to some topic.  Already knowing something about the field, we read each text and mark passages in which certain specific concepts are used or discussed.  For example, we might find that a concept designated 'A' appears in some sub-set of the papers.  Suppose further that we identify those papers in which concepts 'A' and 'B' are used together in the same papers in a certain specified manner. Clearly not all concepts will combine in a natural way, and not all authors combining concepts 'A' and 'B' will do so in the same way, though some predominant mode may emerge.  For a set of n concepts their structure is given by the totality of admissible combinations of concepts taken from two to n at a time.  The frequency with which a given combination occurs in the sample of papers on the topic is a measure of the degree of consensus regarding the particular concept combination within the corpus.  For concepts taken two at a time, the structure can be displayed as a graph with concepts as nodes and the relations between them represented as lines (arcs) connecting the nodes.  This definition of concept structure is similar to the semantic network of artificial intelligence except that in our approach a measure of consensus weights each arc of the graph.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['972', '781', '641', '1385', '313', '203', '570', '566', '448', '727', '785', '1159']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cocited Author Retrieval Online: An Experiment with the Social Indicators Literature One mode of online retrieval in Scisearch or Social Scisearch involves entering pairs of authors' names believed to be jointly cited by subsequent writers and retrieving papers in which cocitations occur.  Six pairs were formed with the names of four authors prominent in the social indicators movement (Bauer, Duncan, Land, and Sheldon).  Documents by the four were not specified.  It was thought that the pair Duncan and Land would retrieve papers in which indicator-type data would be integrated with path-analytic causal modeling.  All other pairs seemed likely to retrieve a \"general social indicators\" literature.  The 298 retrieved papers confirmed expectattions.  It was found that 121 papers generally cited social indicators (SI) documents by the input authors and frequently had SI language in their titles.  Other signs of content also identified them as papers of the SI movement.  The 177 papers retrieved on Duncan and Land generally cited causal modeling documents by the input pair and were path-analytic in nature.  As expected, they were relatively \"harder\" than the first group of papers, although the two groups are akin and are formally linked through citations in certain papers.  An additional result is that papers citing at least three of the input authors tend to be overviews of the SI movement.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['123', '308', '126', '1342', '199', '140', '667', '1348']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query ID: 92\n",
      "Query: Database and Online Statistics for 1979 The number of databases, records contained in databases and the online use of databases has increased dramatically over the past several years, bringing the 1979 totals for bibliographic, bioliographic-related, and natural language databases to 528.  These 528 databases contain 148 million records.  Some 4 million online searches were conducted via the major U.S. and Canadian systems in 1979.\n",
      "No matches found.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments in Local Metrical Feedback in Full-Text Retrieval Systems A method of iterative searching, using the results of one iteration search to formulate the next iteration search, was applied to a full-text database consisting of some 2400 documents and 1,3000,000 text-words of Hebrew and Aramaic.  The iterative method consists of clustering the documents returned in an iteration, using weighting by proximity and by frequency simultaneously. The process produces searchonyms, which are terms synonymous to keywords in the context of a single query.  Augumenting or replacing keywords by searchonyms via manual or automatic feedback leads to the formulation of the next iteration search.  The results of the experiment are consistent with those of an earlier small-scale experiment on an English database, and indicate that in contrast to global clustering where the size of matrices limits applications to small databases and improvements are doubtful, local metrical methods appear to be well suited to arbitrarily large databases, improving precision and recall simultaneously.  Further experiments using more test-queries run on even larger databases should be made to collect further evidence as to the performance of these methods.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1124', '483', '71', '51', '608', '1327', '79', '603', '487', '570', '820', '769', '390', '663', '321', '1164', '806', '503', '1162', '317', '117', '309', '751', '530', '1041', '341', '738', '72', '1382', '1135', '956', '1126', '422', '429', '565', '802', '705', '817', '525', '661', '625', '446', '748', '150', '1416', '175', '680', '190', '731', '478', '377', '659', '811', '722', '252', '34', '673', '1419', '571', '616', '179', '360', '598', '160', '158', '1108', '666', '521', '151', '1252', '1391', '865', '1118', '1399', '669', '998', '1298', '41', '545', '1396', '451', '643', '472', '552', '19', '815', '737', '1199', '1098', '1042', '1191', '1184', '232', '222', '1092', '1024', '1194', '73', '1157', '814', '47', '278', '1061', '657', '332', '773', '1323', '199', '52', '411', '790', '980', '668', '1358', '708', '670', '824', '1326', '1398', '1360', '1190', '424', '1158', '207', '633', '1057', '259', '1167', '198', '1105', '1070', '55', '641', '244', '875', '1172', '105', '282', '42', '962', '316', '148', '1099', '262', '146', '1381', '842', '758', '17', '473', '1095', '1454', '1127', '563', '553', '46', '821', '798', '1367', '1121', '206', '1125', '1016', '816', '441', '1429', '302', '269', '1044', '1325', '890', '1226', '1155', '1082', '470', '543', '763', '153', '615', '1009', '1422', '373', '1292', '1450', '339', '254', '256', '1053', '611', '784', '822', '847', '116', '1389', '77', '792', '475', '1355', '1163', '1018', '827', '707', '208', '408', '1142', '265', '690', '1369', '516', '195', '425', '1035', '683', '911', '1161', '115', '561', '889', '994', '945', '5', '423', '604', '50', '327', '352', '1345', '200', '1179', '93', '667', '4', '1401', '194', '1250', '1240', '1242', '1100', '1133', '1220', '1278', '122', '1260', '376', '357', '407', '228', '290', '6', '299', '82', '192', '629', '1428', '1341', '500', '1097', '225', '837', '527', '1432', '333', '953', '1314', '9', '903']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Microcomputer Alternative for Information Handling:  Refles REFLES is a microcomputer-based system for data retrieval in library environments.  The problem of information retrieval is discussed from a theoretical point of view, followed by an analysis of the reference process and data thereby gathered, leading to a description of REFLES in terms of its hardware and software.  REFLES, a prototype system at present, currently functions in a test environment.  Examples of data contained in the system and of its use are presented.  Future considerations and speculations on other versions of the system conclude the paper.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['490', '575', '528', '512', '518', '129', '779', '590', '993', '67', '737', '604', '481', '1346', '644', '646', '611', '888', '74', '534', '531', '373', '446', '571', '1111', '328', '511', '731', '429', '725', '68', '862', '497', '870', '1090', '1173', '894', '822', '291', '1109', '596', '104', '847', '422', '487', '465', '443', '428', '813', '445', '89', '243', '1358', '767', '718', '873', '167', '294', '185', '615', '866', '809', '292', '889', '1360', '1254', '1024', '687', '572', '1429', '529', '193', '1078', '754', '228', '660', '755', '884', '890', '707', '41', '634', '127', '96', '498', '589', '1334', '640', '233', '1291', '371', '287', '760', '745', '451', '156', '593', '1397', '1273', '197', '1121', '659', '636', '623', '1272', '676', '59', '955', '562', '849', '1010', '592', '27', '776', '958', '482', '1422', '388', '64', '1238', '1252', '973', '52', '53', '347', '546', '11', '1020', '464', '1277', '686', '441', '1427', '457', '724', '795', '962', '161', '85', '97', '1072', '507', '393', '1105', '421', '25', '1290', '739', '1037', '762', '153', '121', '1275', '788', '477', '1268', '112', '48', '714', '1106', '748', '1055', '213', '296', '473', '338', '229', '796', '398', '332', '150', '1233', '675', '1021', '1155', '803', '821', '698', '212', '679', '1441', '22', '503', '587', '577', '210', '1274', '770', '1271', '351', '1014', '285', '1313', '928', '1004', '971', '424', '1194', '1234', '49', '218', '814', '113', '673', '972', '756', '1460', '811', '682', '1229', '184', '791', '735', '901', '1287', '1251', '172', '425', '678', '656', '139', '1225', '794', '235', '632', '194', '744', '1314', '965', '657', '276', '800', '248', '816', '1083', '355', '1347', '969', '580', '102', '50', '764', '882', '146', '792', '891', '576', '284', '666', '366', '1063', '65', '1285', '39', '588', '19', '1312', '420', '763', '953', '1310', '665', '613', '662', '775', '1336', '253', '88']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Comparison of Two Systems of Weighted Boolean Retrieval A major deficiency of traditional Boolean systems is their inability to represent the varying degrees to which a document may be written on a subject. In this article we isolate a number of criteria that should be met by any Boolean system generalized to have a weighting capability.  It is proven that only one weighting rule satisfies these conditions--that associated with fuzzy- set theory--and that this weighting scheme satisfies most of the other properties associated with Boolean algebra as well.  Probabilistic weighting is then introduced as an alternative approach and the two systems compared. In the limit of zero/one weights, all systems considered converge to traditional Boolean retrieval.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['531', '810', '319', '895', '523', '446', '838', '519', '512', '773', '484', '659', '1125', '1120', '1054', '388', '1092', '608', '648', '986', '468', '594', '798', '690', '660', '1136', '702', '611', '826', '165', '1448', '661', '381', '459', '486', '1091', '575', '630', '1255', '898', '501', '28', '1170', '318', '737', '61', '1419', '445', '644', '627', '1197', '267', '606', '334', '790', '571', '434', '502', '1053', '779', '114', '1196', '615', '595', '806', '135', '620', '1134', '483', '600', '448', '883', '508', '1180', '565', '73', '68', '634', '497', '1248', '681', '689', '617', '329', '1282', '26', '71', '321', '1259', '727', '1201', '636', '827', '785', '706', '526', '1191', '492', '780', '728', '703', '461', '1171', '67', '562', '530', '820', '534', '1117', '1305', '525', '1139', '451', '839', '625', '670', '641', '1327', '762', '156', '458', '538', '382', '309', '591', '528', '754', '490', '1190', '159', '590', '389', '709', '966', '120', '376', '637', '518', '610', '516', '1072', '871', '481', '375', '993', '151', '866', '707', '716', '1179', '579', '44', '514', '807', '1081', '1391', '160', '566', '472', '254', '479', '478', '1413', '603', '1130', '197', '454', '123', '129', '664', '257', '474', '1078', '1175', '925', '687', '175', '560', '817', '1124', '515', '1377', '131', '452', '488', '126', '829', '1307', '567', '179', '851', '1405', '596', '731', '1126', '174', '243', '894', '503', '378', '695', '889', '704', '510', '176', '746', '547', '137', '487', '956', '688', '835', '252', '327', '1027', '1264', '1368', '1009', '755', '539', '1323', '58', '66', '78', '797', '626', '51', '812', '498', '509', '650', '63', '592', '1364', '1392', '328', '1158', '655', '450', '1089', '1362', '471', '259', '733', '199', '480', '429', '1164', '1162', '1258', '460', '631', '363', '761', '495', '82', '705', '619', '805', '463', '30', '1422', '680', '148', '675', '813', '125', '1414', '686', '857', '769', '853', '496', '473', '29', '462', '1153', '323', '598']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.011"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.273"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.021<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold Values and Boolean Retrieval Systems Several papers have appeared that have analyzed recent developments in the problem of processing, in a document retrieval system, queries expressed as Boolean expressions.  The purpose of this paper is to continue that analysis. We shall show that the concept of threshold values resolves the problems inherent with relevance weights.  Moreover, we shall explore possible evaluation mechanisms for retrieval of documents, based on fuzzy-set-theoretic considerations.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['523', '956', '779', '724', '481', '571', '606', '837', '1144', '126', '827', '529', '847', '1375', '627', '525', '1417', '149', '387', '785', '1098', '1413', '745', '1309', '97', '10', '1179', '9', '1068', '1039', '977', '198', '700', '843', '1368', '22', '639', '1249', '1454', '1210', '500', '12', '1057', '1318', '1001', '246', '305', '1189', '919', '33', '991', '1335']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.019"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.111"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.033<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Model for a Weighted Retrieval System There has been a good deal of work on information retrieval systems that have continuous weights assigned to the index terms that describe the records in the database, and/or to the query terms that describe the user queries. Recent articles have analyzed retrieval systems with continuous weights of either type and/or with a Boolean structure for the queries.  They have also suggested criteria which such systems ought to satisfy and record evaluation mechanisms which partially satisfy these criteria.  We offer a more careful analysis, based on a generalization of the discrete weights.  We also look at the weights from an entirely different approach involving thresholds, and we generate an improved evaluation mechanism which seems to fulfill a larger subset of the desired criteria than previous mechanisms.  This new mechanism allows the user to attach a \"threshold\" to the query term.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1415', '448', '77', '659', '688', '603', '824', '579', '870', '706', '446', '960', '512', '54', '508', '790', '773', '660', '1091', '570', '731', '445', '506', '52', '1366', '487', '514', '1363', '629', '1134', '726', '507', '820', '167', '825', '590', '1215', '894', '755', '643', '781', '653', '489', '812', '1230', '373', '873', '531', '197', '1392', '429', '1418', '762', '70', '736', '826', '442', '1090', '168', '1010', '572', '212', '959', '865', '702', '204', '1253', '428', '1443', '28', '1385', '803', '780', '1024', '596', '81', '562', '1164', '616', '1162', '479', '840', '488', '680', '810', '600', '687', '634', '161', '727', '1081', '1124', '530', '1176', '811', '359', '566', '390', '664', '604', '148', '833', '329', '779', '44', '449', '805', '1325', '267', '501', '813', '745', '158', '598', '458', '538', '1073', '511', '272', '888', '1404', '1182', '804', '149', '714', '357', '269', '798', '749', '649', '185', '778', '1171', '1339', '1307', '542', '497', '817', '764', '1326', '989', '1077', '549', '581', '478', '1384', '151', '1379', '623', '738', '532', '491', '1036', '443', '985', '818', '1187', '207', '718', '809', '1416', '343', '355', '732', '200', '1426', '1246', '1414', '363', '758', '377', '860', '57', '693', '761', '831', '1123', '650', '1421', '477', '92', '1196', '1037', '868', '1138', '86', '657', '791', '1132', '937', '238', '847', '313']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.026"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.833"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.050<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Translating Computer Interface for End-User Operation of Heterogeneous Retrieval Systems.  I. Design Online retrieval systems may be difficult to use, especially by end users, because of heterogeneity and complexity.  Investigations have concerned the concept of a translating computer interface as a means to simplify access to, and operation of, heterogeneous bibliographic retrieval systems and databases.  The interface allows users to make requests in a common language. These requests are translated by the interface into the appropriate commands for whatever system is being interrogated.  System responses may also be transformed by the interface into a common form before being given to the users.  Thus, the network of different systems is made to look like a single \"virtual\" system to the user.  The interface also provides instruction and other search aids for the user.  The philosophy, design, and implementation of an experimental interface named CONIT are described.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['309', '484', '497', '115', '175', '491', '1360', '179', '1139', '872', '1120', '731', '617', '1054', '566', '526', '703', '720', '530', '151', '991', '64', '1361', '1124', '119', '1092', '1126', '883', '682', '1256', '482', '840', '376', '56', '1105', '501', '1164', '707', '54', '1162', '197', '885', '842', '267', '1207', '689', '676', '958', '624', '998', '710', '681', '477', '68', '701', '1317', '1366', '448', '865', '655', '636', '1377', '737', '603', '507', '419', '244', '1416', '211', '1073', '328', '833', '815', '699', '332', '857', '522', '564', '1000', '553', '990', '762', '85', '517', '217', '1364', '1277', '961', '1144', '848', '1248', '1001', '1044', '666', '450', '488', '214', '745', '467', '608', '30', '498', '271', '288', '397', '500', '1224', '1129', '1274', '1098', '983', '715', '398', '1452', '646', '247', '1234', '194', '776', '863', '886', '77', '480', '790', '1371', '734', '225', '1134', '45', '679', '276', '216', '778', '425', '99', '1296', '861', '1140', '420', '1359', '282', '570', '219', '493', '563', '41', '1108', '285', '428', '1340', '814', '1455', '635', '439', '1325', '1090', '1284', '1166', '110', '1434', '623', '668']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.012"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.069"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.021<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Translating Computer Interface for End-User Operation of Heterogeneous Retrieval Systems.  II. Evaluations The evaluation of the concept of a translating compuyter interface for simplifying operation of multiple, heterogenous online bibliographic retrieval systems has been undertaken.  An experimental retrieval system, named CONIT, was built and tested under controlled conditions with inexperienced end users.  A detailed analysis of the experimental usages showed that users were able to master interface operation sufficiently well to find relevant document references.  Success was attributed, in part, to a simple command language, adequate online instruction, and a simplified natural-language, keyword/stem approach to searching.  It is concluded that operational interfaces of the type studied can provide for increased usability of existing system in a cost effective manner, especially for searchers. Furthermore, more advanced interfaces based on improved instruction and automated search strategy techniques could further enhance retrieval effectiveness for a wide class of users.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['648', '626', '594', '523', '546', '728', '593', '606', '1367', '309', '625', '514', '124', '610', '250', '637', '502', '731', '1054', '1368', '534', '486', '28', '575', '547', '492', '382', '1013', '630', '659', '634', '123', '591', '461', '839', '484', '135', '445', '49', '508', '615', '490', '512', '482', '826', '1171', '1170', '175', '491', '1327', '773', '16', '779', '67', '806', '660', '528', '497', '252', '608', '1375', '222', '726', '42', '993', '1418', '373', '820', '458', '959', '46', '310', '1215', '213', '1360', '167', '179', '1358', '342', '433', '692', '1195', '145', '1363', '190', '894', '243', '139', '378', '636', '1183', '327', '510', '370', '538', '1396', '941', '529', '202', '612', '191', '840', '47', '963', '720', '984', '126', '799', '257', '1113', '629', '962', '957', '1035', '495', '1078', '358', '1143', '723', '624', '845', '695', '115', '1361', '224', '456', '1357', '801', '870', '724', '781', '1376', '1043', '1450', '732', '743', '295', '1445', '70', '1440', '234', '161', '913', '1319', '429', '405', '90', '582', '207', '807', '584', '701', '994', '721', '719', '1229', '828', '132', '10', '66', '204', '334', '533', '258', '1236', '1258', '976', '56', '958', '813', '131', '52', '403', '13', '1058', '9', '208', '855', '212', '1436', '607', '137', '1256', '879', '1353', '1365', '1352', '1174', '286', '614', '1118', '1263', '918', '210', '928', '1042', '631', '665', '1019', '274', '122', '218', '818', '580', '298', '223', '1404', '783', '892', '154', '2', '34', '942', '991', '475', '1442', '217', '220', '277', '1107', '147', '793', '718', '771', '1103', '1211', '280', '730', '1429', '1451', '163']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.091"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.618"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.158<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Interface Between Computerized Retrieval Systems and Micrographic Retrieval Systems This paper notes the benefits accruing from interaction between computerized retrieval systems and micrographic retrieval systems.  It reviews current state of automated micrographic retrieval technology.  The conclusion is that with a combination of advances in communications technology, and sophisticated indexing input from libraries and information scientists, the new generation of automated micrographs devices may constitute the on-line document retrieval systems of the future.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['883', '1124', '131', '636', '716', '123', '655', '916', '631', '481', '993', '795', '72', '17', '661', '922', '1241', '1362', '1144', '1258', '685', '134', '482', '400', '1356', '386', '24', '897', '348', '943', '367', '1346', '718', '80', '846', '1437', '1238', '1082', '1290', '320', '1439', '1457', '100', '621', '801', '1045', '53', '491', '166', '401', '1251', '878', '423', '1273', '977', '485', '1429', '112', '142', '1', '1043', '1079', '901', '1088', '1390', '418', '580', '310', '938', '923', '1344', '847', '32', '1268', '870', '950', '1090', '1025', '767', '873', '1149', '1417', '185', '1383', '907', '915', '1294', '1354', '1388', '143', '453', '935', '902', '1438', '561']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.011"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.056"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.018<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel Computations in Information Retrieval Conventional information retrieval processes are largely based on data movement, pointer manipulations and integer arithmetic; more refined retrieval algorithms may in addition benefit from substantial computational power.  In the present study a number of parallel processing methods are described that serve to enhance retrieval services.  In conventional retrieval environments parallel list processing and parallel search facilities are of greatest interest.  In more advanced systems, the use of array processors also proves beneficial.  Various information retrieval processes are examined and evidence is given to demonstrate the usefulness of parallel processing and fast computational facilities in information retrieval.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1089', '375', '309', '461', '514', '1078', '805', '363', '655', '853', '565', '175', '575', '704', '151', '28', '378', '1081', '755', '608', '1009', '199', '137', '459', '496', '703', '376', '895', '637', '1139', '1136', '179', '1264', '1120', '611', '1053', '1164', '660', '497', '590', '126', '664', '458', '1162', '538', '615', '490', '733', '1027', '1191', '707', '487', '1158', '319', '495', '1413', '690', '567', '484', '1405', '526', '1368', '78', '174', '523', '509', '1092', '1419', '525', '481', '1134', '1305', '131', '445', '797', '474', '827', '1190', '579', '66', '641', '591', '606', '631', '798', '562', '528', '956', '648', '595', '254', '486', '323', '630', '518', '446', '129', '508', '1180', '512', '123', '460', '659', '135', '1054', '451', '731', '67', '1126', '462', '1125', '1170', '1124', '176', '327', '539', '488', '502', '737', '851', '706', '156', '73', '839', '148', '806', '471', '644', '389', '454', '670', '478', '687', '472', '71', '625', '594', '1201', '1362', '883', '516', '728', '835', '318', '627', '889', '1171', '434', '68', '450', '1282', '636', '501', '779', '503', '1179', '1327', '727', '321', '826', '448', '1307', '650', '680', '483', '328', '966', '480', '547', '1364', '61', '534', '243', '1391', '29', '925', '773', '626', '762', '754', '114', '716', '1448', '388', '746', '530', '519', '334', '252', '829', '807', '813', '866', '1323', '598', '463', '267', '600', '661', '1377', '894', '30', '1130', '429', '820', '498', '705', '515', '120', '382', '560', '702', '1175', '1258', '197', '566', '857', '159', '689', '681', '160', '617', '790', '780', '329', '1196', '1255', '510', '610', '26', '993', '592', '473', '531', '381', '619', '44', '125', '1072', '634', '1091', '603', '695', '986', '63', '1153', '871', '452', '769', '257', '259', '817', '165', '620', '686', '812', '58', '761', '1259', '479', '596', '1392', '468', '1197', '492', '1422', '688', '709', '675', '571', '785', '51', '838', '1117', '810', '898', '1248', '82', '1414']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Measurement of Term Importance in Automatic Indexing The frequency characteristics of terms in the documents of a collection have been used as indicators of term importance for content analysis and indexing purposes.  In particular, very rare or very frequent terms are normally believed to be less effective than medium-frequency terms.  Recently automatic indexing theories have been devised that use not only the term frequency characteristics but also the relevance properties of the terms. The major term-weighting theories are first briefly reviewed.  The term precision and term utility weights that are based on the occurrence characteristics of the terms in the relevant, as opposed to the nonrelevant, documents of a collection are then introduced.  Methods are suggested for estimating the relevance properties of the terms based on their overall occurrence characteristics in the collection.  Finally, experimental evaluation results are shown comparing the weighting systems using the term relevance properties with the more conventional frequency-based methodologies.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1325', '634', '1419', '666', '700', '456', '185', '357', '646', '1143', '595', '625', '621', '291', '474', '330', '407', '1040', '202', '320', '134', '295', '525', '217', '128', '630', '468', '408', '916', '1095', '160', '821', '75', '540', '900', '364', '854', '112', '1053', '573', '139']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDX-100:  An Electronic Filing Machine for the Office of the Future This paper describes the design and implementation of an \"electronic filing machine,\" a machine which is capable of storing large numbers of \"unstructured\" documents in such a way a particular document may be easily and quickly retrieved.  A functional distributed architecture permits the implementation of the system in a mixture of hardware and software.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['687', '702', '897', '512', '376', '528', '880']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Selection of Good Search Terms This paper tackles the problem of how one might select further search terms, using relevance feedback, given the search terms in the query.  These search terms are extracted from a maximum spanning tree connecting all the terms in the index term vocabulary.  A number of different spanning trees are generated from a variety of association measures.  The retrieval effectiveness for the different spanning trees is shown to be approximately the same.  Effectiveness is measured in terms of precision and recall, and the retrieval tests are done on three different test collections.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['894', '562', '486', '566', '812', '1124', '86', '448', '531', '596', '824', '61', '643', '726', '501', '488', '778', '959', '151', '649', '483', '956', '608', '419', '1184', '1419', '700', '238', '472', '1418', '167', '503', '71', '377', '78', '363', '576', '165', '366', '280', '748', '223', '509', '237', '92', '1448', '754', '865', '1417', '983', '278', '1323', '1243', '1156', '575', '564', '1253', '597', '59', '593', '1328', '51', '189', '1261', '407', '1425', '235', '815', '261', '522', '1072', '1251', '129', '393', '891', '850', '1023', '905', '646', '1183', '1020', '1028', '266', '1450', '182', '76', '661', '1322', '381', '376', '367', '981', '1153', '551', '926', '241', '1369', '242', '181', '260', '936', '568', '898', '1395', '297', '351', '1221', '115', '33', '901', '344', '8', '777', '1238', '46', '198', '485', '1019', '305', '1310', '284', '1094', '147', '80', '415', '903', '1147', '759', '944', '370', '1189', '2', '977', '303', '1202', '12', '1211', '1152', '1383', '221', '215', '1352', '219', '886', '651', '225', '1071', '1203', '911', '674', '10', '952', '187', '1349']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.006"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.091"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.012<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing Consistency, Quality and Efficiency Indexing quality determines whether the information content of an indexed document is accurately represented.  Indexing effectiveness measures whether an indexed document is correctly retrieved every time it is relevant to a query.  Measurement of these criteria is cumbersome and costly; data base producers therefore prefer inter-indexer consistency as a measure of indexing quality or effectiveness.  The present article assesses the validity of this substitution in various environments.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['805', '608', '1359', '517', '309', '1375', '531', '518', '528', '390', '350', '964', '688', '129', '646', '612', '960', '1202', '642', '325', '1426', '490', '968', '202', '244', '1167', '1207', '357', '1065', '497', '142', '387', '1058', '772', '1025', '67', '1321', '484', '628', '1186', '1029', '1379', '1456']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.091"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Passage Retrieval Based on Colon Classification:  Retrieval Performance A set of experiments was conducted to determine the suitability of the Colon Classification as a foundation for the automated analysis, representation and retrieval of primary information from the full text of documents.  Primary information is that information embodied in the text of a document, as opposed to secondary information which is generally in such forms as:  an abstract, a table of contents, or an index. Full text databases were created in two subject areas and queries solicited from specialists in each area.  An automated full text indexing system, along with four automated passage retrieval systems, was created to test the various features of the Colon Classification.  Two Boolean-based systems and one simple word occurrence system were created in order to compare the retrieval results against types of systems which are in more common use.  The systems' retrieval performances were measured using recall and precision and the mean expected search length reduction factors. Overall, it was found that the Colon Classification-based systems did not perform significantly better than the other systems.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['565', '636', '1124', '702', '1195', '483', '514', '1448', '523', '486', '534', '644', '1419', '61', '820', '595', '575', '1170', '321', '609', '1327', '1298', '1144', '484', '1054', '510', '329', '1120', '71', '175', '641', '446', '179', '571', '1139', '517', '564', '16', '72', '1175', '727', '1078', '478', '458', '1409', '538', '390', '826', '1091', '1391', '180', '319', '526', '535', '522', '806', '591', '378', '389', '492', '434', '1225', '707', '525', '320', '309', '530', '556', '615', '136', '1230', '1105', '1136', '576', '773', '481', '1405', '637', '1261', '986', '798', '257', '252', '839', '1080', '785', '1196', '519', '620', '739', '507', '572', '874', '472', '989', '1035', '966', '889', '752', '336', '898', '28', '448', '690', '174', '682', '825', '135', '606', '512', '1038', '1358', '1114', '421', '177', '64', '779', '865', '659', '1267', '822', '461', '140', '123', '158', '725', '860', '474', '68', '1040', '1215', '445', '796', '165', '1109', '497', '660', '1092', '720', '993', '648', '626', '502', '388', '630', '332', '459', '382', '611', '504', '582', '542', '566', '1255', '262', '1077', '603', '74', '137', '621', '67', '531', '501', '27', '150', '1307', '625', '979', '1281', '728', '547', '670', '294', '49', '594', '815', '1113', '754', '842', '1180', '1191', '419', '726', '1104', '381', '895', '579', '866', '737', '376', '590', '546', '482', '1171', '151', '1126', '990', '1121', '1410', '593', '1', '1125', '66', '1111', '802', '695', '1264', '1190', '433', '202', '406', '600', '703', '731', '335', '1259', '700', '1110', '553', '610', '1074', '1309', '375', '916', '114', '126', '740', '970', '1418', '120', '562', '709', '642', '254', '129', '1282', '1012', '1413', '1173', '742', '508', '1117', '347', '1305', '1361', '897', '627', '574', '528', '454', '1209', '838', '132', '477', '515', '612', '1348', '664', '243', '1143', '827', '1179', '131', '1207', '560', '213', '671', '1051', '809', '925', '617', '762', '1137', '666', '1341', '1098', '795', '451', '447', '1057', '59', '544', '54', '354', '159', '119', '1053', '687', '245', '701', '704', '1127', '73', '1112', '513', '318', '1223', '1007', '1099', '128', '80', '325', '723', '639', '310', '134', '340', '17', '634', '676', '268', '190', '890', '674', '883', '871', '224', '532', '1106', '1193', '1010', '1283', '1367', '1062', '1362', '1128', '689', '1147', '693', '1241', '244', '801', '1229', '490', '1072', '691', '677', '780', '250', '537', '317', '1081', '197', '1067', '267', '706', '607', '744', '386', '850', '1366', '1445', '228', '1349', '409', '652', '948', '849', '295', '1293', '1360', '529', '85', '1350', '741', '1416', '833', '830', '1326', '1073', '1460', '840', '327', '1375', '694', '716', '231', '57', '491', '117', '494', '1427', '872', '1044', '848', '1395', '884', '358', '44', '1152', '449', '557', '699', '683', '373', '1011', '1227', '1289', '567', '960', '646', '880', '852', '1378', '95', '982', '1377', '1024', '647', '476', '1022', '645', '1084', '1447', '1016', '697', '25', '1437', '1328', '468', '1363', '601', '681', '291', '350', '954', '157', '846', '452', '1043', '862', '387', '511', '364', '1436', '10', '212', '868', '955', '400', '394', '1236', '89', '1093', '467', '104', '786', '288', '1415', '1249', '710', '398', '408', '1256', '724', '947', '597', '1197', '4', '1401', '287', '1148', '654', '941', '380', '843', '1004', '917', '102', '18', '141', '888', '292', '465', '1456', '998', '1163', '1277', '841', '951', '399', '13', '115', '1337', '1339', '1290', '1049', '1333', '396', '200', '168', '1317', '1085', '997', '1206', '208', '265', '1425', '222', '443', '124', '999', '348', '1457', '106', '911', '984', '1417', '211', '1000', '1001', '192', '48', '1402']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.091"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-Responsive Subject Control in Bibliographic Retrieval Systems A study was carried out of the relationship between the vocabulary of user queries and the vocabulary of documents relevant to the queries, and the value of adding to the document description record in a retrieval system keywords from previous queries for which the document had proved useful. Two test databases incorporating user query keywords were implemented at the School of Library and Information Science, University of Western Ontario.  Clustering of the documents via title and user keywords, a statistical analysis of title-user keyword co-occurrences, and retrieval tests were used to examine the effect of the added keywords.  Results showed the impracticality of the procedure in an operational setting, but indicated the value of analyses with sample data in the development and maintenance of keyword dictionaries and thesauri.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1118', '483', '606', '504', '608', '643', '71', '802', '1091', '773', '176', '1171', '1448', '151', '1224', '30', '989', '212', '508', '501', '434', '627', '589', '506', '798', '390', '781', '53', '1076', '1139', '1144', '1413', '542', '809', '1073', '1163', '1414', '653', '1133']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.091"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Program for Machine-Mediated Searching A technique of online instruction and assistance to bibliographic data base searchers called Individualized Instruction for Data Access (IIDA) is being developed by Drexel University.  IIDA assists searchers by providing feedback based on real-time analysis while searches are being performed. Extensive help facilities which draw on this analysis are available to users.  Much of the project's experimental work, as described elsewhere, is concerned with the process of searching and the behavior of searchers. This paper will largely address itself to the project's computer system, which is being developed by subcontract with the Franklin Institute's Science Information Services.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['579', '637', '512', '547', '243', '65', '529', '692', '743', '1396', '496', '731', '1096', '135', '206', '307', '220', '216', '900', '728', '376', '375', '145', '604', '642', '727', '466', '504', '1078', '1376', '646', '528', '186', '813', '705', '839', '738', '408', '150', '594', '467', '629', '1362', '358', '854', '845', '1105', '4', '1401', '609', '671', '330', '1415', '490', '348', '593', '129', '1368', '1367', '1400', '169', '217', '760', '822', '291', '268', '801', '156', '1356', '1006', '1143', '1370', '465', '197', '892', '879', '252', '1144', '10', '739', '127', '295', '202', '250', '131', '293', '267', '1239', '141', '985', '364', '1147', '124', '1043', '126', '842', '619', '883', '1106', '674', '161', '687', '535', '1375', '818', '153', '1009', '272', '650', '223', '385', '14', '584', '310', '1430', '588', '809', '722', '1221', '17', '582', '1008', '140', '583', '207', '177', '820', '1440', '234', '133', '946', '645', '597', '208', '979', '429', '507', '66', '1192', '254', '134', '814', '459', '205', '12', '90', '187', '672', '816', '482', '1378', '1245', '967', '1303', '877', '1110', '580', '1212', '1349', '957', '936', '224', '218', '831', '910', '773', '95', '470', '248', '1256', '984', '639', '776', '1248', '244', '1089', '1166', '723', '1353', '1296', '934', '178', '555', '978', '828', '942', '235', '381', '1076', '846', '771', '33', '1032', '914', '700', '500', '1170', '1403', '916', '1059', '347', '1417', '213', '952', '935', '1017', '1397', '774', '353', '258', '709', '162', '138', '1095', '850', '696', '506', '677', '257', '355', '1183', '164', '265', '589', '881', '701', '515', '730', '908', '976', '1223', '949', '300', '1049', '792', '1018', '930', '717', '303', '283', '384', '823', '241', '622', '1236', '1251', '32', '657', '1189', '1423', '37', '1390', '918', '297', '344', '1056', '1253', '1203', '1394', '550', '182', '932']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.091"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author Cocitation:  A Literature Measure of Intellectual Structure It is shown that the mapping of a particular area of science, in this case information science, can be done using authors as units of analysis and the cocitations of pairs of authors as the variable that indicates their \"distances\" from each other.  The analysis assumes that the more two authors are cited together, the closer the relationship between them.  The raw data are cocitation counts drawn online from Social Scisearch (Social Sciences Citation Index) over the period 1972-1979.  GThe resulting map shows (1) identifiable author groups (akin to \"schools\") of information science, (2) locations of these groups with respect to each other, (3) the degree of centrality and peripherality of authors within groups, (4) proximities of authors within group and across group boundaries (\"border authors\" who seem to connect various areas of research), and (5) positions of authors with respect to the map's axes, which were arbitrarily set spanning the most divergent groups in order to aid interpretation.  Cocitation analysis of authors offers a new technique that might contribute to the understanding of intellectual structure in the sciences and possibly in other areas to the extent that those areas rely on serial publications.  The technique establishes authors, as well as documents, as an effective unit in analyzing subject specialties.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['588', '1063', '1274', '632', '1168', '1312', '1338', '1313', '649', '918']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.600"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.085"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.148<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress in Documentation.  Word Processing: An Introduction and Appraisal The \"Office of the Future,\" \"Office Technology,\" \"Word Processing,\" \"Electronic Mail,\" \"Electronic Communications,\" \"Convergence,\" \"Information Management.\"  These are all terms included in the current list of buzz words used to describe current activities in the office technology area.  The high level of investment in factories and plants and the ever-increasing fight to improve productivity by automating the dull, routine jobs are usually quoted and compared with the extremely low investment in improving and automating the equally tedious routine jobs in the office environment; the investment in the factory is quoted as being ten times greater per employee than in the office.  This, however, is changing rapidly and investment on a large scale is already taking place in manhy areas as present-day inflation bites hard, forcing many companies and organizations to take a much closer look at their office operations.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['964', '400', '497', '178', '572', '970', '490', '408', '350', '664', '17', '122', '1358', '1359', '1407', '585', '1070', '1257', '815', '188', '153', '129', '158', '27', '723', '1408', '525', '141', '523', '291', '842', '433', '484', '1027', '1397', '797', '659', '960', '993', '1105', '511', '309', '822', '692', '593', '348', '594', '984', '1193', '1219', '575', '1418', '515', '1317', '547', '654', '16', '732', '1274', '126', '243', '742', '310', '250', '31', '1208', '1183', '959', '907', '164', '491', '1227', '745', '938', '1051', '302', '1352', '529', '590', '704', '839', '1009', '819', '961', '941', '64', '1364', '44', '684', '1022', '1248', '67', '1171', '115', '674', '584', '1015', '690', '227', '25', '146', '857', '617', '591', '976', '709', '102', '681', '884', '710', '698', '265', '365']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.085"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Clustering Using an Inverted File Approach An automated document clustering procedure is described which does not require the use of an inter-document similarity matrix and which is independent of the order in which the documents are processed.  The procedure makes use of an initial set of clusters which is derived from certain of the terms in the indexing vocabulary used to characterise the documents in the file.  The retrieval effectiveness obtained using the clustered file is compared with that obtained from serial searching and from use of the single-linkage clustering method.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['570', '422', '483', '1124', '1419', '608', '309', '503', '790', '52', '71', '446', '659', '377', '565', '487', '321', '820', '51', '737', '769', '643', '175', '530', '1118', '738', '1298', '708', '657', '663', '390', '1024', '72', '1126', '179', '79', '865', '429', '525', '661', '625', '824', '956', '673', '603', '571', '1327', '806', '962', '641', '817', '598', '980', '425', '1194', '731', '773', '842', '195', '190', '604', '1092', '1127', '822', '42', '1018', '1391', '875', '207', '299', '666', '105', '1422', '889', '194', '798', '1191', '521', '1108', '1190', '722', '472', '553', '1355', '208', '360', '1381', '1044', '41', '1252', '423', '82', '341', '670', '259', '1009', '146', '690', '1396', '680', '611', '500', '1325', '200', '1095', '151', '269', '668', '811', '77', '1164', '198', '1162', '34', '50', '1226', '225', '117', '669', '758', '633', '516', '1155', '705', '815', '1323', '545', '1292', '751', '317', '1416', '1360', '527', '552', '278', '814', '543', '222', '373', '816', '252', '9', '1450', '148', '290', '46', '150', '206', '199', '478', '1278', '1061', '115', '1172', '615', '192', '424', '73', '256', '847', '1105', '994', '945', '5', '1242', '629', '282', '1125', '376', '1314', '1082', '327', '451', '616', '17', '953', '1097', '475', '93', '911', '6', '316', '1157', '998', '792', '262', '1041', '1042', '1382', '19', '1099', '254', '228', '563', '561', '1142', '357', '683', '1326', '1398', '707', '1358', '47', '352', '1389', '1184', '802', '153', '1428', '748', '158', '470', '332', '1260', '244', '408', '160', '827', '890', '1098', '1070', '1432', '473', '1179', '1053', '411', '1035', '1158', '122', '1454', '1199', '1369', '116', '55', '1100', '1133', '1220', '441', '232', '1163', '407', '1161', '302', '1121', '1167', '1057', '1345', '837', '1135', '1429', '763', '4', '1401', '265', '333', '1367', '1240', '667', '784', '1341', '1250', '1016', '903', '1399', '339', '821']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.008"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.333"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.015<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Query"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Fast Procedure for the Calculation of Similarity Coefficients in in Automatic Classification A fast algorithm is described for comparing the lists of terms representing documents in automatic classification experiments.  The speed of the procedure arises from the fact that all of the non-zero-valued coefficicents for a given document are identified together, using an inverted file to the terms in the document collection.  The complexity and running time of the algorithm are compared with previously described procedures.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Matching document IDs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['853', '503', '45', '576', '1124', '596', '328', '483', '1132', '643', '487', '485', '530', '608', '1421', '769', '812', '309', '636', '1118', '71', '566', '754', '825', '714', '179', '706', '175', '966', '1215', '68', '666', '842', '84', '1202', '635', '247', '508', '1139', '17', '16', '1398', '1028', '811', '64', '1045', '495', '1109', '634', '979', '834', '135', '1131', '423', '194', '591', '178', '264', '917', '1038', '1450', '200', '625', '1328', '1176', '689', '439', '174', '887', '756', '806', '1252', '374', '27', '1042', '504', '677', '593', '484', '610', '647', '1422', '311', '1218', '208', '1012', '38', '217', '249', '897', '527', '143', '227', '410', '326', '765', '385', '528', '1358', '352', '348']\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Precision: 0.000"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Recall: 0.333"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "F1-Score: 0.000<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Mean Average Precision: 0.054"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def testing(documents, queries, mappings):\n",
    "    # Stores cleaned documents\n",
    "    cleaned_paragraphs = {}\n",
    "\n",
    "    for doc in documents:\n",
    "        doc_id = doc['id']\n",
    "        # Clean and tokenize the document text, then store it\n",
    "        cleaned_text = clean_text(doc['text'])  \n",
    "        cleaned_paragraphs[doc_id] = {'tokens': cleaned_text}\n",
    "\n",
    "    # Build the inverted index\n",
    "    inverted_index = defaultdict(set)\n",
    "    for doc_id, doc in cleaned_paragraphs.items():\n",
    "        for term in doc['tokens']:  # Use 'tokens' instead of 'text'\n",
    "            inverted_index[term].add(doc_id)\n",
    "\n",
    "    # Store average precision for each query\n",
    "    average_precisions = []\n",
    "\n",
    "    for query in queries:\n",
    "        query_id = query['id']\n",
    "        query_text = query['text']\n",
    "\n",
    "        # Preprocess the query text\n",
    "        cleaned_query = ' '.join(clean_text(query_text))\n",
    "      \n",
    "        # Convert the query to postfix and evaluate using the inverted index\n",
    "        postfix_query = infix_to_postfix(cleaned_query)\n",
    "        results = evaluate_postfix(postfix_query, inverted_index, len(cleaned_paragraphs))\n",
    "\n",
    "        # Apply TF-IDF transformation on the resulting paragraphs\n",
    "        tfidf_matrix, filtered_paragraphs, filtered_ids, vectorizer = tf_idf(results, cleaned_paragraphs)\n",
    "\n",
    "        if not filtered_paragraphs:  \n",
    "            print(f\"\\nQuery ID: {query_id}\")\n",
    "            print(f\"Query: {query_text}\")\n",
    "            print(\"No matches found.\\n\")\n",
    "            average_precisions.append(0)\n",
    "            continue\n",
    "\n",
    "        # Use TF-IDF results as input to BM25\n",
    "        tokenized_docs = []\n",
    "        for doc_id in filtered_ids:\n",
    "            tokenized_docs.append(cleaned_paragraphs[doc_id]['tokens'])\n",
    "    \n",
    "        bm25 = BM25Okapi(tokenized_docs)    \n",
    "        bm25_scores = bm25.get_scores(postfix_query)\n",
    "\n",
    "        # Rank documents based on BM25 scores\n",
    "        ranked_results = sorted(\n",
    "            zip(filtered_ids, bm25_scores),\n",
    "            key = lambda x: x[1],\n",
    "            reverse = True\n",
    "        )\n",
    "\n",
    "        # Extract retrieved document IDs with scores > 0\n",
    "        retrieved_docs = []\n",
    "        for doc_id, score in ranked_results:\n",
    "            if score > 0:\n",
    "                retrieved_docs.append(doc_id)\n",
    "\n",
    "       # Find relevant documents for this query\n",
    "        relevant_docs = set()\n",
    "        for mapping in mappings:\n",
    "            if mapping['query_id'] == query_id:\n",
    "                relevant_docs.add(mapping['doc_id'])\n",
    "        \n",
    "        # Calculate precision at each relevant document's position\n",
    "        true_positives = 0\n",
    "        precisions = []\n",
    "\n",
    "        for i, doc_id in enumerate(retrieved_docs, start = 1):\n",
    "            if doc_id in relevant_docs:\n",
    "                true_positives += 1\n",
    "                precision_at_k = true_positives / i\n",
    "                precisions.append(precision_at_k)\n",
    "\n",
    "        if retrieved_docs:\n",
    "            precision = true_positives / len(retrieved_docs)\n",
    "        else:\n",
    "            precision = 0\n",
    "        \n",
    "        if relevant_docs:\n",
    "            ap = sum(precisions) / len(relevant_docs)\n",
    "            recall = true_positives / len(relevant_docs)\n",
    "        else:\n",
    "            ap = 0\n",
    "            \n",
    "        average_precisions.append(ap)\n",
    "\n",
    "        if precision + recall > 0:\n",
    "            f1_score = (2 * precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1_score = 0;\n",
    "\n",
    "        # Print metrics for the current query\n",
    "        display(Markdown(\"Query\"))\n",
    "        print(f\"{query_text}\")\n",
    "        display(Markdown(\"Matching document IDs\"))\n",
    "        print(f\"{retrieved_docs}\")\n",
    "        display(Markdown(f\"Precision: {precision:.3f}\"))\n",
    "        display(Markdown(f\"Recall: {recall:.3f}\"))\n",
    "        display(Markdown(f\"F1-Score: {f1_score:.3f}<br><br>\"))\n",
    "\n",
    "    # Calculate Mean Average Precision \n",
    "    map_score = sum(average_precisions) / len(average_precisions) if average_precisions else 0\n",
    "    display(Markdown(f\"Mean Average Precision: {map_score:.3f}\"))\n",
    "    \n",
    "\n",
    "display(Markdown(\"Using the CISI dataset to evaluate search engine<br>\"))\n",
    "testing(documents, queries, mappings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa391df-e608-45d7-a7b1-9ddc441eb820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
